---
title: "Pr√°tica 4: Modelos"
author: "Jorge Galiano Garc√≠a"
format:
  html:
    theme: [style.scss]
    toc: true
    toc-location: right
    toc-title: √çndice
    toc-depth: 4
editor: visual
---

[**ESCENARIO**]{.hl-bluepastel}

Seg√∫n la [**Organizaci√≥n Mundial de la Salud (OMS)**]{.hl-pinkpastel}, el mundo se enfrenta a una creciente crisis de personal sanitario, con una proyecci√≥n de d√©ficit de m√°s de 11 millones de trabajadores para el a√±o 2030. Esta situaci√≥n se ve agravada por el fen√≥meno del [**employee attrition**]{.hl-bluepastel}, es decir, el abandono voluntario de profesionales en sus puestos de trabajo.

En sectores como el sanitario, este fen√≥meno alcanza cifras especialmente preocupantes. Por ejemplo, se estima que la [**tasa de rotaci√≥n del personal hospitalario supera el 20%**]{.hl-bluepastel}, llegando incluso al 26% en algunos contextos recientes, seg√∫n datos del sector. 

Esta alta rotaci√≥n compromete la calidad de la asistencia, aumenta los costes operativos y dificulta la planificaci√≥n de recursos humanos en instituciones de salud.

Ante esta problem√°tica, surge la necesidad de herramientas predictivas que permitan anticipar el riesgo de abandono de los empleados, facilitando una gesti√≥n proactiva del talento. En este contexto, el Aprendizaje Autom√°tico se posicionan como aliado clave para desarrollar modelos capaces de identificar patrones de riesgo y apoyar la toma de decisiones estrat√©gicas.

```{r echo = FALSE, out.width = "100%", fig.align = "center", fig.cap = ""}
knitr::include_graphics("./img/employeeAtrittion.png")
```

El conjunto de datos sobre [abandono laboral en el √°mbito de la salud](https://www.kaggle.com/datasets/jpmiller/employee-attrition-for-healthcare/data) (`watson_healthcare_modified.csv`) est√° compueto por [**1676 observaciones**]{.hl-pinkpastel} (en este caso cada observaci√≥n corresponde a un trabajador) y de un total de [**26 variables**]{.hl-pinkpastel} (una variable `employeeid` que tomar√° el rol de identificador y la variable objetivo `attrition`).

[**OBJETIVO**]{.hl-bluepastel}

Construir un modelo (varios en nuestro caso) para [**predecir la probabilidad de abandono laboral de un empleado**]{.hl-pinkpastel} en funci√≥n de algunas variables de entrada como el sexo, la edad, el puesto en el que trabaja, su sueldo y otras.

[**ENUNCIADO DE LA PR√ÅCTICA**]{.hl-bluepastel}

1)  **Descargarse el conjunto de datos** desde el enlace facilitado

2)  [**Analizar, depurar, procesar y recategorizar**]{.hl-pinkpastel} los datos (consejo: haz uso de los paquetes `tidyverse`, `ggplt` u otros que hayamos visto que resulten de inter√©s).

3)  Determinar la fijaci√≥n del criterio de [**bondad de ajuste elegido**]{.hl-pinkpastel}.

4)  [**Realizar los siguientes modelos**]{.hl-pinkpastel}:

    -   **√Årbol de Decisi√≥n**

    -   **KNN** (*K-Nearest Neighbors*)

    -   **SVM** (*Support Vector Machine*)

    -   **Red Neuronal**

    -   **Alg√∫n** m√©todo de ***Ensamble***: *Bagging*, *Boosting* o *Stacking* (con uno soy feliz ü´†)

5)  La parte del modelado, [**para cada una de las t√©cnicas menciondas**]{.hl-pinkpastel}, debe contener los [**siguientes puntos**]{.hl-pinkpastel}:

    -   **Justificaci√≥n** de **hiperpar√°metros** a modelizar y el rango de los mismos.

    -   Determinar el valor de los **par√°metros √≥ptimos**.

    -   Selecci√≥n de **modelo ganador**üéñ (en caso de que el propio algoritmo lo permita, explicar dicho modelo) y evaluaci√≥n sobre conjunto *Test*

6)  **Comparar** los 5 modelos generados

::: callout-important
## Consideraciones

1)  El trabajo es **individual**üèåÔ∏è

2)  El **an√°lisis y depuraci√≥n de los datos**üßπ es sin duda la fase m√°s importante de un proyecto como en el que nos encontramos, por ello **ser√° la parte que m√°s pese** del trabajo en comparaci√≥n con el resto de puntos

3)  El trabajo deber√° estar explicado (no basta con poner solo las salidas). Es necesario indicar el c√≥digo utilizado. Se **valorar√° la claridad de exposici√≥n en el informe y la estructura**üìù

4)  üìÄ**IMPORTANTE**üìÄ: Toda el contenido matem√°tico **se evaluar√°** en la asignatura ***Matem√°tica y Estad√≠stica para la Inteligencia Artificial***üì±. Por lo que subir√©is las entregas tanto a una asignatura como a la otra (*Aprendizaje Autom√°tico Avanzado*)
:::

## Librer√≠as

```{r}
#| code-fold: false
#| message: false
#| warning: false

rm(list = ls())

library(tidyverse)  # Depuraci√≥n datos
library(skimr)      # Resumen num√©rico
library(outliers)   # Outliers
library(ggplot2)    # Gr√°ficos
library(tidymodels) # Modelos
library(rpart)      # CART
library(rpart.plot) # Graficar √°rbol
library(caret)      # Matriz de Confusion
library(glue)       # pegar texto + variables f√°cilmente
library(DT)         # Para mostrar tabla (formatStyle)
library(ROSE)       # Para Oversampling
library(yardstick)  # C√≥mo funcionan modelos
library(forcats)    # Para factores
library(solitude) # Isolation Forest
library(mice) # Imputar RF
library(modeest) # Para moda
library(stratification) # Dalenius
library(fastDummies) # Dummies
library(rsample) # Para particion Train/Test
# Combinar gr√°ficos
library(egg)
library(ggimage)
library(ggpubr)
library(hrbrthemes)
library(ggthemes)

```

## Preparaci√≥n de los datos

En primer lugar vamos a **importar el dataset** con el que se va a trabajar.

```{r}
#| message: false
#| warning: false

dataset_attrition <- read.csv(file = "./data/watson_healthcare_modified.csv")

```

Adem√°s vamos a convertir la variable objetivo, que en nuestro caso es **Attrition** a tipo factor donde podr√° obtener los valores **No** y **Yes**. Por otro lado se va a realizar una transformaci√≥n de tal forma que la variable quede representada con valores 1-Yes y 0-No y se mantenga como categ√≥rica.

```{r}
#| code-fold: false
#| message: false
#| warning: false

dataset_attrition$Attrition <- factor(dataset_attrition$Attrition)

is.factor(dataset_attrition$Attrition)

levels(dataset_attrition$Attrition)

dataset_attrition <- dataset_attrition |> mutate(Attrition = ifelse(Attrition == "Yes",1,0))

dataset_attrition$Attrition <- as.factor(dataset_attrition$Attrition)

```

Tambi√©n es importante **estandarizar los nombres de las variables de nuestro dataset**. En general se puede ver que el dataset viene bastante bien preparado ya que no contiene espacios pero si que tiene [UpperCamelCase](https://wiki.c2.com/?PascalCase) por lo que deberemos convertir las variables a min√∫sculas.

```{r}
#| code-fold: false
#| message: false
#| warning: false

names(dataset_attrition)

names(dataset_attrition) <- str_to_lower(names(dataset_attrition))

```

### Variable objetivo

Es muy importante conocer la distribuci√≥n de la variable objetivo para dise√±ar estrategias de modelado adecuadas, garantizar un entrenamiento justo y obtener m√©tricas confiables.

Con esta visualizaci√≥n de la variable objetivo podremos detectar posibles desbalanceos de nuestro conjunto de datos que nos permitir√°n crear estrategias para poder suplir estos problemas a la hora de crear los modelos y entrenarlos.

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
dataset_attrition |> group_by(attrition) |> summarise(nAttrition = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> ggplot(aes(x = attrition, y = nAttrition, fill = attrition)) +
geom_col(position = "dodge", alpha = 0.8) +
geom_text(aes(label = paste(nAttrition," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5) +
ylim(0,1500)+
scale_fill_manual(values = c("#4ec475","#f23849")) +
labs(title = "Distribuci√≥n de la variable objetivo",
     subtitle = "Reparto de niveles de la variable objetivo (attrition)")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None")

```

Como podemos observar nuestra variable objetivo **Attrition** tiene un 88.13% - 11.87% entre los dos valores que puede obtener, lo que nos indica que es una variable que est√° muy desbalanceada. A la hora de entrenar los modelos, esto va a tener repercusiones negativas haciendo que no haya buenas predicciones de cuando un empleado vaya a abandonar la empresa.

Para solucionar este problema se buscar√° una t√©cnica tras realizar el an√°lisis del resto de los datos para compensar esta falta de datos en el **1-Yes** de la variable objetivo.

### Analisis exploratorio de los datos

Para llevar a cabo este an√°lisis en primer lugar vamos a visualizar un resumen de los datos que tenemos actualmente en el dataset:

```{r}
dataset_attrition |> skim()
```

En esta primera visualizaci√≥n de los datos no se obtiene ning√∫n tipo de dato nulo por lo que no habr√° que hacer ning√∫n tipo de conversion de datos.

#### Analisis de variables

-   [**Variable *over18***]{.hl-bluepastel}

En primer lugar podemos ver que existe una variable denominada **over18** que indica si el trabajador tiene m√°s de 18 a√±os o no. Esta variable normalmente ser√≠a dicot√≥mica por su propia definici√≥n pero podemos observar que solo tiene un valor.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> 
  mutate(over18 = ifelse(over18 == "Y","Yes","No")) |> 
  group_by(over18) |> 
  summarise(nOver18 = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = over18, y = nOver18, fill = over18))  + geom_col(position = "dodge", alpha = 0.8) + geom_text(aes(label = paste(nOver18," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,2000) + scale_fill_manual(values = c("#4ec475")) + labs(title = "Distribuci√≥n de la variable over18")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None")
```

Por lo que podemos deducir que es una variable que no aporta valor predictivo ni anal√≠tico y por tanto se puede eliminar de nuestro dataset.

```{r}
#| code-fold: false
#| message: false
#| warning: false
#| 
dataset_attrition = select(dataset_attrition, -over18)
```

-   [**Variable *employeecount***]{.hl-bluepastel}

Esta variable representa el n√∫mero de empleados por fila dentro del dataset, es una variable redundante ya que por fila solo habr√° un empleado dentro de nuestros datos y por tanto no nos aporta ning√∫n tipo de informaci√≥n por lo que puede ser eliminada.

```{r}
#| code-fold: false
#| message: false
#| warning: false
#| 
dataset_attrition = select(dataset_attrition, -employeecount)
```

-   [**Variable *standardhours***]{.hl-bluepastel}

Esta variable representa el n√∫mero de horas que trabaja un empleado cada dos semanas. Es un valor constante para todos los empleados por lo que al igual que en los dos casos anteriores, no aporta valor ni predictivo ni anal√≠tico y se puede eliminar.

```{r}
#| code-fold: false
#| message: false
#| warning: false
#| 
dataset_attrition = select(dataset_attrition, -standardhours)
```

-   [**Variable *overtime***]{.hl-bluepastel}

La variable denominada **overtime** indica si el empleado ha trabajado horas extras o no. Inicialmente la variable es de tipo char con dos valores diferentes que son **Yes** y **No**, por lo que se trata de una variable dicot√≥mica.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> 
  group_by(overtime) |> 
  summarise(nOvertime = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = overtime, y = nOvertime, fill = overtime))  + geom_col(position = "dodge", alpha = 0.8) + geom_text(aes(label = paste(nOvertime," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,1300) + labs(title = "Distribuci√≥n de la variable overtime")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None")
```

Se va a realizar una transformaci√≥n de tal forma que las variables dicot√≥micas queden representadas con valores **1-Yes** y **0-No**.

```{r}
#| code-fold: false
#| message: false
#| warning: false
#| 
dataset_attrition <- dataset_attrition |> mutate(overtime = ifelse(overtime == "Yes",1,0))
```

-   [**Variable *maritalstatus***]{.hl-bluepastel}

La variable denominada **maritalstatus** indica el estado civil del empleado, concretamente puede ser **Single**, **Married** o **Divorced**. Se va a estudiar si esta variable puede llegar a ser simplificada a una variable dicot√≥mica en la que se exprese √∫nicamente si el empleado est√° casado o no.

En primer lugar vamos a ver si existe alguna variable que tenga pocos datos y por tanto pueda juntarse con otra, por ejemplo juntar **Single** con **Divorced** ya que no tendr√≠an pareja.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> 
  group_by(maritalstatus) |> 
  summarise(nMaritalStatus = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = maritalstatus, y = nMaritalStatus, fill = maritalstatus))  + geom_col(position = "dodge", alpha = 0.8) + geom_text(aes(label = paste(nMaritalStatus," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,1300) + labs(title = "Distribuci√≥n de la variable maritalstatus")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None")
```

Observamos que la distribuci√≥n de esta variable no muestra ning√∫n desbalance en los datos por lo que de momento no se podr√° hacer la operaci√≥n de juntar los campos mencionados anteriormente.

**Vamos a relacionar maritalstatus con la variable objetivo para buscar si se podr√≠a hacer esta agrupaci√≥n.**

Viendo la relaci√≥n que se establece entre la variable del abandono del trabajo (variable objetivo) y el estado civil, se va a poder deducir finalmente si la variable podr√≠a modificarse o no a una dicot√≥mica que represente si el empleado tiene o no pareja.

```{r}
#| code-fold: true
#| message: false
#| warning: false
# Apuntamos tasas
attrition_married <-  round(min(dataset_attrition |> group_by(maritalstatus) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(maritalstatus == "Married" & attrition == "1") |> select(attrition_ratio)),2)

attrition_single <-  round(min(dataset_attrition |> group_by(maritalstatus) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(maritalstatus == "Single" & attrition == "1") |> select(attrition_ratio)),2)

attrition_divorced <-  round(min(dataset_attrition |> group_by(maritalstatus) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(maritalstatus == "Divorced" & attrition == "1") |> select(attrition_ratio)),2)


dataset_attrition |> group_by(maritalstatus) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |>
ggplot(aes(x = maritalstatus, y = attrition_ratio, fill = attrition))+
geom_col()+
coord_flip()+
annotate("text", x = 2, y= 11, label= paste(attrition_married,"%", sep =""),size = 4 ,fontface = "bold") + 
annotate("text", x = 3, y= 11, label= paste(attrition_single,"%", sep =""),size = 4 ,fontface = "bold") + 
annotate("text", x = 1, y= 11, label= paste(attrition_divorced,"%", sep =""),size = 4 ,fontface = "bold") +
theme_minimal()+
theme(axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.y = element_text(size = 12, face = "bold"),
      legend.position = "None"
      )


```

Se puede apreciar que la variable **Single** no tiene un porcentaje parecido a la de **Divorced** por lo que es mejor mantener separadas estas variables ya que aportan una informaci√≥n diferente.

La mayor tasa de abandono del trabajo en funci√≥n del estado civil se da cuando el empleado est√° soltero sin haberse casado anteriormente.

-   [**Variable *jobrole***]{.hl-bluepastel}

La variable denominada **jobrole** representa el rol actual que cumple el empleado dentro de la empresa. Se trata de una variable que deber√° ser convertida a categ√≥rica m√°s adelante tras visualizar el resto de datos. Los valores que puede tomar son **Nurse**,**Therapist**,**Administrative**,**Admin** y **Other**.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> 
  group_by(jobrole) |> 
  summarise(njobrole = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = jobrole, y = njobrole, fill = jobrole))  + geom_col(position = "dodge", alpha = 0.8) + geom_text(aes(label = paste(njobrole," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,1300) + labs(title = "Distribuci√≥n de la variable jobrole")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None")
```

Se va a estudiar si los datos categorizados como **Admin** y como **Administrative** pueden llegar a representar el mismo tipo de empleado.

En primer lugar se va a calcular el salario medio por rol para contemplar si los salarios son parecidos, en caso de serlos, podr√≠amos seguir con la hip√≥tesis de que se trata del mismo rol.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> 
  filter(jobrole %in% c("Administrative", "Admin", "Nurse", "Other","Therapist")) |> 
  group_by(jobrole) |> 
  summarise(
    avg_salary = mean(monthlyincome, na.rm = TRUE)
  ) |> ggplot(aes(x = jobrole, y = avg_salary, fill = avg_salary)) +
geom_col(position = "dodge", alpha = 0.8) +
ylim(0,18000) +
labs(title = "Salario medio por rol",
     subtitle = "Salario medio de los empleados por los diferentes roles dentro de la empresa")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None")
```

Como observamos en el gr√°fico nuestras dos categor√≠as muestran un **salario medio similar** por lo que vamos a seguir con el an√°lisis.

En este caso lo que vamos a hacer es estudiar si se mantienen similares los porcentajes de los departamentos o campos en los que el empleado trabaja dependiendo de si su rol es **Admin** o **Administrative**

```{r}
#| code-fold: true
#| message: false
#| warning: false

admin_departments <- dataset_attrition |> group_by(department) |> count(jobrole) |> filter(jobrole == "Admin") |>
   ungroup() |> mutate(percentage = (n / sum(n)) * 100)

plot1 <- ggplot(admin_departments, aes(x = department, y = percentage, fill = department)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Admin por departamento (%)"
  ) +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  theme_minimal() +
  theme(
     axis.title.y = element_blank(),
     axis.title.x =element_blank(),
     legend.position = "none")

administrative_departments <- dataset_attrition |> group_by(department) |> count(jobrole) |> filter(jobrole == "Administrative") |> ungroup() |> mutate(percentage = (n / sum(n)) * 100)

plot2 <- ggplot(administrative_departments, aes(x = department, y = percentage, fill = department)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Administrativo por departamento (%)"
  ) +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  theme_minimal() +
  theme(
     axis.title.y = element_blank(),
     axis.title.x =element_blank(),
     legend.position = "none")

grid.arrange(plot1, plot2, ncol = 2)

```

Con estos gr√°ficos podemos observar que los porcentajes de **Admin** y **Administrative** en los diferentes departamentos o campos de trabajo son similares, por lo que sumado a una media de salario similar podemos llegar a deducir que la categor√≠a **Admin** se puede comportar como **Administrative**

```{r}
#| code-fold: false
#| message: false
#| warning: false

dataset_attrition <- dataset_attrition |> mutate(jobrole = ifelse(jobrole == "Admin","Administrative", jobrole))
```

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> 
  group_by(jobrole) |> 
  summarise(njobrole = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = jobrole, y = njobrole, fill = jobrole))  + geom_col(position = "dodge", alpha = 0.8) + geom_text(aes(label = paste(njobrole," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,1300) + labs(title = "Distribuci√≥n de la variable jobrole modificada")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None")
```

-   [**Variable *businesstravel***]{.hl-bluepastel}

La variable businesstravel representa la frecuencia de viajes de negocios de los distintos empleados de la compa√±√≠a. Existen tres categor√≠as **Travel_Rarely**, **Non_Travel** y por √∫ltimo **Travel_Frecuently**

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> 
  group_by(businesstravel) |> 
  summarise(nBusinessTravel = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = businesstravel, y = nBusinessTravel, fill = businesstravel))  + geom_col(position = "dodge", alpha = 0.8) + geom_text(aes(label = paste(nBusinessTravel," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,1200) + labs(title = "Distribuci√≥n de la variable businesstravel")+
theme_minimal()+
theme(plot.title = element_text(size = 15, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None")
```

Observando las diferentes categor√≠as podemos deducir que se pueden simplificar los datos a viaja o no viaja el empleado. Esto convertir√° la variable en dicot√≥mica.

```{r}
#| code-fold: false
#| message: false
#| warning: false

dataset_attrition <- dataset_attrition |> mutate(businesstravel = ifelse(businesstravel == "Non-Travel",0,1))
```

Por tanto obtendremos la variable **businesstravel** con dos valores posibles, **0** cuando no viaje y **1** cuando el empleado viaje.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> 
  group_by(businesstravel) |> 
  summarise(nBusinessTravel = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = as.factor(businesstravel), y = nBusinessTravel, fill = as.factor(businesstravel))) +
  geom_col(position = "dodge", alpha = 1) +
  geom_text(aes(label = paste(nBusinessTravel," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,1600) +
  labs(title = "Distribuci√≥n de la variable businesstravel modificada") +
theme_minimal()+
theme(plot.title = element_text(size = 15, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None")
```

-   [**Variable *educationfield***]{.hl-bluepastel}

Esta variable representa el campo en el que se ha formado el empleado. Inicialmente existen diferentes categor√≠as **Human Resources**, **Marketing**, **Life Sciences**, **Medical**, **Technical Degree** y **Other**.

En primer lugar vamos a visualizar como queda distribuida esta variable en funci√≥n de las categor√≠as iniciales.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> 
  group_by(educationfield) |> 
  summarise(neducationfield = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = educationfield, y = neducationfield, fill = educationfield))  + geom_col(position = "dodge", alpha = 0.8) + geom_text(aes(label = paste(neducationfield," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,1200) + labs(title = "Distribuci√≥n de la variable educationfield")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 9, face = "bold"),
      legend.position = "None")
```

Todas estas categor√≠as representan diferentes √°mbitos dentro del mundo laboral y formativo, pero pueden ser **agrupadas de una forma m√°s simple**. Esta forma es el **tipo de ciencia o itinerario** al que pertenecen.

Por ejemplo, las personas formadas en **Recursos Humanos** y **Marketing**, comparten su formaci√≥n en ciencias sociales ya que para cursar grados o ciclos formativos de estos estudios se necesita normalmente formaci√≥n previa en un itinerario orientado a las ciencias sociales.

Ocurre lo mismo con las categor√≠as **Medical** y **Life Sciences**. Estas pueden juntarse en una sola categor√≠a ya que a pesar de la amplitud del campo de la medicina, esta sigue siendo parte de las ciencias biol√≥gicas.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition <- dataset_attrition |> 
  mutate(educationfield = case_when(
    educationfield %in% c("Human Resources", "Marketing") ~ "Social sciences",
    educationfield %in% c("Life Sciences", "Medical") ~ "Life sciences",
    educationfield == "Technical Degree" ~ "Technological sciences",
    TRUE ~ educationfield # Mantener el resto como est√°n (other)
  ))
```

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> 
  group_by(educationfield) |> 
  summarise(neducationfield = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = educationfield, y = neducationfield, fill = educationfield))  + geom_col(position = "dodge", alpha = 0.8) + geom_text(aes(label = paste(neducationfield," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,1250) + labs(title = "Distribuci√≥n de la variable educationfield modificada")+
theme_minimal()+
theme(plot.title = element_text(size = 16, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 10, face = "bold"),
      legend.position = "None")
```

Por √∫ltimo se van a analizar las variables restantes de tipo character [***gender y department***]{.hl-bluepastel}

Estas variables tienen representatividad en sus diferentes niveles por lo que no van a sufrir ning√∫n tipo de modificaci√≥n.

```{r}
#| code-fold: true
#| message: false
#| warning: false

plot_gender <- dataset_attrition |> 
  group_by(gender) |> 
  summarise(nGender = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = gender, y = nGender, fill = gender))  + geom_col(position = "dodge", alpha = 0.8) + geom_text(aes(label = paste(nGender," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,1000) + labs(title = "Distribuci√≥n de la variable gender")+
theme_minimal()+
theme(plot.title = element_text(size = 12, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 10, face = "bold"),
      legend.position = "None")

plot_department <- dataset_attrition |> 
  group_by(department) |> 
  summarise(nDepartment = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = department, y = nDepartment, fill = department))  + geom_col(position = "dodge", alpha = 0.8) + geom_text(aes(label = paste(nDepartment," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,1000) + labs(title = "Distribuci√≥n de la variable department")+
theme_minimal()+
theme(plot.title = element_text(size = 12, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 10, face = "bold"),
      legend.position = "None")

grid.arrange(plot_gender, plot_department, ncol = 2)

```

A la hora de **analizar las variables num√©ricas** es muy importante tambi√©n **considerar el tratamiento de outliers** en las mismas. Se van a revisar las diferentes variables num√©ricas para conocer aquellas que requieren o no del tratamiento de outliers.

En primer lugar se van a **identificar aquellas variables que no son num√©ricas por definici√≥n**. En nuestro dataset, existen diferentes variables que a pesar de ser num√©ricas representan realmente categor√≠as, estas variables son las siguientes:

-   [**Variable *joblevel***]{.hl-bluepastel}

La variable **joblevel** representa el nivel del empleado en la empresa. Este nivel est√° ligado al escalaf√≥n de la propia empresa. Siendo **1 el nivel m√°s bajo y 5 el m√°s alto**.

Se trata de una variable que realmente no es num√©rica ya que tiene un n√∫mero definido de categor√≠as entre las cuales se pueden mover los diferentes empleados.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> 
  group_by(joblevel) |> 
  summarise(nJobLevel = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = as.factor(joblevel), y = nJobLevel, fill = as.factor(joblevel)))  + geom_col(position = "dodge", alpha = 0.8) + geom_text(aes(label = paste(nJobLevel," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,650) + labs(title = "Distribuci√≥n de la variable joblevel")+
theme_minimal()+
theme(plot.title = element_text(size = 16, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None")
```

-   [**Variable *shift***]{.hl-bluepastel}

La variable **shift** representa los turnos de trabajo de los diferentes empleados. Puede tomar los siguientes valores, **0 - Employees with own schedule**, **1 - 7am to 3:30pm**, **2 - 2pm to 10pm**, **3 - 9pm to 7am**

Se trata de una variable que realmente es categ√≥rica por el mismo motivo que **joblevel**. Por lo que posteriormente tambi√©n se har√° la conversi√≥n de num√©rica a categ√≥rica de esta variable.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> 
  group_by(shift) |> 
  summarise(nShift = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = as.factor(shift), y = nShift, fill = as.factor(shift)))  + geom_col(position = "dodge", alpha = 0.8) + geom_text(aes(label = paste(nShift," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,750) + labs(title = "Distribuci√≥n de la variable shift")+
theme_minimal()+
theme(plot.title = element_text(size = 16, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None")
```

-   [**Variable *education***]{.hl-bluepastel}

La variable **education** representa el nivel educativo los diferentes empleados. Toma valores desde, **1** a **5** siendo este √∫ltimo el mayor nivel educativo de todos.

Se trata de una variable que tambi√©n es categ√≥rica por el mismo motivo que **shift** y que **joblevel**. Por lo que posteriormente se convertir√° a categ√≥rica.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> 
  group_by(education) |> 
  summarise(nEducation = n(), Porc = round(n()*100/nrow(dataset_attrition),2)) |> 
  ggplot(aes(x = as.factor(education), y = nEducation, fill = as.factor(education)))  + geom_col(position = "dodge", alpha = 0.8) + geom_text(aes(label = paste(nEducation," (",Porc,"%)")),colour = "black", size = 3.5,vjust = -0.5)+ ylim(0,750) + labs(title = "Distribuci√≥n de la variable education")+
theme_minimal()+
theme(plot.title = element_text(size = 16, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None")
```

-   [**Variable *age***]{.hl-bluepastel}

La variable **age** representa la edad de los empleados. Se trata de una variable n√∫merica.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> ggplot( aes(x=as.factor(1), y=age, fill = "#023047" )) +
              geom_violin(width = 1) +
              stat_boxplot(geom = "errorbar", width = 0.15,color = "#C2185B") +
              geom_boxplot(width=0.2, color="#C2185B", alpha = 1 ) +
              scale_fill_manual(values = c("#023047")) +
              labs(title = "Distribuci√≥n variable age", 
                   subtitle = "Gr√°fico de violin y boxplot")+
              theme_minimal()+
              theme(axis.title.y = element_blank(),
                    axis.title.x =element_blank(),
                    axis.text.x = element_blank(),
                    legend.position = "None",
                    plot.title = element_text(size = 20, face = "bold")
                    )
```

Podemos observar que no existen outliers por lo que no se har√° un tratamiento especial de la variable **age**.

-   [**Variables *yearsatcompany*, *yearsincurrentrole*, *yearssincelastpromotion* y *yearswithcurrmanager***]{.hl-bluepastel}

La variable **yearsatcompany** el n√∫mero de a√±os en la compa√±ia de cada empleado.

La variable **yearsincurrentrole** el n√∫mero de a√±os en un rol concreto dentro de la compa√±√≠a de cada empleado.

La variable **yearssincelastpromotion** el n√∫mero de a√±os desde que el empleado recibi√≥ su √∫ltimo ascenso.

La variable **yearswithcurrmanager** el n√∫mero de a√±os que lleva trabajando para un jefe concreto.

```{r}
#| code-fold: true
#| message: false
#| warning: false

gg_yearsatcompany <- dataset_attrition |> ggplot( aes(x=as.factor(1), y=yearsatcompany, fill = "#023047" )) +
              geom_violin(width = 1) +
              stat_boxplot(geom = "errorbar", width = 0.15,color = "#C2185B") +
              geom_boxplot(width=0.2, color="#C2185B", alpha = 1 ) +
              scale_fill_manual(values = c("#023047")) +
              labs(title = "Distribuci√≥n variable yearsatcompany")+
              theme_minimal()+
              theme(axis.title.y = element_blank(),
                    axis.title.x =element_blank(),
                    axis.text.x = element_blank(),
                    legend.position = "None",
                    plot.title = element_text(size = 12, face = "bold")
                    )

gg_yearsincurrentrole <- dataset_attrition |> ggplot( aes(x=as.factor(1), y=yearsincurrentrole, fill = "#023047" )) +
              geom_violin(width = 1) +
              stat_boxplot(geom = "errorbar", width = 0.15,color = "#C2185B") +
              geom_boxplot(width=0.2, color="#C2185B", alpha = 1 ) +
              scale_fill_manual(values = c("#023047")) +
              labs(title = "Distribuci√≥n variable yearsincurrentrole")+
              theme_minimal()+
              theme(axis.title.y = element_blank(),
                    axis.title.x =element_blank(),
                    axis.text.x = element_blank(),
                    legend.position = "None",
                    plot.title = element_text(size = 12, face = "bold")
                    )

gg_yearssincelastpromotion <- dataset_attrition |> ggplot( aes(x=as.factor(1), y=yearssincelastpromotion, fill = "#023047" )) +
              geom_violin(width = 1) +
              stat_boxplot(geom = "errorbar", width = 0.15,color = "#C2185B") +
              geom_boxplot(width=0.2, color="#C2185B", alpha = 1 ) +
              scale_fill_manual(values = c("#023047")) +
              labs(title = "Distribuci√≥n variable yearssincelastpromotion")+
              theme_minimal()+
              theme(axis.title.y = element_blank(),
                    axis.title.x =element_blank(),
                    axis.text.x = element_blank(),
                    legend.position = "None",
                    plot.title = element_text(size = 10, face = "bold")
                    )

gg_yearswithcurrmanager <- dataset_attrition |> ggplot( aes(x=as.factor(1), y=yearswithcurrmanager, fill = "#023047" )) +
              geom_violin(width = 1) +
              stat_boxplot(geom = "errorbar", width = 0.15,color = "#C2185B") +
              geom_boxplot(width=0.2, color="#C2185B", alpha = 1 ) +
              scale_fill_manual(values = c("#023047")) +
              labs(title = "Distribuci√≥n variable yearswithcurrmanager")+
              theme_minimal()+
              theme(axis.title.y = element_blank(),
                    axis.title.x =element_blank(),
                    axis.text.x = element_blank(),
                    legend.position = "None",
                    plot.title = element_text(size = 10, face = "bold")
                    )

ggarrange(gg_yearsatcompany,gg_yearsincurrentrole,gg_yearssincelastpromotion,gg_yearswithcurrmanager, ncol=2, nrow = 2, common.legend = TRUE, legend = "none")

```

Observando todas las gr√°ficas vemos como todas las variables tienen una **distribuci√≥n asim√©trica** con presencia de outliers que se van a tratar posteriormente.

-   [**Variable *distancefromhome***]{.hl-bluepastel}

La variable **distancefromhome** es una variable num√©rica que representa la distancia que tiene cada empleado desde su casa hasta el trabajo.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> ggplot( aes(x=as.factor(1), y=distancefromhome, fill = "#023047" )) +
              geom_violin(width = 1) +
              stat_boxplot(geom = "errorbar", width = 0.15,color = "#C2185B") +
              geom_boxplot(width=0.2, color="#C2185B", alpha = 1 ) +
              scale_fill_manual(values = c("#023047")) +
              labs(title = "Distribuci√≥n variable distancefromhome")+
              theme_minimal()+
              theme(axis.title.y = element_blank(),
                    axis.title.x =element_blank(),
                    axis.text.x = element_blank(),
                    legend.position = "None",
                    plot.title = element_text(size = 20, face = "bold")
                    )
```

Se observa en la gr√°fica de distribuci√≥n de **distancefromhome** como existe asimetr√≠a en la distribuci√≥n de la variable. A pesar de esta asimetr√≠a, no existen outliers por lo que no se deber√° hacer un tratamiento especial de esta variable.

-   [**Variable *monthlyincome***]{.hl-bluepastel}

La variable **monthlyincome** es una variable num√©rica que representa el sueldo mensual de cada empleado.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition |> ggplot( aes(x=as.factor(1), y=monthlyincome, fill = "#023047" )) +
              geom_violin(width = 1) +
              stat_boxplot(geom = "errorbar", width = 0.15,color = "#C2185B") +
              geom_boxplot(width=0.2, color="#C2185B", alpha = 1 ) +
              scale_fill_manual(values = c("#023047")) +
              labs(title = "Distribuci√≥n variable monthlyincome")+
              theme_minimal()+
              theme(axis.title.y = element_blank(),
                    axis.title.x =element_blank(),
                    axis.text.x = element_blank(),
                    legend.position = "None",
                    plot.title = element_text(size = 20, face = "bold")
                    )
```

Observamos que existen outliers en esta variable as√≠ como asimetr√≠a de su distribuci√≥n por lo que si que se llevar√° a cabo un tratamiento de outliers.

-   [**Variable *numcompaniesworked***]{.hl-bluepastel}

La variable **numcompaniesworked** es una variable num√©rica que representa el n√∫mero de compa√±√≠as en las que ha trabajado un empleado.

```{r}
dataset_attrition |> ggplot( aes(x=as.factor(1), y=numcompaniesworked, fill = "#023047" )) +
              geom_violin(width = 1) +
              stat_boxplot(geom = "errorbar", width = 0.15,color = "#C2185B") +
              geom_boxplot(width=0.2, color="#C2185B", alpha = 1 ) +
              scale_fill_manual(values = c("#023047")) +
              labs(title = "Distribuci√≥n variable numcompaniesworked")+
              theme_minimal()+
              theme(axis.title.y = element_blank(),
                    axis.title.x =element_blank(),
                    axis.text.x = element_blank(),
                    legend.position = "None",
                    plot.title = element_text(size = 20, face = "bold")
                    )
```

Con la distribuci√≥n de la variable **numcompaniesworked** podemos detectar que hay asimetr√≠a y que adem√°s existen ciertos valores outlier.

-   [**Variable *percentsalaryhike***]{.hl-bluepastel}

La variable **percentsalaryhike** es una variable num√©rica que representa el porcentaje de salario que ha aumentado en la subida de sueldo m√°s reciente de un empleado.

```{r}
dataset_attrition |> ggplot( aes(x=as.factor(1), y=percentsalaryhike, fill = "#023047" )) +
              geom_violin(width = 1) +
              stat_boxplot(geom = "errorbar", width = 0.15,color = "#C2185B") +
              geom_boxplot(width=0.2, color="#C2185B", alpha = 1 ) +
              scale_fill_manual(values = c("#023047")) +
              labs(title = "Distribuci√≥n variable percentsalaryhike")+
              theme_minimal()+
              theme(axis.title.y = element_blank(),
                    axis.title.x =element_blank(),
                    axis.text.x = element_blank(),
                    legend.position = "None",
                    plot.title = element_text(size = 20, face = "bold")
                    )
```

Observamos asimetr√≠a en los datos, pero en este caso no detectamos outliers por lo que no se har√° un tratamiento especial de la variable **percentsalaryhike**

-   [**Variables *totalworkingyears* y *trainingtimeslastyear***]{.hl-bluepastel}

La variable **totalworkingyears** representa el n√∫mero total de a√±os trabajados de cada empleado. Se trata de una variable num√©rica.

La variable **trainingtimeslastyear** se trata de el n√∫mero de d√≠as destinados a charlas, cursos ... de un empleado en el anterior a√±o laboral.

```{r}
#| code-fold: true
#| message: false
#| warning: false

gg_totalworkingyears <- dataset_attrition |> ggplot( aes(x=as.factor(1), y=totalworkingyears, fill = "#023047" )) +
              geom_violin(width = 1) +
              stat_boxplot(geom = "errorbar", width = 0.15,color = "#C2185B") +
              geom_boxplot(width=0.2, color="#C2185B", alpha = 1 ) +
              scale_fill_manual(values = c("#023047")) +
              labs(title = "Distribuci√≥n variable totalworkingyears")+
              theme_minimal()+
              theme(axis.title.y = element_blank(),
                    axis.title.x =element_blank(),
                    axis.text.x = element_blank(),
                    legend.position = "None",
                    plot.title = element_text(size = 12, face = "bold")
                    )

gg_trainingtimeslastyear <- dataset_attrition |> ggplot( aes(x=as.factor(1), y=trainingtimeslastyear, fill = "#023047" )) +
              geom_violin(width = 1) +
              stat_boxplot(geom = "errorbar", width = 0.15,color = "#C2185B") +
              geom_boxplot(width=0.2, color="#C2185B", alpha = 1 ) +
              scale_fill_manual(values = c("#023047")) +
              labs(title = "Distribuci√≥n variable trainingtimeslastyear")+
              theme_minimal()+
              theme(axis.title.y = element_blank(),
                    axis.title.x =element_blank(),
                    axis.text.x = element_blank(),
                    legend.position = "None",
                    plot.title = element_text(size = 12, face = "bold")
                    )

ggarrange(gg_totalworkingyears,gg_trainingtimeslastyear, ncol=2, common.legend = TRUE, legend = "none")
```

Con esta gr√°fica podemos deducir que la distribuci√≥n de **totalworkingyears** presenta asimetr√≠a y valores outliers.

Por otro lado la distribuci√≥n de **trainingtimelastyear** es sim√©trica aunque observamos que los valores bajos tienen mucha mayor variabilidad respecto a la mediana. En esta gr√°fica tambi√©n encontramos ciertos valores outliers por lo que se deber√° hacer un tratamiento de esta variable de la misma forma que de **totalworkingyears**.

#### Relaci√≥n de variables con la variable objetivo

-   [**Variable *gender***]{.hl-bluepastel}

Las tasas de abandono del puesto laboral en funci√≥n de la variable **gender** son las siguientes:

```{r}
#| code-fold: true
#| message: false
#| warning: false

attrition_male <- round(min(dataset_attrition |> group_by(gender) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(gender == "Male" & attrition == "1") |> select(attrition_ratio)),2)

attrition_female <- round(min(dataset_attrition |> group_by(gender) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(gender == "Female" & attrition == "1") |> select(attrition_ratio)),2)


dataset_attrition |> group_by(gender) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |>
ggplot(aes(x = gender, y = attrition_ratio, fill = attrition))+
geom_col()+
coord_flip()+
annotate("text", x = 1, y= 20, label= paste(attrition_female,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 2, y= 20, label= paste(attrition_male,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
labs(title = "Gender employee attrition (%)")+
theme_minimal()+
theme(axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.y = element_text(size = 12, face = "bold"),
      legend.position = "None",
      plot.title = element_text(size = 12, face = "bold")
      )
```

Podemos observar como existe una mayor tasa de abandono laboral por parte de las mujeres (la tasa en mujeres supone un 12.01% de diferencia respecto a los hombres).

Otro aspecto interesante a observar en funci√≥n de nuestra variable objetivo puede ser el departamento. As√≠ se podr√° conocer el departamento en el que m√°s abandono laboral se produce dentro de la empresa.

-   [**Variable *businesstravel***]{.hl-bluepastel}

En primer lugar vamos a categorizar la variable **businesstravel**:

```{r}
dataset_attrition$businesstravel <- as.factor(dataset_attrition$businesstravel)
```

Las tasas de abandono del puesto laboral en funci√≥n de la variable **businesstravel** son las siguientes:

```{r}
#| code-fold: true
#| message: false
#| warning: false

attrition_not_travel <- round(min(dataset_attrition |> group_by(businesstravel) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(businesstravel == "0" & attrition == "1") |> select(attrition_ratio)),2)

attrition_travel <- round(min(dataset_attrition |> group_by(businesstravel) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(businesstravel == "1" & attrition == "1") |> select(attrition_ratio)),2)


dataset_attrition |> group_by(businesstravel) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |>
ggplot(aes(x = businesstravel, y = attrition_ratio, fill = attrition))+
geom_col()+
annotate("text", x = 1, y= 20, label= paste(attrition_not_travel,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 2, y= 20, label= paste(attrition_travel,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
labs(title = "Businesstravel employee attrition (%)")+
theme_minimal()+
theme(axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.y = element_text(size = 12, face = "bold"),
      legend.position = "None",
      plot.title = element_text(size = 12, face = "bold")
      )
```

Existe un mayor abandono laboral en los empleados que realizan viajes (12,17%) que en los que no realizan ning√∫n tipo de viaje (9.3%)

-   [**Variable *department***]{.hl-bluepastel}

Para relacionar la variable **department** con la variable objetivo simplemente se va a filtrar en funci√≥n de los diferentes departamentos de la empresa.

En este punto convertiremos ya la variable **department** a categ√≥rica.

```{r}
dataset_attrition$department <- as.factor(dataset_attrition$department)
```

```{r}
#| code-fold: true
#| message: false
#| warning: false

attrition_Cardiology <- round(min(dataset_attrition |> group_by(department) |> count(attrition) |> mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(department == "Cardiology" & attrition == "1") |> select(attrition_ratio)),2)

attrition_Maternity <- round(min(dataset_attrition |> group_by(department) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(department == "Maternity" & attrition == "1") |> select(attrition_ratio)),2)

attrition_Neurology <- round(min(dataset_attrition |> group_by(department) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(department == "Neurology" & attrition == "1") |> select(attrition_ratio)),2)

dataset_attrition |> group_by(department) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |>
ggplot(aes(x = department, y = attrition_ratio, fill = attrition))+
geom_col()+
coord_flip()+
annotate("text", x = 1, y= 20, label= paste(attrition_Cardiology,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 2, y= 20, label= paste(attrition_Maternity,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 3, y= 20, label= paste(attrition_Neurology,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
labs(title = "Department employee attrition (%)")+
theme_minimal()+
theme(axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.y = element_text(size = 12, face = "bold"),
      legend.position = "None",
      plot.title = element_text(size = 12, face = "bold")
      )
```

El departamento en el que m√°s abandono laboral se produce es el de **cardiolog√≠a** y en el que menos con bastante diferencia es el de **neurolog√≠a**. Por lo que interpretando estos datos, podr√≠a haber peores condiciones laborales en el departamento de cardiolog√≠a.

Por √∫ltimo, respecto a las variables que originalmente eran de tipo character, se va a observar tambi√©n la relaci√≥n de la variable objetivo con la variable **overtime**

-   [**Variable *educationfield, jobrole y maritalstatus***]{.hl-bluepastel}

Se van a relacionar con nuestra variable objetivo las variables **educationfield**, **jobrole** y **maritalstatus**.

```{r}
#| code-fold: true
#| message: false
#| warning: false


attrition_lsciences <-  round(min(dataset_attrition |> group_by(educationfield) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(educationfield == 'Life sciences' & attrition == 1) |> select(attrition_ratio)),2)

attrition_other <-  round(min(dataset_attrition |> group_by(educationfield) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(educationfield == 'Other' & attrition == 1) |> select(attrition_ratio)),2)

attrition_ssciences <-  round(min(dataset_attrition |> group_by(educationfield) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(educationfield == 'Social sciences' & attrition == 1) |> select(attrition_ratio)),2)

attrition_tsciences <-  round(min(dataset_attrition |> group_by(educationfield) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(educationfield == 'Technological sciences' & attrition == 1) |> select(attrition_ratio)),2)




dataset_attrition |> group_by(educationfield) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |>
ggplot(aes(x = as.factor(educationfield), y = attrition_ratio, fill = attrition))+
geom_col()+
labs(title = "Educationfield employee attrition (%)") + 
annotate("text", x = 1, y= 20, label= paste(attrition_lsciences,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 2, y= 20, label= paste(attrition_other,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") +
annotate("text", x = 3, y= 20, label= paste(attrition_ssciences,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 4, y= 20, label= paste(attrition_tsciences,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") +
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
theme_minimal()+
theme(axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 10, face = "bold"),
      legend.position = "None",
      plot.title = element_text(size = 12, face = "bold")
      )

```

En cuanto a la variable **educationfield** es destacable que los campos con m√°s tasa de abandono laboral son las ciencias sociales y las ciencias tecnol√≥gicas.

```{r}
#| code-fold: true
#| message: false
#| warning: false

attrition_admin <-  round(min(dataset_attrition |> group_by(jobrole) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(jobrole == 'Administrative' & attrition == 1) |> select(attrition_ratio)),2)

attrition_nurse <-  round(min(dataset_attrition |> group_by(jobrole) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(jobrole == 'Nurse' & attrition == 1) |> select(attrition_ratio)),2)

attrition_other <-  round(min(dataset_attrition |> group_by(jobrole) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(jobrole == 'Other' & attrition == 1) |> select(attrition_ratio)),2)

attrition_therapist <-  round(min(dataset_attrition |> group_by(jobrole) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(jobrole == 'Therapist' & attrition == 1) |> select(attrition_ratio)),2)


dataset_attrition |> group_by(jobrole) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |>
ggplot(aes(x = as.factor(jobrole), y = attrition_ratio, fill = attrition))+
geom_col()+
labs(title = "Jobrole employee attrition (%)") + 
annotate("text", x = 1, y= 20, label= paste(attrition_admin,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 2, y= 20, label= paste(attrition_nurse,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") +
annotate("text", x = 3, y= 20, label= paste(attrition_other,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 4, y= 20, label= paste(attrition_therapist,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") +
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
theme_minimal()+
theme(axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 10, face = "bold"),
      legend.position = "None",
      plot.title = element_text(size = 12, face = "bold")
      )
```

Por otro lado, en la variable **jobrole**, es muy destacable que los administrativos y terapeutas no tienen casi tasa de abandono laboral pero puestos como enfermera u otros tienen una muy alta tasa.

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
attrition_divorced <-  round(min(dataset_attrition |> group_by(maritalstatus) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(maritalstatus == 'Divorced' & attrition == 1) |> select(attrition_ratio)),2)

attrition_married <-  round(min(dataset_attrition |> group_by(maritalstatus) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(maritalstatus == 'Married' & attrition == 1) |> select(attrition_ratio)),2)

attrition_single <-  round(min(dataset_attrition |> group_by(maritalstatus) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(maritalstatus == 'Single' & attrition == 1) |> select(attrition_ratio)),2)


dataset_attrition |> group_by(maritalstatus) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |>
ggplot(aes(x = as.factor(maritalstatus), y = attrition_ratio, fill = attrition))+
geom_col()+
labs(title = "Maritalstatus employee attrition (%)") + 
annotate("text", x = 1, y= 20, label= paste(attrition_divorced,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 2, y= 20, label= paste(attrition_married,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") +
annotate("text", x = 3, y= 30, label= paste(attrition_single,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
theme_minimal()+
theme(axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 10, face = "bold"),
      legend.position = "None",
      plot.title = element_text(size = 12, face = "bold")
      )

```

Podemos bservamos en la variable **maritalstatus** que las personas solteras son las que mayor tasa de abandono tienen (21.84%). Esto puede indicar que son personas que no necesitan tanta estabilidad laboral como personas que est√°n casadas o divorciadas.

-   [**Variable *overtime***]{.hl-bluepastel}

Convertimos inicialmente la variable **overtime** a categ√≥rica.

```{r}
dataset_attrition$overtime <- as.factor(dataset_attrition$overtime)
```

```{r}
#| code-fold: true
#| message: false
#| warning: false

attrition_ovty <- round(min(dataset_attrition |> group_by(overtime) |> count(attrition) |> mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(overtime == "1" & attrition == "1") |> select(attrition_ratio)),2)

attrition_ovtn <- round(min(dataset_attrition |> group_by(overtime) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(overtime == "0" & attrition == "1") |> select(attrition_ratio)),2)

dataset_attrition |> group_by(overtime) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |>
ggplot(aes(x = overtime, y = attrition_ratio, fill = attrition))+
geom_col()+
annotate("text", x = 2, y= 40, label= paste(attrition_ovty,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 1, y= 20, label= paste(attrition_ovtn,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
labs(title = "Overtime employee attrition (%)")+
theme_minimal()+
theme(axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None",
      plot.title = element_text(size = 12, face = "bold")
      )
```

Los empleados que trabajan horas extra tienen una tasa de abandono laboral que supone un 484% de diferencia respecto a los empleados que no realizan horas extra por lo que podemos ver que es un factor muy clave en el abandono laboral.

-   [**Variable *age***]{.hl-bluepastel}

Para relacionar la variable **age** con nuestra variable objetivo se van a realizar varias particiones en tramos.

El primer tramo ser√° de **18 a 25 a√±os**, el segundo tramo de **25 a 35 a√±os**, el tercer tramo de **35 a 45 a√±os** y el √∫ltimo tramo desde estos **45 a√±os** hasta la edad m√°xima de nuestro conjunto de datos.

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
max_age <- max(dataset_attrition$age, na.rm = TRUE)

dataset_attrition_age <- dataset_attrition |> mutate(age_cat = case_when(age < 25 ~ "[18 - 25)",
                                                    age < 35 ~ "[25 - 35)",
                                                    age < 45 ~ "[35 - 45)",
                                                    age <= max_age ~ "[45 - 60]")) |> 
                                      select(age, age_cat, attrition) |> 
                                      group_by(age_cat) |> count(attrition) |>
                                      mutate(attrition_ratio = 100*n/sum(n),
                                      age_cat = factor(age_cat, levels = c("[18 - 25)", "[25 - 35)","[35 - 45)", "[45 - 60]"))
                                        )|> ungroup()

attrition_18_25 <-  round(min(dataset_attrition_age |> filter(age_cat == "[18 - 25)" & attrition == "1") |> select(attrition_ratio)),2)
attrition_25_35 <-  round(min(dataset_attrition_age |> filter(age_cat == "[25 - 35)" & attrition == "1") |> select(attrition_ratio)),2)
attrition_35_45 <-  round(min(dataset_attrition_age |> filter(age_cat == "[35 - 45)" & attrition == "1") |> select(attrition_ratio)),2)
attrition_45_60 <-  round(min(dataset_attrition_age |> filter(age_cat == "[45 - 60]" & attrition == "1") |> select(attrition_ratio)),2)

dataset_attrition_age |>  ggplot(aes(x = age_cat, y = attrition_ratio, fill = attrition))+
geom_col()+
coord_flip()+
annotate("text", x = 1, y= 70, label= paste(attrition_18_25,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") +
annotate("text", x = 2, y= 70, label= paste(attrition_25_35,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") +
annotate("text", x = 3, y= 25, label= paste(attrition_35_45,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 4, y= 25, label= paste(attrition_45_60,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") +
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
labs(title = "Age employee attrition (%)")+
theme_minimal()+
theme(axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.y = element_text(size = 12, face = "bold"),
      legend.position = "None",
      plot.title = element_text(size = 12, face = "bold")
      )
```

Se puede observar de forma clara como los empleados que van desde los **18 a 25 a√±os** son los que tienen una mayor tasa de abandono laboral y con el paso de los a√±os comienza a reducirse de manera considerable siendo la menor tasa de abandono desde los **45 a√±os** hasta la edad m√°xima de nuestro conjunto de datos.

-   [**Variable *distancefromhome***]{.hl-bluepastel}

Para realizar una correcta visualizaci√≥n de la relaci√≥n entre la variable objetivo y la variable **distancefromhome**, se va a realizar una estratificaci√≥n univariada de Dalenius-Hodges en la cual dividiremos entre varios tramos de distancia desde distancia **'Muy lejana'** hasta **Muy corta**.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition_dist <- dataset_attrition |> mutate(cat_distfromhome = strata.cumrootf(distancefromhome, CV=0.05, Ls = 5)[["stratumID"]]) |> 
mutate(cat_distfromhome = case_when(cat_distfromhome == "5" ~ "Muy lejana",
          cat_distfromhome == "4" ~ "Lejana",
          cat_distfromhome == "3" ~ "Media",
          cat_distfromhome == "2" ~ "Corta",
          TRUE ~ "Muy corta")) |>
arrange(desc(distancefromhome)) |> 
 select(cat_distfromhome, attrition) 


plot_dist_dfromhome <- dataset_attrition_dist |> group_by(cat_distfromhome) |> summarise(n = n(), percentage = round(n()*100.0/nrow(dataset_attrition_dist),2)) |> 
  ggplot(aes(x = factor(cat_distfromhome,levels = c("Muy corta","Corta","Media","Lejana","Muy lejana")), y = n)) +
  geom_col(position = "dodge", alpha =0.8,fill = "#AAEAAA") +
  geom_text(aes(label = paste(n," (",percentage,"%)", sep ="")), colour = "#A4185B", size = 3,vjust = 0,hjust =1.2, angle = 90,  position = position_dodge(.9)) +
  theme_minimal()+
  theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 10, angle = 90, face =  "bold"),
      legend.position = "None"
      )


attr_1 <-  round(min(dataset_attrition_dist |> group_by(cat_distfromhome) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_distfromhome == "Muy lejana" & attrition == 1) |> select(attrition_ratio)),2)
attr_2 <-  round(min(dataset_attrition_dist |> group_by(cat_distfromhome) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_distfromhome == "Lejana" & attrition == 1) |> select(attrition_ratio)),2)
attr_3 <-  round(min(dataset_attrition_dist |> group_by(cat_distfromhome) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_distfromhome == "Media" & attrition == 1) |> select(attrition_ratio)),2)
attr_4 <-  round(min(dataset_attrition_dist |> group_by(cat_distfromhome) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_distfromhome == "Corta" & attrition == 1) |> select(attrition_ratio)),2)
attr_5 <-  round(min(dataset_attrition_dist |> group_by(cat_distfromhome) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_distfromhome == "Muy corta" & attrition == 1) |>  select(attrition_ratio)),2)




plot_cat_dfromhome <- dataset_attrition_dist |> group_by(cat_distfromhome) |> count(attrition) |>  mutate(stroke_ratio = 100*n/sum(n)) |>
ggplot(aes(x = factor(cat_distfromhome,levels = c("Muy corta","Corta","Media","Lejana","Muy lejana")), y = stroke_ratio, fill = attrition))+
geom_col()+
annotate("text", x = 1, y= 20, label= paste(attr_5,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 2, y= 20, label= paste(attr_4,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 3, y= 20, label= paste(attr_3,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") +  
annotate("text", x = 4, y= 20, label= paste(attr_2,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") +  
annotate("text", x = 5, y= 25, label= paste(attr_1,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") +  
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 10, angle = 90, face =  "bold"),
      legend.position = "None"
      )

ggarrange(plot_dist_dfromhome, plot_cat_dfromhome, ncol=2)
```

Podemos observar que la mayor√≠a de los empleados viven a una distancia muy corta del trabajo y a medida que esta distancia aumenta el n√∫mero de empleados disminuye. Tamb√≠en es destacable que en la distancia m√°s lejana hay un leve aumento de empleados.

Por otro lado los empleados con **Muy corta** o **Corta** distancia al trabajo tienen una menor tasa de abandono **(9.2% - 9.48%)**. A medida que la distancia aumenta, la tasa de abandono tambi√©n lo hace y los empleados que tienen una **Muy lejana** distancia tienen la mayor tasa de abandono **(20.83%)**, lo que sugiere que una mayor distancia al trabajo podr√≠a estar relacionada con un mayor desgaste y mayor rotaci√≥n laboral.

-   [**Variable *education***]{.hl-bluepastel}

Antes de relacionar **education** con nuestra variable objetivo, convertiremos la variable a categ√≥rica:

```{r}
#| code-fold: true
#| message: false
#| warning: false
dataset_attrition$education = as.factor(dataset_attrition$education)
```

Se va a relacionar la variable **education** mediante un gr√°fico que nos muestra las tasas de abandono por nivel educativo:

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
attrition_ed1 <- round(min(dataset_attrition |> group_by(education) |> count(attrition) |> mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(education == "1" & attrition == "1") |> select(attrition_ratio)),2)

attrition_ed2 <- round(min(dataset_attrition |> group_by(education) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(education == "2" & attrition == "1") |> select(attrition_ratio)),2)

attrition_ed3 <- round(min(dataset_attrition |> group_by(education) |> count(attrition) |> mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(education == "3" & attrition == "1") |> select(attrition_ratio)),2)

attrition_ed4 <- round(min(dataset_attrition |> group_by(education) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(education == "4" & attrition == "1") |> select(attrition_ratio)),2)

attrition_ed5 <- round(min(dataset_attrition |> group_by(education) |> count(attrition) |> mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(education == "5" & attrition == "1") |> select(attrition_ratio)),2)

dataset_attrition |> group_by(education) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |>
ggplot(aes(x = education, y = attrition_ratio, fill = attrition))+
geom_col()+
annotate("text", x = 5, y = 20, label= paste(attrition_ed5,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 4, y = 20, label= paste(attrition_ed4,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
  annotate("text", x = 3, y = 20, label= paste(attrition_ed3,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 2, y = 20, label= paste(attrition_ed2,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
  annotate("text", x = 1, y = 20, label= paste(attrition_ed1,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
labs(title = "Education - employee attrition (%)")+
theme_minimal()+
theme(axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None",
      plot.title = element_text(size = 12, face = "bold")
      )
```

Visualizando la relaci√≥n entre la variable objetivo y nuestros niveles de educaci√≥n recogidos en la variable **education**, podemos deducir que en general que el abandono laboral es bastante similar independientemente del nivel de educaci√≥n, a excepci√≥n de las personas que tienen un muy alto nivel educativo que son las que menor porcentaje de abandono tienen (1.79%)

-   [**Variable *joblevel* y *shift***]{.hl-bluepastel}

Tanto la variable **joblevel** como la variable **shift** se tratan de variables que a pesar de ser n√∫mericas inicialmente, deben de ser tratadas como categ√≥ricas por lo que se van a convertir a categ√≥ricas:

```{r}
#| code-fold: true
#| message: false
#| warning: false
dataset_attrition$joblevel = as.factor(dataset_attrition$joblevel)

dataset_attrition$shift = as.factor(dataset_attrition$shift)
```

Se va a visualizar la relaci√≥n de nuestra variable objetivo con estas dos variables:

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
attrition_jb1 <- round(min(dataset_attrition |> group_by(joblevel) |> count(attrition) |> mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(joblevel == "1" & attrition == "1") |> select(attrition_ratio)),2)

attrition_jb2 <- round(min(dataset_attrition |> group_by(joblevel) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(joblevel == "2" & attrition == "1") |> select(attrition_ratio)),2)

attrition_jb3 <- round(min(dataset_attrition |> group_by(joblevel) |> count(attrition) |> mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(joblevel == "3" & attrition == "1") |> select(attrition_ratio)),2)

attrition_jb4 <- round(min(dataset_attrition |> group_by(joblevel) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(joblevel == "4" & attrition == "1") |> select(attrition_ratio)),2)

attrition_jb5 <- round(min(dataset_attrition |> group_by(joblevel) |> count(attrition) |> mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(joblevel == "5" & attrition == "1") |> select(attrition_ratio)),2)

plot_joblevel <- dataset_attrition |> group_by(joblevel) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |>
ggplot(aes(x = joblevel, y = attrition_ratio, fill = attrition))+
geom_col()+
annotate("text", x = 5, y = 30, label= paste(attrition_jb5,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 4, y = 30, label= paste(attrition_jb4,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
  annotate("text", x = 3, y = 30, label= paste(attrition_jb3,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 2, y = 30, label= paste(attrition_jb2,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
  annotate("text", x = 1, y = 30, label= paste(attrition_jb1,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
labs(title = "Joblevel - employee attrition (%)")+
theme_minimal()+
theme(axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None",
      plot.title = element_text(size = 12, face = "bold")
      )

attrition_s1 <- round(min(dataset_attrition |> group_by(shift) |> count(attrition) |> mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(shift == "0" & attrition == "1") |> select(attrition_ratio)),2)

attrition_s2 <- round(min(dataset_attrition |> group_by(shift) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(shift == "1" & attrition == "1") |> select(attrition_ratio)),2)

attrition_s3 <- round(min(dataset_attrition |> group_by(shift) |> count(attrition) |> mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(shift == "2" & attrition == "1") |> select(attrition_ratio)),2)

attrition_s4 <- round(min(dataset_attrition |> group_by(shift) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> filter(shift == "3" & attrition == "1") |> select(attrition_ratio)),2)

plot_shift <- dataset_attrition |> group_by(shift) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |>
ggplot(aes(x = shift, y = attrition_ratio, fill = attrition))+
geom_col()+
annotate("text", x = 4, y = 30, label= paste(attrition_s4,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
  annotate("text", x = 3, y = 30, label= paste(attrition_s3,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 2, y = 30, label= paste(attrition_s2,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
  annotate("text", x = 1, y = 30, label= paste(attrition_s1,"%", sep =""),size = 4 , color = "#A4185B",fontface = "bold") + 
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
labs(title = "Shift - employee attrition (%)")+
theme_minimal()+
theme(axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12, face = "bold"),
      legend.position = "None",
      plot.title = element_text(size = 12, face = "bold")
      )

ggarrange(plot_joblevel, plot_shift, ncol=2)
```

En el **joblevel** podemos detectar como la gente que menos nivel tiene dentro de la propia empresa es la m√°s propensa a abandonar el trabajo y conforme suben de nivel se va reduciendo hasta una tasa muy inferior a la inicial como es 2.47%

En cuanto a los turnos, es destacable que la gente que tiene su propia agenda **(0 - Employees with own schedule)** es la que tiene una mayor tasa de abandono labora, seguida eso s√≠, del turno de noche **(3 - 9pm to 7am)**

-   [**Variable *monthlyincome***]{.hl-bluepastel}

Para relacionar la variable objetivo con la variable **monthlyincome** se va a emplear la t√©cnica de los percentiles.

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
percentiles <- quantile(dataset_attrition$monthlyincome, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE)

attrition_cat_mincome <- dataset_attrition |> 
  mutate(cat_mincome = case_when(
    monthlyincome <= percentiles[2] ~ "P0 - P25",
    monthlyincome <= percentiles[3] ~ "P25 - P50",
    monthlyincome <= percentiles[4] ~ "P50 - P75",
    TRUE ~ "P75 - P100"
  )) |> 
  select(monthlyincome, cat_mincome, attrition) |> 
  group_by(cat_mincome) |> 
  count(attrition) |>
  mutate(attrition_ratio = 100 * n / sum(n),
         cat_mincome = factor(cat_mincome, levels = c("P0 - P25", "P25 - P50", "P50 - P75", "P75 - P100"))
  ) |> ungroup()

attr_mincome_1 <- round(min(attrition_cat_mincome |> filter(cat_mincome == "P0 - P25" & attrition == "1") |> select(attrition_ratio)), 2)
attr_mincome_2 <- round(min(attrition_cat_mincome |> filter(cat_mincome == "P25 - P50" & attrition == "1") |> select(attrition_ratio)), 2)
attr_mincome_3 <- round(min(attrition_cat_mincome |> filter(cat_mincome == "P50 - P75" & attrition == "1") |> select(attrition_ratio)), 2)
attr_mincome_4 <- round(min(attrition_cat_mincome |> filter(cat_mincome == "P75 - P100" & attrition == "1") |> select(attrition_ratio)), 2)

attrition_cat_mincome |>
  ggplot(aes(x = cat_mincome, y = attrition_ratio, fill = attrition)) +
  geom_col() +
  coord_flip() +
  labs(title = "Monthly income - employee attrition (%)")+
  annotate("text", x = 1, y = 40, label= paste(attr_mincome_1, "%", sep = ""), size = 4, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 2, y = 40, label= paste(attr_mincome_2, "%", sep = ""), size = 4, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 3, y = 40, label= paste(attr_mincome_3, "%", sep = ""), size = 4, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 4, y = 40, label= paste(attr_mincome_4, "%", sep = ""), size = 4, color = "#A4185B", fontface = "bold") + 
  scale_fill_manual(values = c("#AAEAAA", "#A4185B")) +
  theme_minimal() +
  theme(axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        axis.text.y = element_text(size = 12, face = "bold"),
        legend.position = "None",
        plot.title = element_text(size = 12, face = "bold"))
```

Podemos observar que en el percentil **P0 - P25** (los empleados con los ingresos m√°s bajos) existe la mayor tasa de abandono del empleo 27.45%. Y conforme van subiendo los sueldos esta tasa disminuye considerablemente hasta un 4.77%

-   [**Variable *numcompaniesworked***]{.hl-bluepastel}

Empleando de nuevo la t√©cnica de divisi√≥n en percentiles se va a visualizar la relaci√≥n entre **numcompaniesworked** y la variable objetivo.

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
percentiles <- quantile(dataset_attrition$numcompaniesworked, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE)

attrition_cat_ncwork <- dataset_attrition |> 
  mutate(cat_ncwork = case_when(
    numcompaniesworked <= percentiles[2] ~ "P0 - P25",
    numcompaniesworked <= percentiles[3] ~ "P25 - P50",
    numcompaniesworked <= percentiles[4] ~ "P50 - P75",
    TRUE ~ "P75 - P100"
  )) |> 
  select(numcompaniesworked, cat_ncwork, attrition) |> 
  group_by(cat_ncwork) |> 
  count(attrition) |>
  mutate(attrition_ratio = 100 * n / sum(n),
         cat_ncwork = factor(cat_ncwork, levels = c("P0 - P25", "P25 - P50", "P50 - P75", "P75 - P100"))
  ) |> ungroup()

attr_mincome_1 <- round(min(attrition_cat_ncwork |> filter(cat_ncwork == "P0 - P25" & attrition == "1") |> select(attrition_ratio)), 2)
attr_mincome_2 <- round(min(attrition_cat_ncwork |> filter(cat_ncwork == "P25 - P50" & attrition == "1") |> select(attrition_ratio)), 2)
attr_mincome_3 <- round(min(attrition_cat_ncwork |> filter(cat_ncwork == "P50 - P75" & attrition == "1") |> select(attrition_ratio)), 2)
attr_mincome_4 <- round(min(attrition_cat_ncwork |> filter(cat_ncwork == "P75 - P100" & attrition == "1") |> select(attrition_ratio)), 2)

attrition_cat_ncwork |>
  ggplot(aes(x = cat_ncwork, y = attrition_ratio, fill = attrition)) +
  geom_col() +
  coord_flip() +
  labs(title = "Num companies worked - employee attrition (%)")+
  annotate("text", x = 1, y = 40, label= paste(attr_mincome_1, "%", sep = ""), size = 4, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 2, y = 40, label= paste(attr_mincome_2, "%", sep = ""), size = 4, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 3, y = 40, label= paste(attr_mincome_3, "%", sep = ""), size = 4, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 4, y = 40, label= paste(attr_mincome_4, "%", sep = ""), size = 4, color = "#A4185B", fontface = "bold") + 
  scale_fill_manual(values = c("#AAEAAA", "#A4185B")) +
  theme_minimal() +
  theme(axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        axis.text.y = element_text(size = 12, face = "bold"),
        legend.position = "None",
        plot.title = element_text(size = 12, face = "bold"))
```

En esta gr√°fica podemos ver como los empleados que han estado en pocas compa√±√≠as tienen una tasa de abandono bastante alta **(13.71%)**, aun as√≠, los que m√°s abandono tienen son los que han estado en m√°s trabajos **(16.03%)**. Esto sugiere que aquellos que han cambiado de empresa frecuentemente en el pasado tienen m√°s probabilidades de abandonar su trabajo actual.

-   [**Variable *percentsalaryhike***]{.hl-bluepastel}

La relaci√≥n entre **percentsalaryhike** y la variable objetivo se va a calcular tambi√©n a partir de percentiles:

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
percentiles <- quantile(dataset_attrition$percentsalaryhike, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE)

attrition_cat_pshike <- dataset_attrition |> 
  mutate(cat_pshike = case_when(
    percentsalaryhike <= percentiles[2] ~ "P0 - P25",
    percentsalaryhike <= percentiles[3] ~ "P25 - P50",
    percentsalaryhike <= percentiles[4] ~ "P50 - P75",
    TRUE ~ "P75 - P100"
  )) |> 
  select(percentsalaryhike, cat_pshike, attrition) |> 
  group_by(cat_pshike) |> 
  count(attrition) |>
  mutate(attrition_ratio = 100 * n / sum(n),
         cat_pshike = factor(cat_pshike, levels = c("P0 - P25", "P25 - P50", "P50 - P75", "P75 - P100"))
  ) |> ungroup()

attr_pshike_1 <- round(min(attrition_cat_pshike |> filter(cat_pshike == "P0 - P25" & attrition == "1") |> select(attrition_ratio)), 2)
attr_pshike_2 <- round(min(attrition_cat_pshike |> filter(cat_pshike == "P25 - P50" & attrition == "1") |> select(attrition_ratio)), 2)
attr_pshike_3 <- round(min(attrition_cat_pshike |> filter(cat_pshike == "P50 - P75" & attrition == "1") |> select(attrition_ratio)), 2)
attr_pshike_4 <- round(min(attrition_cat_pshike |> filter(cat_pshike == "P75 - P100" & attrition == "1") |> select(attrition_ratio)), 2)

attrition_cat_pshike |>
  ggplot(aes(x = cat_pshike, y = attrition_ratio, fill = attrition)) +
  geom_col() +
  coord_flip() +
  labs(title = "Percent salary hike - employee attrition (%)")+
  annotate("text", x = 1, y = 40, label= paste(attr_pshike_1, "%", sep = ""), size = 4, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 2, y = 40, label= paste(attr_pshike_2, "%", sep = ""), size = 4, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 3, y = 40, label= paste(attr_pshike_3, "%", sep = ""), size = 4, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 4, y = 40, label= paste(attr_pshike_4, "%", sep = ""), size = 4, color = "#A4185B", fontface = "bold") + 
  scale_fill_manual(values = c("#AAEAAA", "#A4185B")) +
  theme_minimal() +
  theme(axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        axis.text.y = element_text(size = 12, face = "bold"),
        legend.position = "None",
        plot.title = element_text(size = 12, face = "bold"))
```

Se puede observar como existe una tasa de abandono laboral bastante similar en todos los niveles por lo que parece que la variable **percentsalaryhike** puede no estar aportando mucha informaci√≥n a nuestra variable objetivo. Para comprobar si realmente es √∫til posteriormente se realizar√° un contraste de independencia viendo si tiene sentido o no mantener esta variable.

-   [**Variable *totalworkingyears***]{.hl-bluepastel}

Para relacionar la variable objetivo con la variable **totalworkingyears** y previendo una posible distribuci√≥n irregular en la que existen pocos empleados en ciertas franjas de experiencia como pueden ser los muy experimentados, se ha seleccionado el m√©todo de Dalenius-Hodges.

```{r}
#| code-fold: true
#| message: false
#| warning: false

dataset_attrition_twyears <- dataset_attrition |> mutate(cat_twyears = strata.cumrootf(totalworkingyears, CV=0.05, Ls = 5)[["stratumID"]]) |> 
mutate(cat_twyears = case_when(cat_twyears == "5" ~ "Senior",
          cat_twyears == "4" ~ "Mid/Senior",
          cat_twyears == "3" ~ "Mid",
          cat_twyears == "2" ~ "Mid/Junior",
          TRUE ~ "Junior")) |>
arrange(desc(totalworkingyears)) |> 
 select(cat_twyears, attrition) 


plot_dist_twyears <- dataset_attrition_twyears |> group_by(cat_twyears) |> summarise(n = n(), percentage = round(n()*100.0/nrow(dataset_attrition_twyears),2)) |> 
  ggplot(aes(x = factor(cat_twyears,levels = c("Junior","Mid/Junior","Mid","Mid/Senior","Senior")), y = n)) +
  geom_col(position = "dodge", alpha =0.8,fill = "#AAEAAA") +
  geom_text(aes(label = paste(n," (",percentage,"%)", sep ="")), colour = "#A4185B", size = 3,vjust = 0,hjust =1.2, angle = 90,  position = position_dodge(.9)) +
  theme_minimal()+
  theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 10, angle = 90, face =  "bold"),
      legend.position = "None"
      )


attr_1 <-  round(min(dataset_attrition_twyears |> group_by(cat_twyears) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_twyears == "Senior" & attrition == 1) |> select(attrition_ratio)),2)
attr_2 <-  round(min(dataset_attrition_twyears |> group_by(cat_twyears) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_twyears == "Mid/Senior" & attrition == 1) |> select(attrition_ratio)),2)
attr_3 <-  round(min(dataset_attrition_twyears |> group_by(cat_twyears) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_twyears == "Mid" & attrition == 1) |> select(attrition_ratio)),2)
attr_4 <-  round(min(dataset_attrition_twyears |> group_by(cat_twyears) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_twyears == "Mid/Junior" & attrition == 1) |> select(attrition_ratio)),2)
attr_5 <-  round(min(dataset_attrition_twyears |> group_by(cat_twyears) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_twyears == "Junior" & attrition == 1) |>  select(attrition_ratio)),2)


plot_cat_twyears <- dataset_attrition_twyears |> group_by(cat_twyears) |> count(attrition) |>  mutate(stroke_ratio = 100*n/sum(n)) |>
ggplot(aes(x = factor(cat_twyears,levels = c("Junior","Mid/Junior","Mid","Mid/Senior","Senior")), y = stroke_ratio, fill = attrition))+
geom_col()+
annotate("text", x = 1, y= 35, label= paste(attr_5,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 2, y= 20, label= paste(attr_4,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 3, y= 20, label= paste(attr_3,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") +  
annotate("text", x = 4, y= 20, label= paste(attr_2,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") +  
annotate("text", x = 5, y= 20, label= paste(attr_1,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") +  
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 10, angle = 90, face =  "bold"),
      legend.position = "None"
      )

ggarrange(plot_dist_twyears, plot_cat_twyears, ncol=2)
```

Podemos observar que la mayor√≠a de empleados son Mid/Junior y a partir de esta franja, el numero de empleados comienza a descender hasta la menor tasa en los mas seniors donde es tan solo un **9.07%**.

Por otro lado en cuanto a la relaci√≥n de la variable objetivo con el numero de a√±os trabajados, se observa que los empleados m√°s juniors son los que m√°s tasa de abandono laboral tienen con un **27.7%** y los m√°s seniors los que menos con un **3.29%**.

-   [**Variable *trainingtimeslastyear***]{.hl-bluepastel}

Para la variable **trainingtimeslastyear** tambi√©n se usar√° Dalenius dado que la distribuci√≥n de esta variable es sesgada o discontinua y por tanto los percentiles no har√≠an una divisi√≥n correcta.

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
dataset_attrition_ttlyears <- dataset_attrition |> mutate(cat_ttlyears = strata.cumrootf(trainingtimeslastyear, CV=0.05, Ls = 5)[["stratumID"]]) |> 
mutate(cat_ttlyears = case_when(cat_ttlyears == "5" ~ "Muy alto",
          cat_ttlyears == "4" ~ "Alto",
          cat_ttlyears == "3" ~ "Medio",
          cat_ttlyears == "2" ~ "Bajo",
          TRUE ~ "Muy bajo")) |>
arrange(desc(trainingtimeslastyear)) |> 
 select(cat_ttlyears, attrition) 


plot_dist_ttlyears <- dataset_attrition_ttlyears |> group_by(cat_ttlyears) |> summarise(n = n(), percentage = round(n()*100.0/nrow(dataset_attrition_ttlyears),2)) |> 
  ggplot(aes(x = factor(cat_ttlyears,levels = c("Muy bajo","Bajo","Medio","Alto","Muy alto")), y = n)) +
  geom_col(position = "dodge", alpha =0.8,fill = "#AAEAAA") +
  geom_text(aes(label = paste(n," (",percentage,"%)", sep ="")), colour = "#A4185B", size = 3,vjust = 0,hjust =1.2, angle = 90,  position = position_dodge(.9)) +
  theme_minimal()+
  theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 10, angle = 90, face =  "bold"),
      legend.position = "None"
      )


attr_1 <-  round(min(dataset_attrition_ttlyears |> group_by(cat_ttlyears) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_ttlyears == "Muy alto" & attrition == 1) |> select(attrition_ratio)),2)
attr_2 <-  round(min(dataset_attrition_ttlyears |> group_by(cat_ttlyears) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_ttlyears == "Alto" & attrition == 1) |> select(attrition_ratio)),2)
attr_3 <-  round(min(dataset_attrition_ttlyears |> group_by(cat_ttlyears) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_ttlyears == "Medio" & attrition == 1) |> select(attrition_ratio)),2)
attr_4 <-  round(min(dataset_attrition_ttlyears |> group_by(cat_ttlyears) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_ttlyears == "Bajo" & attrition == 1) |> select(attrition_ratio)),2)
attr_5 <-  round(min(dataset_attrition_ttlyears |> group_by(cat_ttlyears) |> count(attrition) |>  mutate(attrition_ratio = 100*n/sum(n)) |> ungroup() |> 
                              filter(cat_ttlyears == "Muy bajo" & attrition == 1) |>  select(attrition_ratio)),2)


plot_cat_ttlyears <- dataset_attrition_ttlyears |> group_by(cat_ttlyears) |> count(attrition) |>  mutate(stroke_ratio = 100*n/sum(n)) |>
ggplot(aes(x = factor(cat_ttlyears,levels = c("Muy bajo","Bajo","Medio","Alto","Muy alto")), y = stroke_ratio, fill = attrition))+
geom_col()+
annotate("text", x = 1, y= 35, label= paste(attr_5,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 2, y= 20, label= paste(attr_4,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") + 
annotate("text", x = 3, y= 20, label= paste(attr_3,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") +  
annotate("text", x = 4, y= 20, label= paste(attr_2,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") +  
annotate("text", x = 5, y= 20, label= paste(attr_1,"%", sep =""),size = 3 , color = "#A4185B",fontface = "bold") +  
scale_fill_manual(values = c("#AAEAAA", "#A4185B"))+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 10, angle = 90, face =  "bold"),
      legend.position = "None"
      )

ggarrange(plot_dist_ttlyears, plot_cat_ttlyears, ncol=2)
```

La distribuci√≥n del tiempo de entrenamiento por empleados nos indica que los empleados por lo general destinaron un tiempo medio y bajo al entrenamiento (**33.83% y 36.46%**).

Tambi√©n podemos observar que el abandono laboral en funci√≥n del tiempo de entrenamiento se mantiene constante en los diferentes niveles siendo mayor cuando se destina poco tiempo de entrenamiento (**15.06%**) y siendo el menor nivel cuando se destina un tiempo medio (**8.99%**)

-   [**Variables *yearsatcompany y yearsincurrentrole***]{.hl-bluepastel}

Las variables **yearsatcompany** y **yearsincurrentrole** se va a relacionar con la objetivo gracias al m√©todo de percentiles:

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
percentiles <- quantile(dataset_attrition$yearsatcompany, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE)

attrition_cat_yacomp <- dataset_attrition |> 
  mutate(cat_yacomp = case_when(
    yearsatcompany <= percentiles[2] ~ "P0 - P25",
    yearsatcompany <= percentiles[3] ~ "P25 - P50",
    yearsatcompany <= percentiles[4] ~ "P50 - P75",
    TRUE ~ "P75 - P100"
  )) |> 
  select(yearsatcompany, cat_yacomp, attrition) |> 
  group_by(cat_yacomp) |> 
  count(attrition) |>
  mutate(attrition_ratio = 100 * n / sum(n),
         cat_yacomp = factor(cat_yacomp, levels = c("P0 - P25", "P25 - P50", "P50 - P75", "P75 - P100"))
  ) |> ungroup()

attr_yacomp_1 <- round(min(attrition_cat_yacomp |> filter(cat_yacomp == "P0 - P25" & attrition == "1") |> select(attrition_ratio)), 2)
attr_yacomp_2 <- round(min(attrition_cat_yacomp |> filter(cat_yacomp == "P25 - P50" & attrition == "1") |> select(attrition_ratio)), 2)
attr_yacomp_3 <- round(min(attrition_cat_yacomp |> filter(cat_yacomp == "P50 - P75" & attrition == "1") |> select(attrition_ratio)), 2)
attr_yacomp_4 <- round(min(attrition_cat_yacomp |> filter(cat_yacomp == "P75 - P100" & attrition == "1") |> select(attrition_ratio)), 2)

plot_yacomp <- attrition_cat_yacomp |>
  ggplot(aes(x = cat_yacomp, y = attrition_ratio, fill = attrition)) +
  geom_col() +
  coord_flip() +
  labs(title = "Years at company - employee attrition (%)")+
  annotate("text", x = 1, y = 40, label= paste(attr_yacomp_1, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 2, y = 40, label= paste(attr_yacomp_2, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 3, y = 40, label= paste(attr_yacomp_3, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 4, y = 40, label= paste(attr_yacomp_4, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  scale_fill_manual(values = c("#AAEAAA", "#A4185B")) +
  theme_minimal() +
  theme(axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        axis.text.y = element_text(size = 8, face = "bold"),
        legend.position = "None",
        plot.title = element_text(size = 8, face = "bold"))

percentiles <- quantile(dataset_attrition$yearsincurrentrole, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE)

attrition_cat_ycrol <- dataset_attrition |> 
  mutate(cat_ycrol = case_when(
    yearsincurrentrole <= percentiles[2] ~ "P0 - P25",
    yearsincurrentrole <= percentiles[3] ~ "P25 - P50",
    yearsincurrentrole <= percentiles[4] ~ "P50 - P75",
    TRUE ~ "P75 - P100"
  )) |> 
  select(yearsincurrentrole, cat_ycrol, attrition) |> 
  group_by(cat_ycrol) |> 
  count(attrition) |>
  mutate(attrition_ratio = 100 * n / sum(n),
         cat_ycrol = factor(cat_ycrol, levels = c("P0 - P25", "P25 - P50", "P50 - P75", "P75 - P100"))
  ) |> ungroup()

attr_ycrol_1 <- round(min(attrition_cat_ycrol |> filter(cat_ycrol == "P0 - P25" & attrition == "1") |> select(attrition_ratio)), 2)
attr_ycrol_2 <- round(min(attrition_cat_ycrol |> filter(cat_ycrol == "P25 - P50" & attrition == "1") |> select(attrition_ratio)), 2)
attr_ycrol_3 <- round(min(attrition_cat_ycrol |> filter(cat_ycrol == "P50 - P75" & attrition == "1") |> select(attrition_ratio)), 2)
attr_ycrol_4 <- round(min(attrition_cat_ycrol |> filter(cat_ycrol == "P75 - P100" & attrition == "1") |> select(attrition_ratio)), 2)

plot_years_crol <- attrition_cat_ycrol |>
  ggplot(aes(x = cat_ycrol, y = attrition_ratio, fill = attrition)) +
  geom_col() +
  coord_flip() +
  labs(title = "Years in current role - employee attrition (%)")+
  annotate("text", x = 1, y = 40, label= paste(attr_ycrol_1, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 2, y = 40, label= paste(attr_ycrol_2, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 3, y = 40, label= paste(attr_ycrol_3, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 4, y = 40, label= paste(attr_ycrol_4, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  scale_fill_manual(values = c("#AAEAAA", "#A4185B")) +
  theme_minimal() +
  theme(axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        axis.text.y = element_text(size = 8, face = "bold"),
        legend.position = "None",
        plot.title = element_text(size = 8, face = "bold"))


ggarrange(plot_yacomp, plot_years_crol, ncol=2)
```

Observamos como las gr√°ficas son bastante similares en cuanto a su tendencia descendente en funci√≥n del paso de los a√±os.

Los empleados que llevan menos tiempo en la compa√±√≠a son los que tienen una mayor tasa de abandono laboral (**23.01%**), adem√°s se observa como en funci√≥n del paso de los a√±os esta tasa desciende hasta un **2.46%**.

Por otro lado los empleados que menos tiempo llevan con un manager son los que m√°s abandonan el trabajo con un **19.27%** y esta tasa desciende a lo largo de los a√±os a pesar de un peque√±o incremento en el percentil 50-75 hasta el **2.3%** final

-   [**Variable *yearssincelastpromotion y yearswithcurrmanager***]{.hl-bluepastel}

Tambien las variables **yearssincelastpromotion** y **yearswithcurrmanager** se van a seguir relacionando con la variable objetivo mediante percentiles:

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
percentiles <- quantile(dataset_attrition$yearsincurrentrole, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE)

attrition_cat_ycrol <- dataset_attrition |> 
  mutate(cat_ycrol = case_when(
    yearsincurrentrole <= percentiles[2] ~ "P0 - P25",
    yearsincurrentrole <= percentiles[3] ~ "P25 - P50",
    yearsincurrentrole <= percentiles[4] ~ "P50 - P75",
    TRUE ~ "P75 - P100"
  )) |> 
  select(yearsincurrentrole, cat_ycrol, attrition) |> 
  group_by(cat_ycrol) |> 
  count(attrition) |>
  mutate(attrition_ratio = 100 * n / sum(n),
         cat_ycrol = factor(cat_ycrol, levels = c("P0 - P25", "P25 - P50", "P50 - P75", "P75 - P100"))
  ) |> ungroup()

attr_ycrol_1 <- round(min(attrition_cat_ycrol |> filter(cat_ycrol == "P0 - P25" & attrition == "1") |> select(attrition_ratio)), 2)
attr_ycrol_2 <- round(min(attrition_cat_ycrol |> filter(cat_ycrol == "P25 - P50" & attrition == "1") |> select(attrition_ratio)), 2)
attr_ycrol_3 <- round(min(attrition_cat_ycrol |> filter(cat_ycrol == "P50 - P75" & attrition == "1") |> select(attrition_ratio)), 2)
attr_ycrol_4 <- round(min(attrition_cat_ycrol |> filter(cat_ycrol == "P75 - P100" & attrition == "1") |> select(attrition_ratio)), 2)

plot_cat_ycrol <- attrition_cat_ycrol |>
  ggplot(aes(x = cat_ycrol, y = attrition_ratio, fill = attrition)) +
  geom_col() +
  coord_flip() +
  labs(title = "Years in current role - employee attrition (%)")+
  annotate("text", x = 1, y = 40, label= paste(attr_ycrol_1, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 2, y = 40, label= paste(attr_ycrol_2, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 3, y = 40, label= paste(attr_ycrol_3, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 4, y = 40, label= paste(attr_ycrol_4, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  scale_fill_manual(values = c("#AAEAAA", "#A4185B")) +
  theme_minimal() +
  theme(axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        axis.text.y = element_text(size = 8, face = "bold"),
        legend.position = "None",
        plot.title = element_text(size = 8, face = "bold"))

percentiles <- quantile(dataset_attrition$yearswithcurrmanager, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE)

attrition_cat_ycrmang <- dataset_attrition |> 
  mutate(cat_ycrmang  = case_when(
    yearswithcurrmanager <= percentiles[2] ~ "P0 - P25",
    yearswithcurrmanager <= percentiles[3] ~ "P25 - P50",
    yearswithcurrmanager <= percentiles[4] ~ "P50 - P75",
    TRUE ~ "P75 - P100"
  )) |> 
  select(yearswithcurrmanager, cat_ycrmang, attrition) |> 
  group_by(cat_ycrmang) |> 
  count(attrition) |>
  mutate(attrition_ratio = 100 * n / sum(n),
         cat_ycrmang = factor(cat_ycrmang, levels = c("P0 - P25", "P25 - P50", "P50 - P75", "P75 - P100"))
  ) |> ungroup()

attr_ycrmang_1 <- round(min(attrition_cat_ycrmang |> filter(cat_ycrmang == "P0 - P25" & attrition == "1") |> select(attrition_ratio)), 2)
attr_ycrmang_2 <- round(min(attrition_cat_ycrmang |> filter(cat_ycrmang == "P25 - P50" & attrition == "1") |> select(attrition_ratio)), 2)
attr_ycrmang_3 <- round(min(attrition_cat_ycrmang |> filter(cat_ycrmang == "P50 - P75" & attrition == "1") |> select(attrition_ratio)), 2)
attr_ycrmang_4 <- round(min(attrition_cat_ycrmang |> filter(cat_ycrmang == "P75 - P100" & attrition == "1") |> select(attrition_ratio)), 2)

plot_cat_ycrmang <- attrition_cat_ycrol |>
  ggplot(aes(x = cat_ycrol, y = attrition_ratio, fill = attrition)) +
  geom_col() +
  coord_flip() +
  labs(title = "Years with current manager - employee attrition (%)")+
  annotate("text", x = 1, y = 40, label= paste(attr_ycrmang_1, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 2, y = 40, label= paste(attr_ycrmang_2, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 3, y = 40, label= paste(attr_ycrmang_3, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  annotate("text", x = 4, y = 40, label= paste(attr_ycrmang_4, "%", sep = ""), size = 3, color = "#A4185B", fontface = "bold") + 
  scale_fill_manual(values = c("#AAEAAA", "#A4185B")) +
  theme_minimal() +
  theme(axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        axis.text.y = element_text(size = 8, face = "bold"),
        legend.position = "None",
        plot.title = element_text(size = 8, face = "bold"))

ggarrange(plot_cat_ycrol, plot_cat_ycrmang, ncol=2)
```

Se ve como la tasa de abandono se mantiene descendente a lo largo de los a√±os. Los empleados que menos tiempo llevan en su rol o con su manager concreto son los que mas tendencia tienen a abandonar el empleo con un **19.27% y 18.49%** respectivamente.

Esta desciende notablemente hasta un **2.3%** en caso de los a√±os en un rol y hasta un **4.15%** en los a√±os con un manager concreto.

Con todas estas observaciones se puede deducir que existe una tendencia entre la gente m√°s joven y que menos a√±os lleva en el trabajo a abandonar ese empleo.

##### Contraste de independencia

Se va a realizar la prueba $\chi^{2}$ de independencia para comprobar con mayor certeza si la variable predictora es dependiente o no de la variable objetivo.

Este tipo de prueba se realiza sobre dos variables categ√≥ricas para comprobar si est√°n o no relacionadas.

Vamos a ejecutar esta prueba sobre todas nuestras variables que pueden o son ya categ√≥ricas, por ello en primer lugar se van a convertir algunas variables a categ√≥ricas.

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
dataset_attrition$educationfield = as.factor(dataset_attrition$educationfield)

dataset_attrition$gender = as.factor(dataset_attrition$gender)

dataset_attrition$jobrole = as.factor(dataset_attrition$jobrole)

dataset_attrition$maritalstatus = as.factor(dataset_attrition$maritalstatus)
```

Una vez convertidas las variables a categ√≥ricas se van a enfrentar todas nuestras variables categ√≥ricas con la variable objetivo:

```{r}
#| code-fold: true
#| message: false
#| warning: false

cat <- c('businesstravel','department','education','educationfield','gender','joblevel','jobrole','maritalstatus','overtime','shift')

chi <- tibble("variable" = cat, "p_value" = dataset_attrition |> select(cat) |> map_dbl(.f = function(x) { chisq.test(dataset_attrition$attrition, x)$p.value }))

chi |> arrange(desc(p_value))

chi |> filter(p_value > 0.05)
```

Filtrando por las variables que tienen una menor asociaci√≥n significativa con la variable objetivo observamos que las variables **gender**, **educationfield** y **businesstravel** no parecen afectar significativamente al abandono del empleo, por lo tanto estas se van a eliminar de nuestro conjunto de datos.

Se va a conservar la variable **education** ya que es muy cercana a nuestro nivel de significaci√≥n habitual (0.05).

```{r}
#| code-fold: true
#| message: false
#| warning: false
dataset_attrition = select(dataset_attrition, -gender)

dataset_attrition = select(dataset_attrition, -educationfield)

dataset_attrition = select(dataset_attrition, -businesstravel)
```

#### Tratamiento de outliers

##### Detecci√≥n de outliers

Gracias a los diferentes gr√°ficos en el an√°lisis de las variables se puede detectar que existen algunos valores extremos en nuestros datos. Para corregir esto, se va a realizar el tratamiento de los outliers en las variables que tienen estos valores.

Se ha podido observar que las variables que presentan valores at√≠picos son **totalworkingyears**, **yearsatcompany**, **yearsincurrentrole**, **yearssincelastpromotion**, **yearswithcurrmanager**, **monthlyincome**, **numcompaniesworked** y **trainingtimeslastyear**

En alusi√≥n a los gr√°ficos obtenidos en el an√°lisis exploratorio de las variables podemos obervar que todas las distribuciones son asim√©tricas a excepci√≥n de la de la variable **trainingtimeslastyear** por lo que esta tendr√° un tratamiento especial frente al resto.

-   [**Variable *trainingtimeslastyear***]{.hl-bluepastel}

Como se ha mencionado anteriormente, **trainingtimeslastyear** posee una distribuci√≥n sim√©trica por lo que se va a realizar la imputaci√≥n respecto a la media.

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
k_mean <- 3

dataset_attrition <- dataset_attrition |> 
  mutate(outlier_ttlyear = if_else(abs(scores(trainingtimeslastyear, type = "z")) > k_mean, 1, 0))
```

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
dataset_attrition |> filter(outlier_ttlyear == 1) |> distinct() |> count()
```

A pesar de encontrar outliers de forma gr√°fica, podemos observar que **respecto a la media** y estableciendo un valor de **K = 3**, no existen unos valores tan extremos como para ser considerados outliers por lo que no se realizar√° el tratamiento de esta variable.

-   [**Variables *asim√©tricas***]{.hl-bluepastel}

Para realizar el tratamiento de los outliers de estas variables asim√©tricas no se puede imputar por la media por lo que consideraremos realizarlo respecto a la mediana.

Para poder realizar una detecci√≥n de outliers respecto a la mediana primero nos tenemos que asegurar que las medianas de nuestras variables sean diferentes a 0 por lo que se van a realizar estos calculos a continuaci√≥n:

```{r}
median(dataset_attrition$totalworkingyears, na.rm=TRUE)
```

```{r}
median(dataset_attrition$yearsatcompany, na.rm=TRUE)
```

```{r}
median(dataset_attrition$yearsincurrentrole, na.rm=TRUE)
```

```{r}
median(dataset_attrition$yearssincelastpromotion, na.rm=TRUE)
```

```{r}
median(dataset_attrition$yearswithcurrmanager, na.rm=TRUE)
```

```{r}
median(dataset_attrition$monthlyincome, na.rm=TRUE)
```

```{r}
median(dataset_attrition$numcompaniesworked, na.rm=TRUE)
```

Observamos que ninguna de estas variables posee una mediana = 0 por lo que podemos continuar con nuestro proceso normalmente.

Respecto a la mediana asignaremos **K = 3** inicialmente. Por tanto un dato at√≠pico en nuestro an√°lisis ser√° aquel que se aleje 3 veces de la mediana de las desviaciones absolutas.

Por cada una de las variables habr√° una variable outlier respectiva que contendr√° 0 o 1 en funci√≥n de si es o no outlier.

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
k <- 3

dataset_attrition <- dataset_attrition |> 
  mutate(outlier_twyears = if_else(abs(scores(totalworkingyears, type = "mad")) > k, 1, 0),
        outlier_yacompany = if_else(abs(scores(yearsatcompany, type = "mad")) > k, 1, 0),
        outlier_yicrole = if_else(abs(scores(yearsincurrentrole, type = "mad")) > k, 1, 0),
        outlier_yprom = if_else(abs(scores(yearssincelastpromotion, type = "mad")) > k, 1, 0),
        outlier_ywcmag = if_else(abs(scores(yearswithcurrmanager, type = "mad")) > k, 1, 0),
        outlier_minc = if_else(abs(scores(monthlyincome, type = "mad")) > k, 1, 0),
        outlier_ncwork = if_else(abs(scores(numcompaniesworked, type = "mad")) > k, 1, 0))

datatable(dataset_attrition |> select(employeeid, outlier_twyears, outlier_yacompany,
                                      outlier_yicrole, outlier_yprom, outlier_ywcmag,
                                      outlier_minc, outlier_ncwork), 
          rownames = FALSE, 
          filter = "top",
          options = list(pageLength = 10)) |> formatStyle(names(dataset_attrition |>
          select(employeeid, outlier_twyears, outlier_yacompany, outlier_yicrole, outlier_yprom,
                 outlier_ywcmag, outlier_minc, outlier_ncwork)), 
          lineHeight = "65%")
```

El **n√∫mero total de outliers** en el conjunto de datos es:

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
dataset_attrition |> filter(outlier_twyears == 1 | outlier_yacompany == 1 | outlier_yicrole == 1 | outlier_yprom == 1 | outlier_ywcmag == 1 | outlier_minc == 1 | outlier_ncwork == 1) |> distinct() |> count()


```

##### Imputaci√≥n de outliers

Para la imputaci√≥n de outliers se va a realizar una **winzorizaci√≥n** en todas las variables que ten√≠an estos valores extremos. Escogeremos el m√°ximo valor no outlier de nuestra variable y usaremos ese dato para sustituirlo en caso de ser outlier.

En primer lugar vamos a visualizar la distribuci√≥n de las diferentes variables al aplicar el proceso de winzoricaci√≥n para comprobar su utilidad.

-   [**Variables *totalworkingyears***]{.hl-bluepastel}

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
max_value <- max(dataset_attrition |> filter(outlier_twyears==0) |> select(totalworkingyears))


dataset_attrition |> mutate(twy_winzorized = ifelse(outlier_twyears == 1, max_value,totalworkingyears)) |> select(totalworkingyears, twy_winzorized) |> pivot_longer(cols = c("totalworkingyears","twy_winzorized"), names_to = "Variable", values_to = "Value") |> 
  ggplot(aes(x = Variable, y = Value, fill = Variable, color = Variable)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_manual(values = c("#C2185B","#1E2D49")) +
  scale_color_manual(values = c("#C2185B","#1E2D49")) +
  labs(title = "Boxplot comparativo",
      subtitle = "Comparativa entre las distribuciones de la variable totalworkingyears (con y sin Winzorizaci√≥n)"
    ) +
theme_minimal()+
theme(plot.title = element_text(size = 17,face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x = element_blank(),
      axis.text.x = element_text(size = 13, face = "bold"))
```

-   [**Variables *yearsatcompany***]{.hl-bluepastel}

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
max_value <- max(dataset_attrition |> filter(outlier_yacompany==0) |> select(yearsatcompany))


dataset_attrition |> mutate(ytc_winzorized = ifelse(outlier_yacompany == 1, max_value, yearsatcompany)) |> select(yearsatcompany, ytc_winzorized) |> pivot_longer(cols = c("yearsatcompany","ytc_winzorized"), names_to = "Variable", values_to = "Value") |> 
  ggplot(aes(x = Variable, y = Value, fill = Variable, color = Variable)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_manual(values = c("#C2185B","#1E2D49")) +
  scale_color_manual(values = c("#C2185B","#1E2D49")) +
  labs(title = "Boxplot comparativo",
      subtitle = "Comparativa entre las distribuciones de la variable yearsatcompany (con y sin Winzorizaci√≥n)"
    ) +
theme_minimal()+
theme(plot.title = element_text(size = 17,face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x = element_blank(),
      axis.text.x = element_text(size = 13, face = "bold"))
```

-   [**Variables *yearsincurrentrole***]{.hl-bluepastel}

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
max_value <- max(dataset_attrition |> filter(outlier_yicrole==0) |> select(yearsincurrentrole))


dataset_attrition |> mutate(yicrole_winzorized = ifelse(outlier_yicrole == 1, max_value, yearsincurrentrole)) |> select(yearsincurrentrole, yicrole_winzorized) |> pivot_longer(cols = c("yearsincurrentrole","yicrole_winzorized"), names_to = "Variable", values_to = "Value") |> 
  ggplot(aes(x = Variable, y = Value, fill = Variable, color = Variable)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_manual(values = c("#C2185B","#1E2D49")) +
  scale_color_manual(values = c("#C2185B","#1E2D49")) +
  labs(title = "Boxplot comparativo",
      subtitle = "Comparativa entre las distribuciones de la variable yearsincurrentrole (con y sin Winzorizaci√≥n)"
    ) +
theme_minimal()+
theme(plot.title = element_text(size = 17,face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x = element_blank(),
      axis.text.x = element_text(size = 13, face = "bold"))
```

-   [**Variables *yearssincelastpromotion***]{.hl-bluepastel}

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
max_value <- max(dataset_attrition |> filter(outlier_yprom==0) |> select(yearssincelastpromotion))


dataset_attrition |> mutate(yprom_winzorized = ifelse(outlier_yprom == 1, max_value, yearssincelastpromotion)) |> select(yearssincelastpromotion, yprom_winzorized) |> pivot_longer(cols = c("yearssincelastpromotion","yprom_winzorized"), names_to = "Variable", values_to = "Value") |> 
  ggplot(aes(x = Variable, y = Value, fill = Variable, color = Variable)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_manual(values = c("#C2185B","#1E2D49")) +
  scale_color_manual(values = c("#C2185B","#1E2D49")) +
  labs(title = "Boxplot comparativo",
      subtitle = "Comparativa entre las distribuciones de la variable yearssincelastpromotion (con y sin Winzorizaci√≥n)"
    ) +
theme_minimal()+
theme(plot.title = element_text(size = 17,face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x = element_blank(),
      axis.text.x = element_text(size = 11, face = "bold"))
```

-   [**Variables *yearswithcurrmanager***]{.hl-bluepastel}

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
max_value <- max(dataset_attrition |> filter(outlier_ywcmag==0) |> select(yearswithcurrmanager))


dataset_attrition |> mutate(ywcmag_winzorized = ifelse(outlier_ywcmag == 1, max_value, yearswithcurrmanager)) |> select(yearswithcurrmanager, ywcmag_winzorized) |> pivot_longer(cols = c("yearswithcurrmanager","ywcmag_winzorized"), names_to = "Variable", values_to = "Value") |> 
  ggplot(aes(x = Variable, y = Value, fill = Variable, color = Variable)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_manual(values = c("#C2185B","#1E2D49")) +
  scale_color_manual(values = c("#C2185B","#1E2D49")) +
  labs(title = "Boxplot comparativo",
      subtitle = "Comparativa entre las distribuciones de la variable yearswithcurrmanager (con y sin Winzorizaci√≥n)"
    ) +
theme_minimal()+
theme(plot.title = element_text(size = 17,face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x = element_blank(),
      axis.text.x = element_text(size = 11, face = "bold"))
```

-   [**Variables *monthlyincome***]{.hl-bluepastel}

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
max_value <- max(dataset_attrition |> filter(outlier_minc==0) |> select(monthlyincome))


dataset_attrition |> mutate(mthinc_winzorized = ifelse(outlier_minc == 1, max_value, monthlyincome)) |> select(monthlyincome, mthinc_winzorized) |> pivot_longer(cols = c("monthlyincome","mthinc_winzorized"), names_to = "Variable", values_to = "Value") |> 
  ggplot(aes(x = Variable, y = Value, fill = Variable, color = Variable)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_manual(values = c("#C2185B","#1E2D49")) +
  scale_color_manual(values = c("#C2185B","#1E2D49")) +
  labs(title = "Boxplot comparativo",
      subtitle = "Comparativa entre las distribuciones de la variable monthlyincome (con y sin Winzorizaci√≥n)"
    ) +
theme_minimal()+
theme(plot.title = element_text(size = 17,face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x = element_blank(),
      axis.text.x = element_text(size = 11, face = "bold"))
```

-   [**Variables *numcompaniesworked***]{.hl-bluepastel}

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
max_value <- max(dataset_attrition |> filter(outlier_ncwork==0) |> select(numcompaniesworked))


dataset_attrition |> mutate(nwork_winzorized = ifelse(outlier_ncwork == 1, max_value, numcompaniesworked)) |> select(numcompaniesworked, nwork_winzorized) |> pivot_longer(cols = c("numcompaniesworked","nwork_winzorized"), names_to = "Variable", values_to = "Value") |> 
  ggplot(aes(x = Variable, y = Value, fill = Variable, color = Variable)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_manual(values = c("#C2185B","#1E2D49")) +
  scale_color_manual(values = c("#C2185B","#1E2D49")) +
  labs(title = "Boxplot comparativo",
      subtitle = "Comparativa entre las distribuciones de la variable numcompaniesworked (con y sin Winzorizaci√≥n)"
    ) +
theme_minimal()+
theme(plot.title = element_text(size = 17,face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x = element_blank(),
      axis.text.x = element_text(size = 11, face = "bold"))
```

Observamos gracias a estos gr√°ficos como el proceso de winzorizaci√≥n nos permite reducir la influencia de los valores at√≠picos en todas las variables por lo que ya podemos continuar con el proceso.

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
max_twyears_not_outlier <- max(dataset_attrition |> filter(outlier_twyears == 0) |> select(totalworkingyears))

max_yacompany_not_outlier <- max(dataset_attrition |> filter(outlier_yacompany == 0) |> select(yearsatcompany))

max_yicrole_not_outlier <- max(dataset_attrition |> filter(outlier_yicrole == 0) |> select(yearsincurrentrole))

max_yprom_not_outlier <- max(dataset_attrition |> filter(outlier_yprom == 0) |> select(yearssincelastpromotion))

max_ywcmag_not_outlier <- max(dataset_attrition |> filter(outlier_ywcmag == 0) |> select(yearswithcurrmanager))

max_minc_not_outlier <- max(dataset_attrition |> filter(outlier_minc == 0) |> select(monthlyincome))

max_ncwork_not_outlier <- max(dataset_attrition |> filter(outlier_ncwork == 0) |> select(numcompaniesworked))

dataset_attrition <- dataset_attrition |> mutate(
                            totalworkingyears = ifelse(outlier_twyears == 1,
                                                      max_twyears_not_outlier,totalworkingyears),
                            yearsatcompany = ifelse(outlier_yacompany == 1, 
                                         max_yacompany_not_outlier, yearsatcompany ),
                            yearsincurrentrole = ifelse(outlier_yicrole == 1, 
                                         max_yicrole_not_outlier, yearsincurrentrole ),
                            yearssincelastpromotion = ifelse(outlier_yprom == 1, 
                                         max_yprom_not_outlier, yearssincelastpromotion ),
                            yearswithcurrmanager = ifelse(outlier_ywcmag == 1, 
                                         max_ywcmag_not_outlier, yearswithcurrmanager ),
                            monthlyincome = ifelse(outlier_minc == 1, 
                                         max_minc_not_outlier, monthlyincome ),
                            numcompaniesworked = ifelse(outlier_ncwork == 1, 
                                         max_ncwork_not_outlier, numcompaniesworked ),)
```

Por √∫ltimo, eliminamos de nuestro dataset aquellas variables que nos hab√≠an servido para detectar los valores at√≠picos. Adem√°s guardamos el resultado en un archivo rds.

::: callout-note
## Apunte sobre el dataset

Se va a renombrar el nombre del dataset a partir de este punto para separar la parte de an√°lisis y depuraci√≥n de datos de la creaci√≥n de los modelos
:::

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
dataset_attrition <- dataset_attrition |> select(-c(outlier_twyears,outlier_yacompany,outlier_yicrole,outlier_yprom,outlier_ywcmag, outlier_minc,outlier_ttlyear,outlier_ncwork))

datatable(dataset_attrition)

saveRDS(dataset_attrition, file = "./data/attrition_data.rds")
```

Ya tendr√≠amos nuestros depurados por completo y listos para usar en los distintos modelos :)

## √Årbol de decisi√≥n

### Teor√≠a del modelo

Los √°rboles de decisi√≥n son modelos predictivos que utilizan una estructura jer√°rquica basada en reglas binarias para clasificar datos o predecir valores num√©ricos. 

Su fundamento matem√°tico combina teor√≠a de probabilidad, medidas de impureza y optimizaci√≥n recursiva.

#### Estructura b√°sica 

Un √°rbol consta de:

- **Nodos**: Segmentos que contienen subconjuntos de la muestra.

- **Nodo ra√≠z**: Conjunto inicial de datos.

- **Nodos padre/hijo**: Nodos predecesor/sucesor de otro nodo. Se trata de un punto de decisi√≥n con condiciones.

- **Ramas**: Posibles caminos seg√∫n las condiciones.

- **Nodos hoja**: Nodos sin hijo que finalizan una rama y contienen resultados finales (clases o valores num√©ricos).

#### Criterios de divisi√≥n

##### Indice de Gini

Calcula la impureza del nodo como la probabilidad de obtener dos elementos de un mismo nodo y que no ocurra que ambos pertenecen a la misma clase.



### Librer√≠as necesarias

```{r}
#| code-fold: false
#| message: false
#| warning: false

rm(list = ls())

library(tidyverse)  # Depuraci√≥n datos
library(skimr)      # Resumen num√©rico
library(ggplot2)    # Gr√°ficos
library(tidymodels) # Modelos
library(rpart)      # CART
library(rpart.plot) # Graficar √°rbol
library(caret)      # Matriz de Confusion
library(glue)       # pegar texto + variables f√°cilmente
library(DT)         # Para mostrar tabla (formatStyle)
library(ROSE)       # Para Oversampling
library(yardstick)  # C√≥mo funcionan modelos
library(forcats)    # Para factores
library(pROC)       # ROC y AUC
```

### Datos iniciales

En primer lugar se importan los datos que han sido preprocesados previamente y se elimina la variable del identificador que no nos aportar√° informaci√≥n.

```{r}
#| code-fold: false
#| message: false
#| warning: false

#Carga de datos
attrition_data <- readRDS("./data/attrition_data.rds")
#Eliminar ID
attrition_data <- attrition_data |> select(-employeeid)
```

Vamos a observar la distribuci√≥n de nuestra variable **target** que en este caso es la variable **attrition**:

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
attrition_data |> group_by(attrition) |> summarise(n = n(), Porc = round(n()*100.0/nrow(attrition_data),2)) |> 
ggplot(aes(x = attrition, y = n, fill = attrition)) +
geom_col(position = "dodge", alpha =0.8) +
geom_text(aes(label = paste(n," (",Porc,"%)", sep ="")),colour = "black", size = 4,vjust = -0.5, position = position_dodge(.9)) +
ylim(0,5300)+
scale_fill_manual(values = c("#023047","#C2185B")) +
labs(title = "Distribuci√≥n del target",
     subtitle = "Reparto de niveles de la variable attrition")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12),
      legend.position = "None"
      )
```

Podemos ver como **attrition** se trata de una variable que est√° extremadamente desbalanceada por lo que posteriormente tendremos que solucionar este problema.


### Train y test

Se va a seleccionar inicialmente un **80%** de los datos para nuestro conjunto de entrenamiento (**Train**) y un **20%** para los del conjunto de validaci√≥n (**Test**). Asignamos tambi√©n una semilla para que se haga siempre la misma divisi√≥n.

```{r}
#| code-fold: false
#| message: false
#| warning: false

set.seed(200900)

attrition_split <- initial_split(attrition_data, strata = attrition, prop = 0.80)

# Train
attrition_train <- training(attrition_split)
# Test
attrition_test <- testing(attrition_split)
```


Para comprobar que esta divisi√≥n se haya hecho de forma correcta se observa si se mantiene la proporci√≥n de nuestra variable **target**:


```{r}
#| code-fold: false
#| message: false
#| warning: false

# Reparto de Vaccine en Train
attrition_train |> group_by(attrition) |> summarise(n = n()) |> mutate(prop = n /sum(n))
# Reparto de Vaccine en Test
attrition_test |> group_by(attrition) |> summarise(n = n()) |> mutate(prop = n /sum(n))
```

Vemos como si que se mantiene por lo que la divisi√≥n de los datos es correcta.

### Entrenamiento

La fase de entrenamiento de un √°rbol de decisi√≥n esta dividida en varias partes, en primer lugar vamos a comenzar por la **divisi√≥n en k-folds**.

#### Divisi√≥n en k-folds

El conjunto de datos de entrenamiento se dividir√° en una serie de trozos denominados **folds**. Se crear√° un modelo de √°rbol de decisi√≥n utilizando como entrenamiento toda esta serie de trozos a excepci√≥n de uno. Este se tratar√° del validation-fold mediante el cual evaluaremos nuestro modelo.

Este proceso se realiza tantas veces como divisiones se hayan creado en el conjunto de datos.

Para realizar el proceso de k-folding se va a utilizar la funci√≥n proporcionada en la asignatura de aprendizaje autom√°tico. 

```{r}
#| code-fold: false
#| message: false
#| warning: false
#| 
source("./funciones/utils.r")

attrition_data_cv <- fold_rep_for_cv(data = attrition_train, folds = 5, reps = 3, target = "attrition", seed = 200900)
```


#### Fine-tuning de los hiperpar√°metros

Para configurar los valores de nuestros **hiperpar√°metros** en el √°rbol de decisi√≥n vamos a crear dos grids, uno para el minbucket que define el n√∫mero m√≠nimo de observaciones que debe tener una hoja del √°rbol y otro para la complejidad de la poda del √°rbol.

- El grid de **minbucket** ir√° desde 0.5% hasta 2.5% **(0.5, 1, 1.5, 2, 2.5)**. Con estos valores vamos a ser capaces de abarcar desde hojas del √°rbol que contengan poca informaci√≥n cuando se use 0.5% hasta √°rboles m√°s regularizados que nos permitir√°n generalizar mejor cuando sea 2.5%.


- El grid de **complejidad de poda** ser√° **0.0001,0.001,0.01,0.1** para manejar diferentes podas que nos permitir√°n encontrar un equilibrio entre complejidad y generalizaci√≥n.

```{r}
#| code-fold: false
#| message: false
#| warning: false
#| 
minbucket_list <- seq(from = 0.5, to=2.5, by=0.5)

complexity_list <- c(0.0001,0.001,0.01,0.1)
```

#### Primer entrenamiento

Una vez definido el grid de nuestros hiperpar√°metros en el √°rbol de decisi√≥n y realizadas las divisiones de los datos para hacer una validaci√≥n cruzada ya estar√≠amos listos para efectuar el primer entrenamiento del modelo:

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| results: false
#| eval: false

cv_results <-  data.frame(rep          = integer(),
                           fold         = integer(),
                           minbucket    = integer(),
                           cp           = double(),
                           accuracy     = double(),
                           kappa        = double(),
                           sensitivity  = double(),
                           specificity  = double(),
                           auc          = double())


for (data_fold in attrition_data_cv) 
{
    #---------------------------------
    # Conjuntos de Train y Val
    #---------------------------------
    rep_value <- data_fold[["repeat"]]
    fold_value <- data_fold[["fold"]]
    train <- data_fold[["train_data"]]
    val <- data_fold[["validation_data"]]
    
    #---------------------------------
    # Fine tunning con diferentes hiperpar√°metros
    #---------------------------------
    for (bucket in minbucket_list)
    {
        for (complexity_parameter in complexity_list)
        {
            # ----------------- 
            #      Modelo
            # -----------------
            tree <- rpart(data = train,
                          attrition ~ .,
                          control = rpart.control(minbucket = as.integer((bucket*nrow(train))/100), 
                          cp = complexity_parameter))
            
            
            # Predicciones en Val
            pred <- predict(tree, newdata = val, type = "class") 
            # Matriz de confusi√≥n
            conf_mat <- confusionMatrix(pred, val[["attrition"]], positive = "1")
            # Accuracy
            accuracy_value <- conf_mat[["overall"]][["Accuracy"]]
            # Kappa
            kappa_value <- conf_mat[["overall"]][["Kappa"]]
            # Sensitivity
            sensitivity_value <- conf_mat[["byClass"]][["Sensitivity"]]
            # Specificity
            specificity_value <- conf_mat[["byClass"]][["Specificity"]]
            # Curva ROC y AUC
            pred <- as.data.frame(predict(tree, val, type="prob"))
            pred$real_class <- as.factor(val[["attrition"]])
            pred <- pred |>  rename(prob_attrition = "1", prob_none = "0")
            auc <- pred |>  roc_auc(truth = real_class, prob_attrition)
            auc_value <- auc |>  pull(.estimate)
            # ----------------------------------------> Guardamos resultados
            cv_results[nrow(cv_results) + 1,] <- c( rep_value,
                                                    fold_value,
                                                    bucket,
                                                    complexity_parameter,
                                                    round(accuracy_value,6),
                                                    round(kappa_value,6),
                                                    round(sensitivity_value,6),
                                                    round(specificity_value,6),
                                                    round(auc_value,6))
            # Para mostrar por pantalla lo que  se va ejecutando
            texto <- paste("Repeat: ",rep_value," - Fold: ",fold_value, " - Minbucket: ",bucket, sep = "" )
            print(texto)
            print("-----------------------")
        #}
        }
        
    }
         
}
# Conversi√≥n a formatos correctos
cv_results$minbucket <- as.double(cv_results$minbucket)
cv_results$cp <- as.double(cv_results$cp)
cv_results$accuracy <- as.double(cv_results$accuracy)
cv_results$kappa <- as.double(cv_results$kappa)
cv_results$sensitivity <- as.double(cv_results$sensitivity)
cv_results$specificity <- as.double(cv_results$specificity)
cv_results$auc <- as.double(cv_results$auc)
# Variable con nombre modelos
cv_results <- cv_results |>  mutate(model = paste(minbucket, " - ", cp, sep = ""))
# Guardamos
saveRDS(cv_results, file = "./outputs/cv_results_tree.rds")


```

Podemos observar los resultados de nuestro entrenamiento en la siguiente tabla:

```{r}
#| message: false
#| warning: false
#| echo: false

cv_results <- readRDS("./outputs/cv_results_tree.rds")

datatable(cv_results, 
          rownames = FALSE, 
          filter = "top",
          options = list(pageLength = 10, dom = "tip")) |> formatStyle(names(cv_results))
```



Podemos ver que el modelo tiene muy buen **acuraccy** y **specificity** ya que la mayor√≠a de nuestros datos son 0's y por tanto los clasificamos muy bien.

El problema de este modelo viene a la hora de clasificar los 1's que es lo que realmente nos interesa; y es que como no hay casi representaci√≥n de esta clase, m√©tricas como el **AUC** y la **sensibilidad**, son muy malas.

Como se ha mencionado anteriormente, el modelo tiene una distribuci√≥n de la variable **target** muy desbalanceada, esto nos ha llevado a obtener malos resultados en el modelo por lo que se va a llevar a cabo el empleo de la t√©cnica de oversampling para a√±adir datos que representen el valor que queremos predecir.

#### Oversampling

El **oversampling** complementar los datos de entrenamiento con m√∫ltiples copias de algunas de las clases minoritarias, en nuestro caso a√±adir√° muestras de 1's en la variable **attrition**

Previamente la variable objetivo estaba distribuida de la siguiente forma:

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
attrition_train |> group_by(attrition) |> summarise(n = n(), Porc = round(n()*100.0/nrow(attrition_train),2)) |> 
ggplot(aes(x = attrition, y = n, fill = attrition)) +
geom_col(position = "dodge", alpha =0.8) +
geom_text(aes(label = paste(n," (",Porc,"%)", sep ="")),colour = "black", size = 4,vjust = -0.5, position = position_dodge(.9)) +
ylim(0,5300)+
scale_fill_manual(values = c("#023047","#C2185B")) +
labs(title = "Distribuci√≥n del target",
     subtitle = "Reparto de niveles de la variable attrition")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12),
      legend.position = "None"
      )
```

[**Aplicamos oversampling**]{.hl-bluepastel}

```{r}
attrition_train_balance <- ovun.sample(attrition ~ .,
                                    data = attrition_train,
                                    seed = 200900,
                                    method = "over")$data
```


Tras aplicar oversampling nuestra variable **attrition** finalmente tiene un reparto de clases balanceado

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| 
attrition_train_balance |> group_by(attrition) |> summarise(n = n(), Porc = round(n()*100.0/nrow(attrition_train_balance),2)) |> 
ggplot(aes(x = attrition, y = n, fill = attrition)) +
geom_col(position = "dodge", alpha =0.8) +
geom_text(aes(label = paste(n," (",Porc,"%)", sep ="")),colour = "black", size = 4,vjust = -0.5, position = position_dodge(.9)) +
ylim(0,5300)+
scale_fill_manual(values = c("#023047","#C2185B")) +
labs(title = "Distribuci√≥n del target",
     subtitle = "Reparto de niveles de la variable attrition")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12),
      legend.position = "None"
      )
```

#### Entrenamiento con datos balanceados

Antes de comenzar el entrenamiento con los datos balanceados tendremos que generar de nuevo nuestras divisiones de **K-folds** sobre el conjunto de datos modificado.

```{r}
#| message: false
#| warning: false

attrition_data_balance_cv <- fold_rep_for_cv(data = attrition_train_balance, folds = 5, reps = 3, target = "attrition", seed = 200900) 
```


Procedemos a entrenar con los datos balanceados aplicando los diferentes grids de hiperpar√°metros

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| results: false
#| eval: false

cv_results <-  data.frame(rep          = integer(),
                           fold         = integer(),
                           minbucket    = integer(),
                           cp           = double(),
                           accuracy     = double(),
                           kappa        = double(),
                           sensitivity  = double(),
                           specificity  = double(),
                           auc          = double())


for (data_fold in attrition_data_balance_cv) 
{
    #---------------------------------
    # Conjuntos de Train y Val
    #---------------------------------
    rep_value <- data_fold[["repeat"]]
    fold_value <- data_fold[["fold"]]
    train <- data_fold[["train_data"]]
    val <- data_fold[["validation_data"]]
    
    #---------------------------------
    # Fine tunning con diferentes hiperpar√°metros
    #---------------------------------
    for (bucket in minbucket_list)
    {
        for (complexity_parameter in complexity_list)
        {
            # ----------------- 
            #      Modelo
            # -----------------
            tree <- rpart(data = train,
                          attrition ~ .,
                          control = rpart.control(minbucket = as.integer((bucket*nrow(train))/100), 
                          cp = complexity_parameter))
            
            
            # Predicciones en Val
            pred <- predict(tree, newdata = val, type = "class") 
            # Matriz de confusi√≥n
            conf_mat <- confusionMatrix(pred, val[["attrition"]], positive = "1")
            # Accuracy
            accuracy_value <- conf_mat[["overall"]][["Accuracy"]]
            # Kappa
            kappa_value <- conf_mat[["overall"]][["Kappa"]]
            # Sensitivity
            sensitivity_value <- conf_mat[["byClass"]][["Sensitivity"]]
            # Specificity
            specificity_value <- conf_mat[["byClass"]][["Specificity"]]
            # Curva ROC y AUC
            pred <- as.data.frame(predict(tree, val, type="prob"))
            pred$real_class <- as.factor(val[["attrition"]])
            pred <- pred |>  rename(prob_attrition = "1", prob_none = "0")
            auc <- pred |>  roc_auc(truth = real_class, prob_attrition)
            auc_value <- auc |>  pull(.estimate)
            # ----------------------------------------> Guardamos resultados
            cv_results[nrow(cv_results) + 1,] <- c( rep_value,
                                                    fold_value,
                                                    bucket,
                                                    complexity_parameter,
                                                    round(accuracy_value,6),
                                                    round(kappa_value,6),
                                                    round(sensitivity_value,6),
                                                    round(specificity_value,6),
                                                    round(auc_value,6))
            # Para mostrar por pantalla lo que  se va ejecutando
            texto <- paste("Repeat: ",rep_value," - Fold: ",fold_value, " - Minbucket: ",bucket, sep = "" )
            print(texto)
            print("-----------------------")
        #}
        }
        
    }
         
}
# Conversi√≥n a formatos correctos
cv_results$minbucket <- as.double(cv_results$minbucket)
cv_results$cp <- as.double(cv_results$cp)
cv_results$accuracy <- as.double(cv_results$accuracy)
cv_results$kappa <- as.double(cv_results$kappa)
cv_results$sensitivity <- as.double(cv_results$sensitivity)
cv_results$specificity <- as.double(cv_results$specificity)
cv_results$auc <- as.double(cv_results$auc)
# Variable con nombre modelos
cv_results <- cv_results |>  mutate(model = paste(minbucket, " - ", cp, sep = ""))
# Guardamos
saveRDS(cv_results, file = "./outputs/cv_oversampling_tree.rds")
```


Los resultados de nuestro modelo de √°rbol de decisi√≥n entrenado son los siguientes:

```{r}
#| message: false
#| warning: false
#| echo: false

cv_results <- readRDS("./outputs/cv_oversampling_tree.rds")

datatable(cv_results, 
          rownames = FALSE, 
          filter = "top",
          options = list(pageLength = 10, dom = "tip")) |> formatStyle(names(cv_results))
```



Observamos que se ha reducido tanto el accuracy como el specificity en estos nuevos modelos, aun as√≠, gracias a ampliar nuestra muestra de personas que abandonaban la empresa, ahora tambi√©n predice mejor esta casu√≠stica (**sensitivity**) por tanto en general los modelos son m√°s completos y predicen mejor ambas clases, pero sobre todo los positivos que es lo que m√°s nos interesa.


Vamos a observar los diferentes resultados de nuestro cross-validation para comparar los modelos en t√©rminos de sensibilidad.

```{r}
#| code-fold: true
#| message: false
#| warning: false
# Grafico comparativo
# Group by
cv_results_group <- cv_results |>   group_by(model) |>  summarise(accuracy = mean(accuracy),
                                                                 kappa = mean(kappa),
                                                                 sensitivity = mean(sensitivity),
                                                                 specificity = mean(specificity),
                                                                 auc = mean(auc)
                                                                 ) |>  
                                    arrange(desc(accuracy)) |>   
                                    slice_head(n = 10) |>   
                                    select(model)
# Cruce con cv_results para filtrar
cv_results_top <- cv_results |>  inner_join(cv_results_group, by = "model")
# Grafico comparativo
cv_results_top |>  ggplot( aes(x=model, y=sensitivity, fill="#e01b63")) +
               stat_boxplot(geom = "errorbar",
                           width = 0.25) + 
               geom_boxplot() +
               labs( title = "Cross Validation Results",subtitle = "Comparativa (en t√©rminos de sensitivity) de los mejores 10 modelos en promedio")+
               scale_y_continuous(breaks = seq(from = 0.5, to=1, by=0.05))+
               stat_summary(fun.y=mean, geom="point", shape=23, size=1.5, color="blue", fill="blue") +
               theme( plot.title   = element_text(size=15, face = "bold" ),
                      
                      axis.title.x = element_blank(),
                      axis.text.x  = element_text(size=12,face = "bold", angle = 90),
                      axis.title.y = element_blank(),
                      axis.text.y  = element_text(size=12,face = "bold"),
                      
                      legend.position = "None"
                       )
```

Vamos a considerar como üèÜ **modelo ganador** üèÜ el primer modelo: **0.5 - 0.001**. 

Este es el mejor modelo porque:

- Tiene la mediana y la media m√°s altas (**~0.94-0.95**).

- Existe poca variabilidad

Por tanto los hiperpar√°metros de nuestro modelo ganador son **minbucket = 0.5** y **complejidad de poda = 0.001**

#### Modelo ganador

En primer lugar vamos a generar este modelo ganador y vamos a ver tambi√©n la importancia de las variables en este modelo.

```{r}
#| message: false
#| warning: false
#| 
best_tree <- rpart(data = attrition_train_balance, 
                   attrition ~ .,
                   control = rpart.control(minbucket = as.integer((0.5*nrow(attrition_train_balance))/100), cp = 0.001))
```


```{r}
#| code-fold: true
#| message: false
#| warning: false


imp <- best_tree$variable.importance
imp_data <- as.data.frame(imp)
imp_data <- tibble::rownames_to_column(imp_data, "Variables") |>  arrange(desc(imp))
imp_data$Variables <- as.factor(imp_data$Variables)


imp_data |> mutate(Variables = fct_reorder(Variables, imp)) |>
ggplot( aes(x=Variables, y=imp)) +
geom_bar(stat="identity", fill="#37d8d5", width=.7)+
coord_flip() +
theme_bw()+
theme(axis.title.x = element_blank(),
      axis.text.x  = element_text(size=10,face = "bold"),
      axis.title.y = element_blank(),
      axis.text.y  = element_text(size=10,face = "bold"),
      legend.position = "None"
      )
```

Gracias a este gr√°fico podemos observar cuales ser√°n las variables que potencialmente m√°s vaya a utilizar el √°rbol, y es que no utiliza todas las variables si no que ir√° seleccionando las mejores.

Destaca sobre todas las variables la importancia de la variable **overtime**.

### Predicciones en conjunto test

Inicialmente se llev√≥ a cabo una separaci√≥n entre Train y Test en el conjunto de los datos. Una vez entrenado y obtenido el modelo ganador con los datos de Train, ahora se aplicar√° este conjunto de Test reservado al modelo ganador para evaluar nuestro modelo y sacar conclusiones de estas predicciones.

```{r}
pred <- predict(best_tree, newdata = attrition_test, type = "class")
```


#### Matriz de confusi√≥n

::: callout-note
## Apunte sobre el auc

A la hora de calcular el auc, esta m√©trica nos proporciona los valores inversos por lo que vamos a utilizar la predicci√≥n de none en este caso que ser√≠a la correspondiente a attrition.
:::

```{r}
#| code-fold: true
#| message: false
#| warning: false
# Matriz de Confusion
conf_mat <- confusionMatrix(pred, attrition_test$attrition, positive = "1")

# Accuracy
accuracy <- conf_mat[["overall"]][["Accuracy"]]
# Sensitivity
sensitivity <- conf_mat[["byClass"]][["Sensitivity"]]
# Specificity
specificity <- conf_mat[["byClass"]][["Specificity"]]
# AUC
pred <- as.data.frame(predict(best_tree, attrition_test, type="prob"))
pred$real_class <- as.factor(attrition_test$attrition)
pred <- pred |> rename(prob_attrition = "1", prob_none = "0")
auc <- pred |> roc_auc(truth = real_class, prob_none) 

auc_value <- auc |> pull(.estimate)

statistics <- data.frame (metrics  = c("accuracy","sensitivity","specificity","auc"),
                          values = c(accuracy,sensitivity,specificity,auc_value)
                          )
knitr::kable(statistics , col.names = gsub("[.]", " ", names(statistics)))
```


#### Curva ROC

::: callout-note
## Apunte sobre el auc en la curva roc

A la hora de realizar los c√°lculos de la curva roc con el paquete roc_curve, las clases est√°n invertidas por tanto para obtener el c√°lculo correcto de la curva roc se va a hacer con la probabilidad de no attrition en vez de la probabilidad de un 1. Adem√°s, para evidenciar que esto es correcto se va a utilizar otro paquete de curva roc en el que se va a generar este gr√°fico de forma normal
:::

```{r}
#| code-fold: true
#| message: false
#| warning: false
#---------------------------------------------------------------------------------------------------------------------------
# Prediccions en formato prob
predicted <- as.data.frame(predict(best_tree, attrition_test, type="prob"))
# Uni√≥n de etiqueta real
predicted$real_class <- as.factor(attrition_test$attrition)
# Rename
predicted <- predicted |>  rename(prob_attrition = "1", prob_none = "0")
#----------------------------------------------------------------------------------------------------------
# Curva ROC: etiqueta real vs probabilid de 0. (Se invierte la clase)
roc_curve <- predicted |> roc_curve(truth = real_class, prob_none)

# √Årea debajo de la curva.
auc <- predicted |>  roc_auc(truth = real_class, prob_none)
auc <- auc |>  pull(.estimate)

# Curva ROC con otro paquete para comprobar que est√° mal calculada hasta el momento
# Calculate ROC curve
roc_curve2 <- roc(predicted$real_class, predicted$prob_attrition)

#---------------------------------------------------------------------------------------------------------------------------
# Gr√°fico Curva ROC- (con paquete habitual)
ggplot(roc_curve, aes(x = 1 - specificity, y = sensitivity)) +
  #scale_x_reverse() +
# L√≠nea de tama√±o 2, color azul y transparencia 0.85
geom_line(lwd = 1, alpha = 0.85, color = "#e01b63") +
# A√±adimos diagonal de l√≠nea tipo 4
geom_abline(lty = "dashed") +
# Hacemos el gr√°fico cuadrado
coord_equal() +
# Etiquetas
labs(x = "1 - Specificity",
     y = "Sensitivity",
     title = "CURVA ROC (ggplot - roc_curve)",
     subtitle = glue("AUC = {round(auc, 3)}"))+
theme_minimal() +
# Tema
theme(axis.title.y = element_text(face="bold"),
      axis.title.x = element_text(face="bold"),
      plot.title = element_text(size =12,face="bold"),
      plot.subtitle = element_text(size  =10))

plot(roc_curve2, 
     col = "#37d8d5",
     lwd = 2,
     legacy.axes = TRUE, 
     main = "CURVA ROC (plot - roc)",
     xlab = "1 - Specificity",
     ylab = "Sensitivity",
     print.auc = TRUE,
     font.main = 2,
     font.lab = 2)
```


En cuanto a nuestro modelo de √°rbol de decisi√≥n podemos decir que tiene una buena precisi√≥n, con un **83.03%** de **accuracy**, lo que indica que acierta en la mayor√≠a de los casos. La **sensibilidad** ha mejorado notablemente respecto a la que se ve√≠a en el primer modelo, alcanzando **67.5%**, lo que refleja una mejor capacidad para detectar empleados que dejar√°n la empresa (ha empeorado en el conjunto de test pero esto es algo normal). El valor de **specificity** es alto (**85.14%**), lo que sugiere que el modelo identifica correctamente a aquellos empleados que no se van. Finalmente, el **AUC** de **0.7762** demuestra una capacidad razonable para distinguir entre las dos clases.

```{r}
#| message: false
#| warning: false
#| echo: false

saveRDS(statistics, file = "./outputs/tree_stats.rds")
saveRDS(roc_curve, file = "./outputs/tree_roc_auc.rds")
saveRDS(predicted, file = "./outputs/tree_preds.rds")
```



## KNN K-Nearest Neighbors

### Teor√≠a del modelo

### Librer√≠as necesarias

```{r}
#| message: false
#| warning: false
#| 
# Borramos variables del environment
rm(list = ls())
library(tidyverse)  # Depuraci√≥n datos
library(skimr)      # Resumen num√©rico
library(ggplot2)    # Gr√°ficos
library(tidymodels) # Modelos
library(rpart)      # CART
library(rpart.plot) # Graficar √°rbol
library(caret)      # Matriz de Confusion
library(glue)       # pegar texto + variables f√°cilmente
library(DT)         # Para mostrar tabla (formatStyle)
library(ROSE)       # Para Oversampling
library(outliers)   # Para funcion scores (receta)
library(lubridate)  # Fechas
library(timeDate)   # Festivos (receta)
library(hrbrthemes) # Tema ggplot
library(corrplot)   # Plot m.correl
library(kknn)       # ajuste knn
library(themis)     # Oversampling
```


### Datos iniciales

En primer lugar se importan los datos que han sido depurados previamente.

```{r}
#| message: false
#| warning: false

attrition_data <- readRDS("./data/attrition_data.rds")
```


### Train y test

Al igual que en el modelo de los √°rboles de decisi√≥n, en **KNN** tambi√©n tenemos que realizar la divisi√≥n de los datos. **80%** de los datos formar√°n parte del conjunto de entrenamiento (**Train**) y el **20%** restante formar√°n el conjunto de **Test**.


```{r}
#| code-fold: false
#| message: false
#| warning: false
#| 
set.seed(200900)

attrition_split <- initial_split(attrition_data, strata = attrition, prop = 0.80)

# Train
attrition_train <- training(attrition_split)
# Reparto en Train
attrition_train |> group_by(attrition) |> summarise(n = n()) |> mutate(prop = n /sum(n))

# Test
attrition_test <- testing(attrition_split)
# Reparto en test
attrition_test |> group_by(attrition) |> summarise(n = n()) |> mutate(prop = n /sum(n))
```

### Receta 

La **receta** es una serie de instrucciones que nos permite llevar a cabo diferentes **transformaciones en los datos**. Algunas de estas transformaciones son la asignaci√≥n de roles; la recategorizaci√≥n de variables; el tratamiento de valores extremos o nulos; la estandarizaci√≥n de los datos por rango y/o normalizaci√≥n etc.

Es un proceso equivalente en muchos casos a la depuraci√≥n de los datos que se ha hecho previamente, por lo que la receta que se va a desarrollar est√° orientada a unos datos que ya han sido tratados.

La receta que se construye **prepara los datos para predecir la variable attrition**, eliminando el identificador del conjunto de datos a la hora del modelado y el bake final, tambi√©n **agrupa categor√≠as poco frecuentes**, **limpia variables redundantes o sin variaci√≥n**, **escala valores num√©ricos**, **convierte categ√≥ricos a dummies** y aplica oversampling para **balancear la variable objetivo** (attrition).

```{r}
#| warning: false
#| message: false
# Receta completa
attrition_recipe <-
  # F√≥rmula y datos
  recipe(data = attrition_train, attrition ~ .) |> 
  # Roles/borrado de la variable
  update_role(employeeid, new_role = "ID") |> update_role_requirements(role = "ID", bake = FALSE) |> 
  # Categoria Other 
  step_other(all_nominal_predictors(), threshold = 0.005) |>
  # Filtro de correlaci√≥n
  step_corr(all_numeric_predictors(), threshold = 0.95) |>
  # Filtro 0 varianza
  step_zv(all_predictors()) |>
  # Min / Max
  step_range(all_numeric_predictors(), min = 0, max = 1) |>
  # nominales las pasemos a dummy 1/0
  step_dummy(all_nominal_predictors(), -all_outcomes()) |>
  # Oversampling
  step_upsample(attrition, over_ratio = 1)
```


Tras **aplicar la receta a los datos**, estos quedan de la siguiente forma:

```{r}
#| warning: false
#| message: false
#| echo: false

attrition_train_baked <- bake(attrition_recipe |> prep(), new_data = NULL)

datatable(attrition_train_baked, rownames = FALSE, filter = "top",options = list(pageLength = 10)) |> formatStyle(names(attrition_train_baked), lineHeight = "65%")
```

Observamos como ahora nuestras **variables num√©ricas** quedan bien representadas con **valores entre 0 y 1** (necesario para KNN) y tambi√©n como se han creado algunas variables dummies.

Finalmente, al aplicar oversampling al conjunto de datos nuestra variable objetivo ha quedado distribuida de la siguiente forma:

```{r}
#| code-fold: true
#| message: false
#| warning: false

attrition_train_baked |> group_by(attrition) |> summarise(n = n(), Porc = round(n()*100.0/nrow(attrition_train_baked),2)) |> 
ggplot(aes(x = attrition, y = n, fill = attrition)) +
geom_col(position = "dodge", alpha =0.8) +
ylim(c(0, 2600)) +
geom_text(aes(label = paste(n," (",Porc,"%)", sep ="")),colour = "black", size = 4,vjust = -0.5, position = position_dodge(.9)) +
scale_fill_manual(values = c("#023047","#C2185B")) +
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12),
      legend.position = "None"
      )
```

Por lo que ya tenemos una distribuci√≥n correcta de los datos con la que trabajar

### K-Fold cross validation

Inicialmente indicamos el numero de particiones y las repeticiones que haremos para hacer el cross-validation

```{r}
set.seed(200900)

folds <- vfold_cv(attrition_train, v = 5, strata = attrition, repeats = 3)
```

Despu√©s se crea el modelo sin ning√∫n tipo de par√°metros fijo

```{r}
knn_model <- nearest_neighbor(mode = "classification",
                              neighbors = tune("k"),
                              weight_func = tune("weight"),
                              dist_power = tune("dist")) |>
             set_engine("kknn")
```

Una vez hecha la validaci√≥n cruzada y creado el modelo ya se puede empezar a crear el flujo de trabajo

```{r}
attrition_wflow <- workflow() |> add_recipe(attrition_recipe) |> add_model(knn_model)
```


#### Grid de hiperpar√°metros

A la hora de entrenar el modelo se utilizan distintos hiperpar√°metros. Se va a crear un grid con los diferentes valores que pueden tomar estos hiperpar√°metros para despu√©s evaluar cual es el mejor modelo y con que valores lo hemos obtenido.

- En primer lugar vamos a definir el n√∫mero de vecinos, tomar√° valores desde 100 hasta 500 de 100 en 100.

- Definiremos tambi√©n la funci√≥n que va a emplear el kernel para promediar el peso
    - **Inv**: Promedio por el inverso de la distancia.
    - **Gaussian**: Promedio seg√∫n los puntos m√°s cercanos al centro.
    - **Epanechnikov**: Proporciona eficiencia y rendimiento.
    - **Biweight**: Ignora a los vecinos mas alejados.
    
- Par√°metro dist, que decide el tipo de distancia, variable entre 1 y 2 (distancia Manhattan y Eucl√≠dea, respectivamente)

Tendremos inicialmente 40 posibles modelos.

```{r}
#| message: false
#| warning: false
grid_knn <- expand_grid(k = seq(100, 500, by = 100),
                        weight = c("inv","gaussian","epanechnikov","biweight"),
                        dist = c(1, 2))
```


```{r}
#| message: false
#| warning: false
#| echo: false
datatable(grid_knn, 
          rownames = FALSE, 
          filter = "top",
          options = list(pageLength = 10, dom = "tip")) |> formatStyle(names(grid_knn))
```


### Entrenamiento 

La receta ha sido creada, tambi√©n se han definido las particiones entre train y test, el modelo se ha generado sin par√°metros y se ha generado el grid de hiperpar√°metros que se aplicar√°.

Como resultado de esto tenemos inicialmente 40 modelos que tras aplicar cross validation, nos queda en 40x3x5 = 600 modelos jej ü´†ü´†


```{r}
#| message: false
#| warning: false
#| eval: false
attrition_knn_fit_tune <- attrition_wflow |> 
                       tune_grid(resamples = folds, 
                                 grid = grid_knn,
                                 control = control_grid(verbose = TRUE),
                                 metrics = metric_set(accuracy, sens, spec, roc_auc))
# Guardo resultados
saveRDS(attrition_knn_fit_tune, file = "./outputs/attrition_knn_fit_tune.rds")
```


```{r}
#| message: false
#| warning: false
# Cargamos los datos obtenidos
attrition_knn_fit_tune <- readRDS("./outputs/attrition_knn_fit_tune.rds")

# M√©tricas tratadas en cv_results 
attrition_cv_results <- attrition_knn_fit_tune |> collect_metrics(summarize = FALSE) |> 
              select(rep = id, fold = id2, k, weight, dist , metric = .metric, value = .estimate ) |>  
              pivot_wider(names_from = metric, values_from = value) |>
              mutate(model = as.factor(paste(k," - ",weight," - ", dist, sep =""))) |>
              arrange(desc(accuracy))
```

Las m√©tricas de los diferentes modelos entrenados son las siguientes: 

```{r}
#| message: false
#| warning: false
#| echo: false
datatable(attrition_cv_results, 
          rownames = FALSE, 
          filter = "top",
          options = list(pageLength = 10, dom = "tip")) |> formatStyle(names(attrition_cv_results))
```


Graficamos los 10 mejores resultados de nuestro entrenamiento de modelos. Para ello vamos a agrupar cada modelo y calcular la media en cada una de las m√©tricas para ver los que son mejores.


```{r}
#| message: false
#| warning: false
#| code-fold: true
#| 
attrition_cv_results_group <- attrition_cv_results |> group_by(model) |>  
                                                      summarise(accuracy = mean(accuracy),
                                                                 sensitivity = mean(sens),
                                                                 specificity = mean(spec),
                                                                 auc = mean(roc_auc)) |>  
                                                      arrange(desc(accuracy)) |>   
                                                      slice_head(n = 10) |> 
                                                      select(model)

attrition_cv_results_top <- attrition_cv_results |>  inner_join(attrition_cv_results_group, by = "model")


attrition_cv_results_top |> ggplot(aes(x=model, y=sens)) +
stat_boxplot(geom = "errorbar",width = 0.25) + 
geom_boxplot( fill = "#e11b63") +
labs( title = "Cross Validation Results",
      subtitle = "Comparativa (en t√©rminos de sensitivity) de los modelos")+
scale_y_continuous(breaks = seq(from = 0.2, to=1, by=0.02))+
stat_summary(fun.y=mean, geom="point", shape=23, size=1.5, color="black", fill="black") +
theme_minimal()+
theme(plot.title= element_text(size=15, face = "bold" ),
      axis.title.x = element_blank(),
      axis.text.x  = element_text(size=10,face = "bold", angle = 90),
      axis.title.y = element_blank(),
      axis.text.y  = element_text(size=10,face = "bold"),
      legend.position = "None"
      )
```

El modelo "100 - biweight - 2" es el mejor en esta comparativa.

- **Sensibilidad m√°s alta en mediana**: es crucial para detectar bien los positivos (en este problema es lo que nos interesa).

- **Menor dispersi√≥n**: predicciones estables.

Los hiperpar√°metros de este modelo son 100 como n√∫mero de vecinos, biweight como funci√≥n que utilice el kernel para promediar los pesos y distancia eucl√≠dea.

Por tanto el üèÜ **modelo ganador** üèÜ es el de la combinaci√≥n `k = 100` + `weight_func = "biweight"` + `dist = 2`

### Modelo ganador

Generamos el modelo ganador

```{r}
best_knn_model <- nearest_neighbor(mode = "classification", 
                              neighbors = 100,
                              weight_func = "biweight", 
                              dist_power = 2) |>
                  set_engine("kknn")
```

Una vez generado el modelo ganador construimos el flujo de trabajo sobre este modelo

```{r}
best_attrition_wflow <-  workflow() |>  add_recipe(attrition_recipe) |>  add_model(best_knn_model)
```

Ajustamos el modelo al conjunto de datos de entrenamiento

```{r}
best_attrition_knn_fit <- best_attrition_wflow |> fit(data = attrition_train)
```


### Predicciones en test

Se va a aplicar el modelo ganador al conjunto de test que se reserv√≥ al comenzar a tratar los datos para el KNN.

```{r}
#| message: false
#| warning: false

attrition_test <- augment(best_attrition_knn_fit, attrition_test)
```

#### Matriz de confusi√≥n 

```{r}
#| message: false
#| warning: false
# Matriz de Confusion
conf_mat <- confusionMatrix(attrition_test$.pred_class, attrition_test$attrition, positive = "1")
# Accuracy
accuracy <- conf_mat[["overall"]][["Accuracy"]]
# Sensitivity
sensitivity <- conf_mat[["byClass"]][["Sensitivity"]]
# Specificity
specificity <- conf_mat[["byClass"]][["Specificity"]]
# AUC
auc <- attrition_test |>  roc_auc(truth = attrition, .pred_0)
auc_value <- auc |> pull(.estimate)

statistics <- data.frame (metrics  = c("accuracy","sensitivity","specificity","auc"),
                          values = c(accuracy,sensitivity,specificity,auc_value)
                          )
knitr::kable(statistics , col.names = gsub("[.]", " ", names(statistics)))
```


#### Curva ROC y AUC

Al igual que en el modelo de √°rbol de decisi√≥n, en KNN tambi√©n al realizar el c√°lculo del auc en la curva roc sale a la inversa por lo que para obtener los valores correctos indicaremos la clase 0 en vez de la clase 1 que es la que nos interesa predecir.

```{r}
#| code-fold: true
#| message: false
#| warning: false
# Curva ROC: etiqueta real vs probabilid de 1
roc_curve_knn <- attrition_test |> roc_curve(truth = attrition, .pred_0)

#-----------------------------------------------------------------
# Gr√°fico Curva ROC
#-----------------------------------------------------------------

ggplot(roc_curve_knn, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(lwd = 1, alpha = 0.85, color = "#e01b63") +
geom_abline(lty = "dashed") +
coord_equal() +
labs(x = "1 - Specificity",
     y = "Sensitivity",
     title = "CURVA ROC",
     subtitle = glue("AUC = {round(auc_value, 3)}"))+
theme_minimal()+
theme(axis.title.y = element_text(face="bold"),
      axis.title.x = element_text(face="bold"),
      plot.title = element_text(size =15,face="bold"),
      plot.subtitle = element_text(size  =10))
```


```{r}
#| message: false
#| warning: false
#| echo: false

saveRDS(statistics, file = "./outputs/knn_stats.rds")
saveRDS(roc_curve_knn, file = "./outputs/knn_roc_auc.rds")
saveRDS(attrition_test, file = "./outputs/knn_preds.rds")
```


### ¬øC√≥mo vamos?

```{r}
#| message: false
#| warning: false
#| code-fold: true 
#| 
statistics_tree <- readRDS("./outputs/tree_stats.rds")
statistics_tree$model <- "√Årbol"

roc_curve_tree <- readRDS("./outputs/tree_roc_auc.rds")
roc_curve_tree$model <- "√Årbol"

statistics_knn <- readRDS("./outputs/knn_stats.rds")
statistics_knn$model <- "KNN"

roc_curve_knn <- readRDS("./outputs/knn_roc_auc.rds")
roc_curve_knn$model <- "KNN"

statistics <- rbind(statistics_knn,statistics_tree)
roc_curve <- rbind(roc_curve_knn,roc_curve_tree)
```

```{r}
#| message: false
#| warning: false
#| echo: false

# Metricas de la matriz de confusi√≥n
datatable(statistics |> arrange(metrics, values, model), rownames = FALSE, filter = "top",options = list(pageLength = 2)) |> formatStyle(names(statistics), lineHeight = "65%")
```

```{r}
#| message: false
#| warning: false
#| code-fold: true
statistics |> ggplot(aes(x = metrics , y= values, fill = model)) +
               geom_bar( alpha = 0.85, position = "dodge", stat = "identity") +
               scale_fill_manual(values = c("√Årbol" = "darkslategray1", "KNN" = "indianred1", "Red Neuronal" = "palegreen2", "SVM Lineal" = "pink", "SVM Polinomial" = "darkgoldenrod1", "Ensamblado" = "darkslategray")) +
               labs(#x = "m√©trica", 
                    #y = "frecuencia absoluta", 
                    title = "Comparativa Modelos",
                    subtitle = "Resultados de las m√©tricas de cada modelo"
                )+
                theme_minimal()+theme_ipsum(base_family = "Arial")+
                theme(axis.title.y = element_blank(),
                      axis.title.x = element_blank(),
                      axis.text.x = element_text(size = 12,face = "bold"),
                      plot.title = element_text(size =15,face="bold"),
                      plot.subtitle = element_text(size  =10))
```

```{r}
#| message: false
#| warning: false
#| code-fold: true

# Gr√°fico Curva ROC
ggplot(roc_curve, aes(x = 1 - specificity, y = sensitivity, colour=model)) +
# L√≠nea de tama√±o 2, color azul y transparencia 0.85
geom_line(lwd = 1, alpha = 0.85) +
# A√±adimos diagonal de l√≠nea tipo 4
geom_abline(lty = "dashed") +
# Hacemos el gr√°fico cuadrado
coord_equal() +
# Color
scale_colour_manual(values = c("√Årbol" = "darkslategray1", "KNN" = "indianred1", "Red Neuronal" = "palegreen2", "SVM Lineal" = "pink", "SVM Polinomial" = "darkgoldenrod1", "Ensamblado" = "darkslategray")) +
# Etiquetas
labs(x = "1 - Specificity",
     y = "Sensitivity",
     title = "Comparativa Modelos",
     subtitle = "Curva ROC (test) de cada modelo empleado")+
theme_minimal()+
# Tema
  theme(axis.title.y = element_text(face="bold"),
      axis.title.x = element_text(face="bold"),
      plot.title = element_text(size =15,face="bold"),
      plot.subtitle = element_text(size  =10))
```


## SVM Support vector machine - Kernel lineal

### Paquetes necesarios

```{r}
#| message: false
#| warning: false

rm(list = ls())
library(tidyverse)  # Depuraci√≥n datos
library(skimr)      # Resumen num√©rico
library(ggplot2)    # Gr√°ficos
library(tidymodels) # Modelos
library(rpart)      # CART
library(rpart.plot) # Graficar √°rbol
library(caret)      # Matriz de Confusion
library(glue)       # pegar texto + variables f√°cilmente
library(DT)         # Para mostrar tabla (formatStyle)
library(ROSE)       # Para Oversampling
library(outliers)   # Para funcion scores (receta)
library(lubridate)  # Fechas
library(timeDate)   # Festivos (receta)
library(hrbrthemes) # Tema ggplot
library(corrplot)   # Plot m.correl
library(kknn)       # ajuste knn
library(themis)     # Oversampling
library(e1071)      # SVM
```


### Datos iniciales

```{r}
#| message: false
#| warning: false

attrition_data <- readRDS("./data/attrition_data.rds")
```

En el caso de SVM de Kernel lineal eliminaremos el ID

```{r}
#| message: false
#| warning: false

attrition_data <- attrition_data |> select(-employeeid)
```

Originalmente nuestra variable attrition que es la variable objetivo est√° distribuida de la siguiente forma:

```{r}
#| message: false
#| warning: false
#| code-fold: true
#| 
attrition_data |> group_by(attrition) |> summarise(n = n(), Porc = round(n()*100.0/nrow(attrition_data),2)) |> 
ggplot(aes(x = attrition, y = n, fill = attrition)) +
geom_col(position = "dodge", alpha =0.8) +
geom_text(aes(label = paste(n," (",Porc,"%)", sep ="")),colour = "black", size = 4,vjust = -0.5, position = position_dodge(.9)) +
ylim(0,5300)+
scale_fill_manual(values = c("#023047","#C2185B")) +
labs(title = "Distribuci√≥n del target",
     subtitle = "Reparto de niveles de la variable attrition")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12),
      legend.position = "None"
      )
```



### Train y test

Realizamos la partici√≥n de nuestro conjunto de datos en **80% train** y **20% test**

```{r}
#| warning: false
#| message: false
# Semilla
set.seed(200900)
# Partici√≥n 20% de test
attrition_split <- initial_split(attrition_data, strata = attrition, prop = 0.80)
# Train
attrition_train <- training(attrition_split)
# Test
attrition_test <- testing(attrition_split)
```

### Preparaci√≥n de los datos

#### Receta

En el caso de esta receta no vamos a modificar el rol del ID debido a que lo hemos borrado en pasos anteriores, pero el resto de receta si que se va a mantener para SVM ya que necesitamos disponer de variables num√©ricas as√≠ como de modificar la frecuencia de nuestra variable target en el conjunto de datos.

```{r}
#| warning: false
#| message: false
# Receta completa
attrition_recipe <-
  # F√≥rmula y datos
  recipe(data = attrition_train, attrition ~ .) |>
  # Categoria Other 
  step_other(all_nominal_predictors(), threshold = 0.005) |>
  # Filtro de correlaci√≥n
  step_corr(all_numeric_predictors(), threshold = 0.95) |>
  # Filtro 0 varianza
  step_zv(all_predictors()) |>
  # Min / Max
  step_range(all_numeric_predictors(), min = 0, max = 1) |>
  # nominales las pasemos a dummy 1/0
  step_dummy(all_nominal_predictors(), -all_outcomes()) |>
  # Oversampling
  step_upsample(attrition, over_ratio = 1)
```

Esta receta se va a aplicar a ambas particiones del conjunto de datos que hemos hecho en el paso anterior:

```{r}
#| message: false
#| warning: false

attrition_train_baked <- bake(attrition_recipe |> prep(), new_data = NULL)

attrition_test_baked <- bake(attrition_recipe |> prep(), new_data = attrition_test)
```

Tras haber aplicado nuestra receta al conjunto de los datos este queda de la siguiente forma:

```{r}
#| message: false
#| warning: false
#| echo: false
#  Mostrar tabla con filtros
datatable(attrition_train_baked, rownames = FALSE, filter = "top",options = list(pageLength = 10)) |> formatStyle(names(attrition_train_baked), lineHeight = "65%")
```

Y la variable attrition ahora est√° distribuida de la siguiente manera:

```{r}
#| message: false
#| warning: false
#| code-fold: true
#| 
attrition_train_baked |> group_by(attrition) |> summarise(n = n(), Porc = round(n()*100.0/nrow(attrition_train_baked),2)) |> 
ggplot(aes(x = attrition, y = n, fill = attrition)) +
geom_col(position = "dodge", alpha =0.8) +
geom_text(aes(label = paste(n," (",Porc,"%)", sep ="")),colour = "black", size = 4,vjust = -0.5, position = position_dodge(.9)) +
ylim(0,5300)+
scale_fill_manual(values = c("#023047","#C2185B")) +
labs(title = "Distribuci√≥n del target",
     subtitle = "Reparto de niveles de la variable attrition")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12),
      legend.position = "None"
      )
```

### K-Fold cross validation

Utilizaremos de nuevo la funci√≥n proporcionada en la asignatura de aprendizaje autom√°tico para poder realizar este cross validation sobre nuestros datos de entrenamiento.

Se van a realizar 5 divisiones y 3 repeticiones por tanto van a haber 15 pares de conjunto de entrenamiento y validaci√≥n.

```{r}
#| message: false
#| warning: false

source("./funciones/utils.r")

attrition_train_data_cv <- fold_rep_for_cv(data = attrition_train_baked, folds = 5, reps = 3, target = "attrition", seed = 200900) 
```

### Hiperpar√°metros en SVM lineal

Como estamos creando un modelo de SVM con kernel lineal, √∫nicamente vamos a tener como hiperpar√°metro el coste C para la regularizaci√≥n. Se va a construir un grid que contenga diferentes valores para este hiperpar√°metro:

```{r}
#| message: false
#| warning: false

svm_cost_list <- c(0.01,0.05,0.1,0.2,0.5,1,2,5,10)

```

### Entrenamiento

```{r}
#| message: false
#| warning: false
#| code-fold: true
#| eval: false

# Tabla para guardar los resultados del cross validation
cv_results <-  data.frame(rep          = character(),
                           fold         = character(),
                           cost         = double(),
                           accuracy     = double(),
                           sensitivity  = double(),
                           specificity  = double(),
                           auc          = double())

for (data_fold in attrition_train_data_cv)
{
    #---------------------------------
    # Conjuntos de Train y Val
    #---------------------------------
    rep_value <- data_fold[["repeat"]]
    fold_value <- data_fold[["fold"]]
    train <- data_fold[["train_data"]]
    val <- data_fold[["validation_data"]]
    #---------------------------------
    # Tuneado SVM lineal
    #---------------------------------
    for (cost_value in svm_cost_list)
    {
            # ---------------------------------
            #           SVM model
            # --------------------------------
            svm_model <- svm(data=train,
                             kernel = "linear",
                             attrition ~ .,
                             probability = TRUE,
                             cost = cost_value)
            # Predicciones en Val
            pred <- predict(svm_model, newdata = val, type = "class") 
            # Matriz de confusi√≥n
            conf_mat <- confusionMatrix(pred, val[["attrition"]], positive = "1")
            # Accuracy
            accuracy_value <- conf_mat[["overall"]][["Accuracy"]]
            # Sensitivity
            sensitivity_value <- conf_mat[["byClass"]][["Sensitivity"]]
            # Specificity
            specificity_value <- conf_mat[["byClass"]][["Specificity"]]
            # Curva ROC y AUC
            pred <- predict(svm_model,newdata = val, probability=TRUE)
            pred <- as.data.frame(attr(pred, "prob"))
            pred$real_class <- as.factor(val[["attrition"]])
            auc <- pred |>  roc_auc(truth = real_class, "0")
            auc_value <- auc |> pull(.estimate)
            # --------------------- 
            # Guardamos resultados
            # ---------------------
            cv_results[nrow(cv_results) + 1,] <- c( rep_value,
                                                    fold_value,
                                                    cost_value,
                                                    round(accuracy_value,6),
                                                    round(sensitivity_value,6),
                                                    round(specificity_value,6),
                                                    round(auc_value,6))
            # Para mostrar por pantalla lo que  se va ejecutando
            texto <- paste("Repeat: ",rep_value," - Fold: ",fold_value, " - Cost: ",cost_value, sep = ""  )
            print(texto)
            print("-----------------------")
    }
}
# Conversi√≥n a formatos correctos
cv_results$cost <- as.factor(cv_results$cost)
cv_results$accuracy <- as.double(cv_results$accuracy)
cv_results$sensitivity <- as.double(cv_results$sensitivity)
cv_results$specificity <- as.double(cv_results$specificity)
cv_results$auc <- as.double(cv_results$auc)

# Guardamos
saveRDS(cv_results, file = "./outputs/cv_svm_linear_results.rds")
```

Los resultados de nuestro entrenamiento son los siguientes:

```{r}
#| message: false
#| warning: false
#| echo: false

cv_results <- readRDS("./outputs/cv_svm_linear_results.rds")

datatable(cv_results, rownames = FALSE, filter = "top",options = list(pageLength = 10)) |> formatStyle(names(cv_results), lineHeight = "65%")
```

Graficamos los resultados de nuestro entrenamiento de modelos. Para ello vamos a agrupar cada modelo seg√∫n el par√°metro de coste para la regularizaci√≥n y calcularemos las m√©tricas a partir de la media de las distintas iteraciones.

```{r}
#| message: false
#| warning: false
#| echo: false
cv_results |> ggplot( aes(x=cost, y=sensitivity)) +
stat_boxplot(geom = "errorbar",width = 0.25) + 
geom_boxplot( fill = "#e11b63") +
labs( title = "Cross Validation Results",
      subtitle = "Comparativa (en t√©rminos de sensitivity) de los modelos")+
scale_y_continuous(breaks = seq(from = 0.2, to=1, by=0.02))+
stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="black", fill="black") +
theme_minimal()+
theme(plot.title= element_text(size=15, face = "bold" ),
      axis.title.x = element_blank(),
      axis.text.x  = element_text(size=10,face = "bold", angle = 90),
      axis.title.y = element_blank(),
      axis.text.y  = element_text(size=10,face = "bold"),
      legend.position = "None"
      )
```

Vamos a elegir como üèÜ **modelo ganador** üèÜ el que utiliza **0.5** como par√°metro de **coste para la regularizaci√≥n**. Observamos que tiene valores bastante similares a los de 10 y 5 pero el que hemos elegido como ganador tiene algo menos de dispersi√≥n.

### Modelo ganador

Generamos el modelo ganador pasando el valor concreto de nuestro hiperpar√°metro:

```{r}
#| message: false
#| warning: false

best_svm_lin <- svm(data=attrition_train_baked,
                     kernel = "linear",
                     attrition ~ .,
                     probability = TRUE,
                     cost = 0.5)
```


### Predicciones en conjunto de test

Se va a aplicar el **SVM** al conjunto de test que se guard√≥ al inicio:

```{r}
#| message: false
#| warning: false

attrition_pred <- predict(best_svm_lin, newdata = attrition_test_baked, type = "class")
saveRDS(attrition_pred, file = "./outputs/svm_lin_preds.rds")
```

#### Matriz de confusi√≥n

```{r}
#| message: false
#| warning: false
#| code-fold: true

# Matriz de confusi√≥n
conf_mat <- confusionMatrix(attrition_pred, attrition_test_baked[["attrition"]], positive = "1")
# Accuracy
accuracy_value <- conf_mat[["overall"]][["Accuracy"]]
# Sensitivity
sensitivity_value <- conf_mat[["byClass"]][["Sensitivity"]]
# Specificity
specificity_value <- conf_mat[["byClass"]][["Specificity"]]
# AUC
attrition_pred <- predict(best_svm_lin,newdata = attrition_test_baked, probability=TRUE)
attrition_pred <- as.data.frame(attr(attrition_pred, "prob"))
attrition_pred$real_class <- as.factor(attrition_test_baked[["attrition"]])

auc <- attrition_pred |>  roc_auc(truth = real_class, "0")
auc_value <- auc |> pull(.estimate)

statistics <- data.frame(metrics  = c("accuracy","sensitivity","specificity","auc"),
                          values = c(accuracy_value,sensitivity_value,specificity_value,auc_value)
                          )
knitr::kable(statistics , col.names = gsub("[.]", " ", names(statistics)))
```

#### Curva ROC y AUC

```{r}
#| code-fold: true
#| message: false
#| warning: false

roc_curve_svm <- attrition_pred |> roc_curve(truth = real_class, "0")

#---------------------------
#   Gr√°fico Curva ROC
# --------------------------
ggplot(roc_curve_svm, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(lwd = 1, alpha = 0.85, color = "#e01b63") +
geom_abline(lty = "dashed") +
coord_equal() +
labs(x = "1 - Specificity",
     y = "Sensitivity",
     title = "CURVA ROC",
     subtitle = glue("AUC = {round(auc_value, 3)}"))+
theme_minimal()+
theme(axis.title.y = element_text(face="bold"),
      axis.title.x = element_text(face="bold"),
      plot.title = element_text(size =15,face="bold"),
      plot.subtitle = element_text(size  =10))
```

### ¬øC√≥mo vamos?

```{r}
#| message: false
#| warning: false
#| echo: false
#| 
saveRDS(attrition_pred, file = "./outputs/svm_lin_predicted.rds")
saveRDS(statistics, file = "./outputs/svm_lin_stats.rds")
saveRDS(roc_curve_svm, file = "./outputs/svm_lin_roc_auc.rds")

svm_lin_stats <- readRDS("./outputs/svm_lin_stats.rds")
svm_lin_stats$model <- "SVM Lineal"

svm_lin_roc_curve <- readRDS("./outputs/svm_lin_roc_auc.rds")
svm_lin_roc_curve$model <- "SVM Lineal"

knn_stats <- readRDS("./outputs/knn_stats.rds")
knn_stats$model <- "KNN"

knn_roc_curve <- readRDS("./outputs/knn_roc_auc.rds")
knn_roc_curve$model <- "KNN"

tree_stats <- readRDS("./outputs/tree_stats.rds")
tree_stats$model <- "√Årbol"

tree_roc_curve <- readRDS("./outputs/tree_roc_auc.rds")
tree_roc_curve$model <- "√Årbol"

model_stats <- rbind(svm_lin_stats, knn_stats, tree_stats)
model_roc_curve <- rbind(svm_lin_roc_curve, knn_roc_curve, tree_roc_curve)
```


```{r}
#| message: false
#| warning: false
#| echo: false

# Matriz de Confusi√≥n (M√©tricas)
datatable(model_stats |> arrange(metrics, values, model), rownames = FALSE, filter = "top",options = list(pageLength = 3)) |> formatStyle(names(statistics), lineHeight = "65%")

model_stats |> ggplot(aes(x = metrics , y= values, fill = model)) +
               geom_bar( alpha = 0.85, position = "dodge", stat = "identity") +
               scale_fill_manual(values = c("√Årbol" = "darkslategray1", "KNN" = "indianred1", "Red Neuronal" = "palegreen2", "SVM Lineal" = "pink", "SVM Polinomial" = "darkgoldenrod1", "Ensamblado" = "darkslategray")) +
               labs(title = "Comparativa Modelos",
                    subtitle = "Resultados de las m√©tricas para cada modelo empleado")+
                theme_minimal()+
                theme(axis.title.y = element_blank(),
                      axis.title.x = element_blank(),
                      axis.text.x = element_text(size = 12,face = "bold"),
                      plot.title = element_text(size =15,face="bold"),
                      plot.subtitle = element_text(size  =10))



# Gr√°fico Curva ROC
ggplot(model_roc_curve, aes(x = 1 - specificity, y = sensitivity, colour=model)) +
geom_line(lwd = 1, alpha = 0.85) +
geom_abline(lty = "dashed") +
coord_equal() +
scale_colour_manual(values = c("√Årbol" = "darkslategray1", "KNN" = "indianred1", "Red Neuronal" = "palegreen2", "SVM Lineal" = "pink", "SVM Polinomial" = "darkgoldenrod1", "Ensamblado" = "darkslategray")) +
labs(x = "1 - Specificity",
     y = "Sensitivity",
     title = "Comparativa Modelos",
     subtitle = "Curva ROC (test) de cada modelo empleado")+
theme_minimal()+
  theme(axis.title.y = element_text(face="bold"),
      axis.title.x = element_text(face="bold"),
      plot.title = element_text(size =15,face="bold"),
      plot.subtitle = element_text(size  =10))
```


## SVM Support vector machine - Kernel polinomial

En este modelo de support vector machine con un kernel polinomial podemos reutilizar diferentes partes de nuestro modelo de kernel lineal.

Se van a reutilizar los siguientes apartados:

- **Paquetes necesarios**
- **Datos iniciales**
- **Train y test**
- **Preparacion de los datos**
- **K-Fold cross validation**

### Hiperpar√°metros en SVM - Kernel polinomial

Seg√∫n la propia definici√≥n del kernel polinomial podemos encontrar m√∫ltiples variables en la ecuaci√≥n que lo define. Estas variables van a representar los hiperpar√°metros que va a recibir el modelo a parte del coste para la regularizaci√≥n que ya exist√≠a en el kernel lineal.

- **El grado del polinomio**: Usaremos grado 2 debido a que a partir de este grado aparece sobreajuste y se vuelve computacionalmente costoso.

- **Gamma**

- **Coef0**

El grid de estos hiperpar√°metros es peque√±o debido a las caracter√≠sticas de los par√°metros y de nuestros datos.

Cuando los valores de coef0 se reducen mucho o aparecen grandes grids con valores de coste m√°s altos, se produce sobreajuste en el modelo. Estos resultados de sobreajuste se basan en obtener un 1 en la sensibilidad de train , es decir que clasifica perfecto los valores de attrition en los datos de entrenamiento y un 0.5 en test, que denota que es igual que predecirlo al azar.

```{r}
#| message: false
#| warning: false
#| 
svm_cost_list <- c(0.01, 0.05, 0.1, 0.2)
svm_gamma_list <- c(0.01, 0.05, 0.1)
svm_coef0_list <- c(0.5, 0.75, 1)
degree_value <- 2
```

### Entrenamiento

Ahora s√≠ con el grid de hiperpar√°metros definido y reutilizando los datos del modelo previo de SVM con Kernel lineal, estamos listos para entrenar nuestro nuevo modelo de SVM con Kernel polinomial

```{r}
#| message: false
#| warning: false
#| eval: false
#| code-fold: true

# Tabla donde almacenaremos resultados CV
cv_results <-  data.frame(rep          = character(),
                           fold         = character(),
                           degree       = double(),                            
                           cost         = double(),
                           gamma        = double(),
                           coef0        = double(),
                           accuracy     = double(),
                           sensitivity  = double(),
                           specificity  = double(),
                           auc          = double())

for (data_fold in attrition_train_data_cv) 
{
    #---------------------------------
    #    Conjuntos de Train y Val
    #---------------------------------
    rep_value <- data_fold[["repeat"]]
    fold_value <- data_fold[["fold"]]
    train <- data_fold[["train_data"]]
    val <- data_fold[["validation_data"]]
    #---------------------------------
    # Tuneado Arbol
    #---------------------------------
    for (cost_value in svm_cost_list)
    {
      for (gamma_value in svm_gamma_list)
      {
        for (coef0_value in svm_coef0_list)
        {
            # --------------------------
            #     SVM polinomial
            # --------------------------
            svm_model <- svm(data=train,
                                  kernel = "polynomial",
                                  attrition ~ .,
                                  probability = TRUE,
                                  cost = cost_value,
                                  gamma = gamma_value,
                                  coef0 = coef0_value,
                                  degree = degree_value
                              )
            # Predicciones en Val
            pred <- predict(svm_model, newdata = val, type = "class") 
            # Matriz de confusi√≥n
            conf_mat <- confusionMatrix(pred, val[["attrition"]], positive = "1")
            # Accuracy
            accuracy_value <- conf_mat[["overall"]][["Accuracy"]]
            # Sensitivity
            sensitivity_value <- conf_mat[["byClass"]][["Sensitivity"]]
            # Specificity
            specificity_value <- conf_mat[["byClass"]][["Specificity"]]
            # Curva ROC y AUC
            pred <- predict(svm_model,newdata = val, probability=TRUE)
            pred <- as.data.frame(attr(pred, "prob"))
            pred$real_class <- as.factor(val[["attrition"]])
            auc <- pred |>  roc_auc(truth = real_class, `0`)
            auc_value <- auc |> pull(.estimate)
            # --------------------
            # Guardamos resultados
            # --------------------
            cv_results[nrow(cv_results) + 1,] <- c( rep_value,
                                                    fold_value,
                                                    degree_value,
                                                    cost_value,
                                                    gamma_value,
                                                    coef0_value,
                                                    round(accuracy_value,6),
                                                    round(sensitivity_value,6),
                                                    round(specificity_value,6),
                                                    round(auc_value,6))
            # Para mostrar por pantalla lo que  se va ejecutando
            texto <- paste("Repeat: ",rep_value,
                           " - Fold: ",fold_value,
                           " - Degree: ",degree_value,
                           " - Cost: ",cost_value,
                           " - Gamma: ",gamma_value,
                           " - Coef0: ",coef0_value, 
                           sep = ""  )
            print(texto)
            print("-----------------------")
        }
      }
    }
}
# Conversi√≥n a formatos correctos
cv_results$cost <- as.factor(cv_results$cost)
cv_results$degree <- as.factor(cv_results$degree)
cv_results$gamma <- as.factor(cv_results$gamma)
cv_results$coef0 <- as.factor(cv_results$coef0)

cv_results$accuracy <- as.double(cv_results$accuracy)
cv_results$sensitivity <- as.double(cv_results$sensitivity)
cv_results$specificity <- as.double(cv_results$specificity)
cv_results$auc <- as.double(cv_results$auc)
# Model
cv_results <- cv_results |> mutate(model = paste("Degree: ",degree," - Cost: ",cost," - Gamma: ",gamma," - Coef0: ",coef0, sep =" "))
# Guardamos
saveRDS(cv_results, file = "./outputs/cv_svm_poli_results.rds")
```

Se han generado en total 540 modelos de SVM polinomial:

```{r}
#| message: false
#| warning: false
#| echo: false

cv_results <- readRDS("./outputs/cv_svm_poli_results.rds")

datatable(cv_results, rownames = FALSE, filter = "top",options = list(pageLength = 10)) |> formatStyle(names(cv_results), lineHeight = "65%")
```


Vamos a mostrar los 10 mejores modelos agrupados por los hiperpar√°metros en funci√≥n de la sensibilidad:

```{r}
#| message: false
#| warning: false
#| code-fold: true

# Mejores 10 modelos en promedio de sensitivity
best_mean_cv_results <- cv_results |> 
                        group_by(model)|> summarise(sensitivity = mean(sensitivity))|> 
                        arrange(desc(sensitivity)) |>
                        slice(1:10)
# Plot
cv_results |> inner_join(best_mean_cv_results,by = "model")|>
ggplot( aes(x=model, y=sensitivity.x)) +
stat_boxplot(geom = "errorbar",width = 0.25) + 
geom_boxplot( fill = "#ff8fab") +
labs( title = "Cross Validation Results",
      subtitle = "Comparativa (en t√©rminos de sensitivity) de los modelos")+
scale_y_continuous(breaks = seq(from = 0.5, to=1, by=0.05))+
stat_summary(fun.y=mean, geom="point", shape=23, size=1.5, color="#023047", fill="#023047") +
theme_minimal()+
theme(plot.title= element_text(size=15, face = "bold" ),
      axis.title.x = element_blank(),
      axis.text.x  = element_text(size=7,face = "bold", angle = 90),
      axis.title.y = element_blank(),
      axis.text.y  = element_text(size=10,face = "bold"),
      legend.position = "None"
      )

```

Por tanto el üèÜ **modelo ganador** üèÜ ser√° el que utiliza **Degree: 2, Cost:0.2, Gamma: 0.1 y coef0:0.75** como hiperpar√°metros.

### Modelo ganador

```{r}
#| message: false
#| warning: false

best_svm_poli <- svm(data=attrition_train_baked,
                          kernel = "polynomial",
                          attrition ~ .,
                          probability = TRUE,
                          cost = 0.2,
                          gamma = 0.1,
                          coef0 = 0.75,
                          degree = 2)

saveRDS(best_svm_poli, file = "./outputs/best_svm_poli.rds")
```

### Predicciones en test

```{r}
#| message: false
#| warning: false
#| 
attrition_pred <- predict(best_svm_poli, newdata = attrition_test_baked, type = "class")

saveRDS(attrition_pred, file = "./outputs/svm_poli_preds.rds")
```

#### Matriz de confusi√≥n

```{r}
#| message: false
#| warning: false
#| code-fold: true
# Matriz de confusi√≥n
conf_mat <- confusionMatrix(attrition_pred, attrition_test_baked[["attrition"]], positive = "1")
# Accuracy
accuracy_value <- conf_mat[["overall"]][["Accuracy"]]
# Sensitivity
sensitivity_value <- conf_mat[["byClass"]][["Sensitivity"]]
# Specificity
specificity_value <- conf_mat[["byClass"]][["Specificity"]]
# AUC
attrition_pred <- predict(best_svm_lin,newdata = attrition_test_baked, probability=TRUE)
attrition_pred <- as.data.frame(attr(attrition_pred, "prob"))
attrition_pred$real_class <- as.factor(attrition_test_baked[["attrition"]])

auc <- attrition_pred |>  roc_auc(truth = real_class, "0")
auc_value <- auc |> pull(.estimate)

statistics <- data.frame(metrics  = c("accuracy","sensitivity","specificity","auc"),
                          values = c(accuracy_value,sensitivity_value,specificity_value,auc_value)
                          )
knitr::kable(statistics , col.names = gsub("[.]", " ", names(statistics)))
```

#### Curva ROC Y AUC

```{r}
#| message: false
#| warning: false
#| code-fold: true
#| 
# Curva ROC: etiqueta real vs probabilid de 1
roc_curve_svm <- attrition_pred |> roc_curve(truth = real_class, `0`)
# ----------------------
#   Gr√°fico Curva ROC
# ----------------------
ggplot(roc_curve_svm, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(lwd = 1, alpha = 0.85, color = "#e01b63") +
geom_abline(lty = "dashed") +
coord_equal() +
labs(x = "1 - Specificity",
     y = "Sensitivity",
     title = "CURVA ROC",
     subtitle = glue("AUC = {round(auc_value, 3)}"))+
theme_minimal()+
theme(axis.title.y = element_text(face="bold"),
      axis.title.x = element_text(face="bold"),
      plot.title = element_text(size =15,face="bold"),
      plot.subtitle = element_text(size  =10))
```

Aunque las m√©tricas globales del modelo son buenas, observamos que la sensibilidad en validaci√≥n sigue siendo inferior a la que se obtiene en el conjunto de entrenamiento. Esto indica que podr√≠a seguir existiendo cierto sobreajuste, ya que el modelo parece estar capturando patrones espec√≠ficos del conjunto de entrenamiento, en lugar de generalizar correctamente.

Sin embargo, se ha mejorado este problema respecto a la primera versi√≥n del modelo. Inicialmente, la sensibilidad era de solo 0.5, lo que indicaba que era como tirar una moneda al aire.

Gracias a los ajustes realizados en el grid de hiperpar√°metros se ha conseguido mejorar a 0.75 pero queremos mejorar algo estos valores as√≠ que vamos a tunear m√°s los hiperpar√°metros.

Para ello lo que vamos a hacer es modificar el par√°metro gamma (permite una mayor generalizaci√≥n cuanto mas bajo es) y ver cual es el que mejor predice:

```{r}
#| message: false
#| warning: false
#| code-fold: true

gamma1_svm_poli <- svm(data=attrition_train_baked,
                          kernel = "polynomial",
                          attrition ~ .,
                          probability = TRUE,
                          cost = 0.2,
                          gamma = 0.01,
                          coef0 = 0.75,
                          degree = 2)

gamma2_svm_poli <- svm(data=attrition_train_baked,
                          kernel = "polynomial",
                          attrition ~ .,
                          probability = TRUE,
                          cost = 0.2,
                          gamma = 0.05,
                          coef0 = 0.75,
                          degree = 2)

gamma3_svm_poli <- svm(data=attrition_train_baked,
                          kernel = "polynomial",
                          attrition ~ .,
                          probability = TRUE,
                          cost = 0.2,
                          gamma = 0.1,
                          coef0 = 0.75,
                          degree = 2)
```

[**Modelo con gamma = 0.01**]{.hl-bluepastel}

```{r}
#| message: false
#| warning: false
#| code-fold: true
#| 
attritiong1_pred <- predict(gamma1_svm_poli, newdata = attrition_test_baked, type = "class")

conf_mat <- confusionMatrix(attritiong1_pred, attrition_test_baked[["attrition"]], positive = "1")
# Accuracy
accuracy_value <- conf_mat[["overall"]][["Accuracy"]]
# Sensitivity
sensitivity_value <- conf_mat[["byClass"]][["Sensitivity"]]
# Specificity
specificity_value <- conf_mat[["byClass"]][["Specificity"]]
# AUC
attritiong1_pred <- predict(gamma1_svm_poli, newdata = attrition_test_baked, probability=TRUE)
attritiong1_pred <- as.data.frame(attr(attritiong1_pred, "prob"))
attritiong1_pred$real_class <- as.factor(attrition_test_baked[["attrition"]])

auc <- attritiong1_pred |>  roc_auc(truth = real_class, "0")
auc_value <- auc |> pull(.estimate)

statistics <- data.frame(metrics  = c("accuracy","sensitivity","specificity","auc"),
                          values = c(accuracy_value,sensitivity_value,specificity_value,auc_value)
                          )
knitr::kable(statistics , col.names = gsub("[.]", " ", names(statistics)))
```

[**Modelo con gamma = 0.05**]{.hl-bluepastel}

```{r}
#| message: false
#| warning: false
#| code-fold: true
#| 
attritiong2_pred <- predict(gamma2_svm_poli, newdata = attrition_test_baked, type = "class")

conf_mat <- confusionMatrix(attritiong2_pred, attrition_test_baked[["attrition"]], positive = "1")
# Accuracy
accuracy_value <- conf_mat[["overall"]][["Accuracy"]]
# Sensitivity
sensitivity_value <- conf_mat[["byClass"]][["Sensitivity"]]
# Specificity
specificity_value <- conf_mat[["byClass"]][["Specificity"]]
# AUC
attritiong2_pred <- predict(gamma2_svm_poli,newdata = attrition_test_baked, probability=TRUE)
attritiong2_pred <- as.data.frame(attr(attritiong2_pred, "prob"))
attritiong2_pred$real_class <- as.factor(attrition_test_baked[["attrition"]])

auc <- attritiong2_pred |>  roc_auc(truth = real_class, "0")
auc_value <- auc |> pull(.estimate)

statistics <- data.frame(metrics  = c("accuracy","sensitivity","specificity","auc"),
                          values = c(accuracy_value,sensitivity_value,specificity_value,auc_value)
                          )
knitr::kable(statistics , col.names = gsub("[.]", " ", names(statistics)))
```

[**Modelo con gamma = 0.1**]{.hl-bluepastel}

```{r}
#| message: false
#| warning: false
#| code-fold: true
#| 
attritiong3_pred <- predict(gamma3_svm_poli, newdata = attrition_test_baked, type = "class")

conf_mat <- confusionMatrix(attritiong3_pred, attrition_test_baked[["attrition"]], positive = "1")
# Accuracy
accuracy_value <- conf_mat[["overall"]][["Accuracy"]]
# Sensitivity
sensitivity_value <- conf_mat[["byClass"]][["Sensitivity"]]
# Specificity
specificity_value <- conf_mat[["byClass"]][["Specificity"]]
# AUC
attritiong3_pred <- predict(gamma3_svm_poli,newdata = attrition_test_baked, probability=TRUE)
attritiong3_pred <- as.data.frame(attr(attritiong3_pred, "prob"))
attritiong3_pred$real_class <- as.factor(attrition_test_baked[["attrition"]])

auc <- attritiong3_pred |>  roc_auc(truth = real_class, "0")
auc_value <- auc |> pull(.estimate)

statistics <- data.frame(metrics  = c("accuracy","sensitivity","specificity","auc"),
                          values = c(accuracy_value,sensitivity_value,specificity_value,auc_value)
                          )
knitr::kable(statistics , col.names = gsub("[.]", " ", names(statistics)))
```


#### Modelo ganador de verdad de la buena üòõ

Aunque el modelo con gamma = 0.1 presentaba la media de sensibilidad m√°s alta en validaci√≥n cruzada, observamos que el modelo con gamma = 0.01 ofrece un mejor rendimiento sobre el conjunto de test, alcanzando una sensibilidad superior y mantiene muy buenas m√©tricas. 

Esta diferencia sugiere lo que hemos mencionado anteriormente y es que gamma = 0.1 podr√≠a estar ajust√°ndose demasiado a los datos de entrenamiento, mientras que una gamma m√°s baja permite una mayor generalizaci√≥n.

Por lo tanto, se selecciona el modelo con gamma = 0.01 para el despliegue final, priorizando su rendimiento en datos no vistos.

```{r}
#| message: false
#| warning: false
#| echo: false
#| 
saveRDS(gamma1_svm_poli, file = "./outputs/best_svm_poli.rds")

attritiong1_pred <- predict(gamma1_svm_poli, newdata = attrition_test_baked, type = "class")

saveRDS(attritiong1_pred, file = "./outputs/svm_poli_preds.rds")

conf_mat <- confusionMatrix(attritiong1_pred, attrition_test_baked[["attrition"]], positive = "1")
# Accuracy
accuracy_value <- conf_mat[["overall"]][["Accuracy"]]
# Sensitivity
sensitivity_value <- conf_mat[["byClass"]][["Sensitivity"]]
# Specificity
specificity_value <- conf_mat[["byClass"]][["Specificity"]]
# AUC
attritiong1_pred <- predict(gamma1_svm_poli, newdata = attrition_test_baked, probability=TRUE)
attritiong1_pred <- as.data.frame(attr(attritiong1_pred, "prob"))
attritiong1_pred$real_class <- as.factor(attrition_test_baked[["attrition"]])

auc <- attritiong1_pred |>  roc_auc(truth = real_class, "0")
auc_value <- auc |> pull(.estimate)

statistics <- data.frame(metrics  = c("accuracy","sensitivity","specificity","auc"),
                          values = c(accuracy_value,sensitivity_value,specificity_value,auc_value)
                          )
knitr::kable(statistics , col.names = gsub("[.]", " ", names(statistics)))
```



```{r}
#| code-fold: true
#| message: false
#| warning: false
# Curva ROC: etiqueta real vs probabilidad de 1
roc_curve_svm <- attritiong1_pred |> roc_curve(truth = real_class, "0")

#--------------------------
#   Gr√°fico Curva ROC
#--------------------------
ggplot(roc_curve_svm, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(lwd = 1, alpha = 0.85, color = "#e01b63") +
geom_abline(lty = "dashed") +
coord_equal() +
labs(x = "1 - Specificity",
     y = "Sensitivity",
     title = "CURVA ROC",
     subtitle = glue("AUC = {round(auc_value, 3)}"))+
theme_minimal()+
theme(axis.title.y = element_text(face="bold"),
      axis.title.x = element_text(face="bold"),
      plot.title = element_text(size =15,face="bold"),
      plot.subtitle = element_text(size  =10))
```

### ¬øC√≥mo vamos?

```{r}
#| message: false
#| warning: false
#| echo: false
#| 
saveRDS(attritiong1_pred, file = "./outputs/svm_pol_predicted.rds")
saveRDS(statistics, file = "./outputs/svm_pol_stats.rds")
saveRDS(roc_curve_svm, file = "./outputs/svm_pol_roc_auc.rds")

svm_pol_stats <- readRDS("./outputs/svm_pol_stats.rds")
svm_pol_stats$model <- "SVM Polinomial"

svm_pol_roc_curve <- readRDS("./outputs/svm_pol_roc_auc.rds")
svm_pol_roc_curve$model <- "SVM Polinomial"

svm_lin_stats <- readRDS("./outputs/svm_lin_stats.rds")
svm_lin_stats$model <- "SVM Lineal"

svm_lin_roc_curve <- readRDS("./outputs/svm_lin_roc_auc.rds")
svm_lin_roc_curve$model <- "SVM Lineal"

knn_stats <- readRDS("./outputs/knn_stats.rds")
knn_stats$model <- "KNN"

knn_roc_curve <- readRDS("./outputs/knn_roc_auc.rds")
knn_roc_curve$model <- "KNN"

tree_stats <- readRDS("./outputs/tree_stats.rds")
tree_stats$model <- "√Årbol"

tree_roc_curve <- readRDS("./outputs/tree_roc_auc.rds")
tree_roc_curve$model <- "√Årbol"

model_stats <- rbind(svm_pol_stats, svm_lin_stats, knn_stats, tree_stats)
model_roc_curve <- rbind(svm_pol_roc_curve, svm_lin_roc_curve, knn_roc_curve, tree_roc_curve)
```

```{r}
#| message: false
#| warning: false
#| echo: false

datatable(model_stats |> arrange(metrics, values, model), rownames = FALSE, filter = "top",options = list(pageLength = 4)) |> formatStyle(names(statistics), lineHeight = "65%")

model_stats |> ggplot(aes(x = metrics , y= values, fill = model)) +
               geom_bar(alpha = 0.85, position = "dodge", stat = "identity") +
               scale_fill_manual(values = c("√Årbol" = "darkslategray1", "KNN" = "indianred1", "Red Neuronal" = "palegreen2", "SVM Lineal" = "pink", "SVM Polinomial" = "darkgoldenrod1", "Ensamblado" = "darkslategray")) +
               labs(title = "Comparativa Modelos",
                    subtitle = "Resultados de las m√©tricas para cada modelo empleado")+
                theme_minimal()+
                theme(axis.title.y = element_blank(),
                      axis.title.x = element_blank(),
                      axis.text.x = element_text(size = 12,face = "bold"),
                      plot.title = element_text(size =15,face="bold"),
                      plot.subtitle = element_text(size  =10))



# Gr√°fico Curva ROC
ggplot(model_roc_curve, aes(x = 1 - specificity, y = sensitivity, colour=model)) +
geom_line(lwd = 1, alpha = 0.85) +
geom_abline(lty = "dashed") +
coord_equal() +
scale_colour_manual(values = c("√Årbol" = "darkslategray1", "KNN" = "indianred1", "Red Neuronal" = "palegreen2", "SVM Lineal" = "pink", "SVM Polinomial" = "darkgoldenrod1", "Ensamblado" = "darkslategray")) +
labs(x = "1 - Specificity",
     y = "Sensitivity",
     title = "Comparativa Modelos",
     subtitle = "Curva ROC (test) de cada modelo empleado")+
theme_minimal()+
  theme(axis.title.y = element_text(face="bold"),
      axis.title.x = element_text(face="bold"),
      plot.title = element_text(size =15,face="bold"),
      plot.subtitle = element_text(size  =10))
```

## Red neuronal

### Librer√≠as necesarias

```{r}
#| code-fold: false
#| message: false
#| warning: false
#| 
rm(list = ls())

library(tidymodels) # Modelos
library(tidyverse)  # Depuraci√≥n datos
library(themis)     # Oversampling
library(nnet)       # Redes neuronales
library(yardstick)  # Metrics
library(DT)         # Mostrar tabla
library(caret)      # Matriz de Conf.
library(glue)       # Variables ggplot
library(rsample)
library(brulee)
```


### Datos iniciales

```{r}
#| message: false
#| warning: false

attrition_data <- readRDS("./data/attrition_data.rds")
```

En el caso de la red neuronal eliminaremos el ID

```{r}
#| message: false
#| warning: false

attrition_data <- attrition_data |> select(-employeeid)
```

Originalmente la variable objetivo (**attrition**) est√° distribuida de la siguiente forma:

```{r}
#| message: false
#| warning: false
#| code-fold: true
#| 
attrition_data |> group_by(attrition) |> summarise(n = n(), Porc = round(n()*100.0/nrow(attrition_data),2)) |> 
ggplot(aes(x = attrition, y = n, fill = attrition)) +
geom_col(position = "dodge", alpha =0.8) +
geom_text(aes(label = paste(n," (",Porc,"%)", sep ="")),colour = "black", size = 4,vjust = -0.5, position = position_dodge(.9)) +
ylim(0,5300)+
scale_fill_manual(values = c("#023047","#C2185B")) +
labs(title = "Distribuci√≥n del target",
     subtitle = "Reparto de niveles de la variable attrition")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12),
      legend.position = "None"
      )
```


### Train y test

Realizamos la partici√≥n de nuestro conjunto de datos en **80% train** y **20% test**

```{r}
#| warning: false
#| message: false
# Semilla
set.seed(200900)
# Partici√≥n 20% de test
attrition_split <- initial_split(attrition_data, strata = attrition, prop = 0.80)
# Train
attrition_train <- training(attrition_split)
# Test
attrition_test <- testing(attrition_split)
```


### Preparaci√≥n de los datos

El modelo de **Red Neuronal** necesita disponer de variables num√©ricas (y es conveniente estandarizarlas), por lo que se va a crear tambi√©n una receta.

```{r}
#| warning: false
#| message: false
# Receta completa
attrition_recipe <-
  # F√≥rmula y datos
  recipe(data = attrition_train, attrition ~ .) |> 
  # Categoria Other 
  step_other(all_nominal_predictors(), threshold = 0.005) |>
  # Filtro de correlaci√≥n
  step_corr(all_numeric_predictors(), threshold = 0.95) |>
  # Filtro 0 varianza
  step_zv(all_predictors()) |>
  # Min / Max
  step_range(all_numeric_predictors(), min = 0, max = 1) |>
  # nominales las pasemos a dummy 1/0
  step_dummy(all_nominal_predictors(), -all_outcomes()) |>
  # Oversampling
  step_upsample(attrition, over_ratio = 1)
```


### K-Fold cross validation

En primer lugar vamos a indicar el n√∫mero de divisiones que vamos a realizar y las repeticiones, en nuestro caso ser√°n **5 divisiones** y **3 repeticiones**.

Vamos a tener **15 pares de conjuntos de entrenamiento y validaci√≥n**.

```{r}
#| warning: false
#| message: false
set.seed(200900)

folds <- vfold_cv(attrition_train, v = 5, strata = attrition, repeats = 3)
```


### Entrenamiento

Inicialmente vamos a crear un modelo que no tenga par√°metros fijos para despu√©s crear un grid con diferentes valores para configurar nosotros los siguientes hiperpar√°metros:

- **N√∫mero de capas y nodos**

- **Learning rate y n√∫mero de iteraciones**

- **Funci√≥n de activaci√≥n**: Por defecto usaremos ReLU

- **T√©cnicas de regularizaci√≥n**: Usaremos dropout que nos permitir√° evitar sobreajuste en el modelo

```{r}
#| warning: false
#| message: false
#| 
nn_model <- mlp(hidden_units = tune("nodes"),
                epochs = tune("iter"),
                dropout = tune("drop_out"),
                learn_rate = tune("lr")) |>
            set_engine("brulee") |>
            set_mode("classification")
```


#### Flujo de trabajo

Con la receta y el modelo sin par√°metros fijos definidos ya tenemos todo listo para crear el flujo de trabajo

```{r}
#| warning: false
#| message: false

attrition_wflow <- workflow() |> add_recipe(attrition_recipe) |> add_model(nn_model)
```


#### Grid de hiperpar√°metros

Para asignar valores a los hiperpar√°metros de este modelo vamos a crear diferentes grids. En primer lugar para el n√∫mero de nodos y capas, despu√©s para el learning rate, tambi√©n para el n√∫mero de iteraciones y por √∫ltimo para el dropout.

```{r}
#| warning: false
#| message: false

grid_nn <- expand_grid(nodes = seq(5, 8, by = 1),
                       iter = c(100, 200, 500, 1000),
                       drop_out = seq(0, 0.5, by = 0.1),
                       lr = c(0.001, 0.01, 0.1))
```


Con este grid obtenemos que se van a definir un total de 4x4x6x3 modelos, es decir 288, que aplicandoles validaci√≥n cruzada pasar√≠an a ser 4152. Lo veo complicado de entrenar ü´† pero vamos a probar jeje

```{r}
#| warning: false
#| message: false
#| eval: false

set.seed(2009200)

attrition_nn_fit_tune <-  attrition_wflow |> 
                                tune_grid(resamples = folds, 
                                grid = grid_nn,
                                control = control_grid(verbose = TRUE),
                                metrics = metric_set(accuracy,sens,yardstick::spec,roc_auc))

saveRDS(attrition_nn_fit_tune, file = "./outputs/attrition_first_nn_fit_tune.rds")
```


```{r}
#| warning: false
#| message: false
#| code-fold: true
#| 
attrition_nn_fit_tune <- readRDS("./outputs/attrition_first_nn_fit_tune.rds")

cv_results <- attrition_nn_fit_tune |> collect_metrics(summarize = FALSE) |> 
              select(rep = id, 
                     fold = id2, 
                     nodes, 
                     drop_out, 
                     iter, 
                     lr,
                     metric = .metric, 
                     value = .estimate ) |>  
              pivot_wider(names_from = metric, values_from = value) |>
              mutate(model = as.factor(paste
                                      ("Nodos: ", nodes, 
                                        " - ", "Iter: ", iter, 
                                        " - ", "Dropout: ", drop_out,
                                        " - ", "LR: ", lr, sep ="")))


datatable(cv_results, rownames = FALSE, filter = "top",options = list(pageLength = 10)) |> formatStyle(names(cv_results), lineHeight = "65%")
```

Visualizamos los mejores modelos en cuando a sensibilidad tras realizar el entrenamiento con cross validation:

```{r}
#| warning: false
#| message: false
#| code-fold: true
#| 

cv_results_group <- cv_results |> group_by(model) |>  summarise(accuracy = mean(accuracy),
                                                                 sens = mean(sens),
                                                                 spec = mean(spec),
                                                                 auc = mean(roc_auc)
                                                                 ) |>  
                                    arrange(desc(accuracy)) |>   
                                    slice_head(n = 15) |>
                                    mutate(orden = as.factor(seq(from = 1, to=n(), by=1))) |>
                                    select(model, orden)

cv_results_top <- merge(cv_results, cv_results_group, by = "model")


cv_results_top |> ggplot( aes(x=model, y=sens)) +
stat_boxplot(geom = "errorbar",width = 0.25) + 
geom_boxplot( fill = "#6e78ff") +
labs( title = "Cross Validation Results",
      subtitle = "Comparativa (en t√©rminos de sensitivity) de los modelos")+
scale_y_continuous(breaks = seq(from = 0, to=1, by=0.1))+
stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="#023047", fill="#023047") +
theme_minimal()+
theme(plot.title= element_text(size=15, face = "bold" ),
      axis.title.x = element_blank(),
      axis.text.x  = element_text(size=6,face = "bold", angle = 90),
      axis.title.y = element_blank(),
      axis.text.y  = element_text(size=10,face = "bold"),
      legend.position = "None"
      )
```

El mejor modelo parece **Nodos: 7 - Iter: 500 - Dropout: 0 - LR: 0.01**, aun as√≠ vamos a corroborarlo mediante la funcion show_best() mediante la sensibilidad:

```{r}
#| warning: false
#| message: false

attrition_nn_fit_tune |> show_best(metric = "sens")
```

Efectivamente el modelo **Nodos: 7 - Iter: 500 - Dropout: 0 - LR: 0.01** es nuestro üèÜ **modelo ganador** üèÜ.

### Modelo ganador

Generamos en primer lugar nuestro modelo ganador:

```{r}
#| message: false
#| warning: false

set.seed(200900)

best_nn_model <- mlp(hidden_units = 7,
                     epochs = 500,
                     dropout = 0,
                     learn_rate = 0.01) |>
                 set_engine("nnet") |>
                 set_mode("classification")

saveRDS(best_nn_model, file = "./outputs/best_ovft_nn.rds")
```

Creamos el flujo de trabajo de nuestro modelo ganador:

```{r}
#| message: false
#| warning: false
#| 
attrition_best_wflow <- workflow() |> add_recipe(attrition_recipe) |> add_model(best_nn_model)
```

Ajustamos el flujo de trabajo del modelo ganador a nuestro conjunto de entrenamiento:

```{r}
#| message: false
#| warning: false
#| 
attrition_best_nn_fit <- attrition_best_wflow |> fit(data = attrition_train)
```

### Predicciones en test

Se va a aplicar el modelo ganador al conjunto de test que se reserv√≥ al comenzar a tratar los datos para la red neuronal:

```{r}
#| message: false
#| warning: false

attrition_pred <- augment(attrition_best_nn_fit, attrition_test)
```

#### Matriz de confusi√≥n 

```{r}
#| message: false
#| warning: false
#| code-fold: true
#|
# Matriz de Confusion
conf_mat <- confusionMatrix(attrition_pred$.pred_class, attrition_pred$attrition, positive = "1")
# Accuracy
accuracy <- conf_mat[["overall"]][["Accuracy"]]
# Sensitivity
sensitivity <- conf_mat[["byClass"]][["Sensitivity"]]
# Specificity
specificity <- conf_mat[["byClass"]][["Specificity"]]
# AUC
auc <- attrition_pred |>  roc_auc(truth = attrition, .pred_0)
auc_value <- auc |> pull(.estimate)

statistics <- data.frame (metrics  = c("accuracy","sensitivity","specificity","auc"),
                          values = c(accuracy,sensitivity,specificity,auc_value)
                          )
knitr::kable(statistics , col.names = gsub("[.]", " ", names(statistics)))
```


### Overfitting

Se observa overfitting en el modelo. Esto es debido al tama√±o reducido del dataset y el uso de muchas iteraciones sin dropout y con bastantes nodos. 

Todos estos factores han favorecido que el modelo memorice los datos de entrenamiento en lugar de generalizar correctamente.

Adem√°s al hacer oversampling, nuestro modelo est√° duplicando datos ya existentes en el dataset por lo que esto puede ser otro factor muy influyente.

Para solucionar este problema vamos a crear un nuevo grid de hiperpar√°metros con algunos valores diferentes y reentrenar la red.

Adem√°s a parte de este nuevo grid de hiperpar√°metros vamos a reducir las divisiones de nuestro cross validation previo de 5 a 3:

```{r}
#| warning: false
#| message: false
set.seed(200900)

folds <- vfold_cv(attrition_train, v = 3, strata = attrition, repeats = 3)
```

```{r}
#| warning: false
#| message: false

grid_nn <- expand_grid(nodes = c(3,4),
                       iter = c(100, 200),
                       drop_out = c(0.4, 0.5),
                       lr = 0.01)
```

Vamos a reducir el n√∫mero de nodos y de iteraciones en nuestra red ya que el conjunto de datos es peque√±o. 

Adem√°s vamos a considerar √∫nicamente dropouts que desactiven bastante cantidad de neuronas para que no haya una memorizaci√≥n de los datos.

Por otro lado se va a conservar el valor del hiperpar√°metro del learning rate del modelo ganador que estaba sobreajustado.

### Reentrenamiento

```{r}
#| warning: false
#| message: false
#| eval: false

set.seed(2009200)

attrition_nn_fit_tune <-  attrition_wflow |> 
                                tune_grid(resamples = folds, 
                                grid = grid_nn,
                                control = control_grid(verbose = TRUE),
                                metrics = metric_set(yardstick::accuracy,yardstick::sens,yardstick::spec,yardstick::roc_auc))

saveRDS(attrition_nn_fit_tune, file = "./outputs/attrition_nn_fit_tune.rds")
```

Me acabo de dar cuenta que he sobreescrito el archivo anterior del modelo sobreajustado y voy a tener que entrenarlo de nuevo otro dia entero por no subirlo a git

```{r echo = FALSE, out.width = "50%", fig.align = "center", fig.cap = ""}
knitr::include_graphics("./img/sad.jpg")
```

Visualizamos las m√©tricas y las gr√°ficas del modelo reentrenado con los cambios mencionados anteriormente:

```{r}
#| warning: false
#| message: false
#| code-fold: true
#| 
attrition_nn_fit_tune <- readRDS("./outputs/attrition_nn_fit_tune.rds")

cv_results <- attrition_nn_fit_tune |> collect_metrics(summarize = FALSE) |> 
              select(rep = id, 
                     fold = id2, 
                     nodes, 
                     drop_out, 
                     iter, 
                     lr,
                     metric = .metric, 
                     value = .estimate ) |>  
              pivot_wider(names_from = metric, values_from = value) |>
              mutate(model = as.factor(paste
                                      ("Nodos: ", nodes, 
                                        " - ", "Iter: ", iter, 
                                        " - ", "Dropout: ", drop_out,
                                        " - ", "LR: ", lr, sep ="")))


datatable(cv_results, rownames = FALSE, filter = "top",options = list(pageLength = 10)) |> formatStyle(names(cv_results), lineHeight = "65%")
```

```{r}
#| warning: false
#| message: false
#| code-fold: true
#| 

cv_results_group <- cv_results |> group_by(model) |>  summarise(accuracy = mean(accuracy),
                                                                 sens = mean(sens),
                                                                 spec = mean(spec),
                                                                 auc = mean(roc_auc)
                                                                 ) |>  
                                    arrange(desc(sens)) |>   
                                    slice_head(n = 15) |>
                                    mutate(orden = as.factor(seq(from = 1, to=n(), by=1))) |>
                                    select(model, orden)

cv_results_top <- merge(cv_results, cv_results_group, by = "model")


cv_results_top |> ggplot( aes(x=model, y=sens)) +
stat_boxplot(geom = "errorbar",width = 0.25) + 
geom_boxplot( fill = "#6e78ff") +
labs( title = "Cross Validation Results",
      subtitle = "Comparativa (en t√©rminos de sensitivity) de los modelos")+
scale_y_continuous(breaks = seq(from = 0, to=1, by=0.1))+
stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="#023047", fill="#023047") +
theme_minimal()+
theme(plot.title= element_text(size=15, face = "bold" ),
      axis.title.x = element_blank(),
      axis.text.x  = element_text(size=7,face = "bold", angle = 90),
      axis.title.y = element_blank(),
      axis.text.y  = element_text(size=10,face = "bold"),
      legend.position = "None"
      )
```

Una vez finalizado el entrenamiento, obtenemos de nuevo el mejor modelo por sensibilidad:

```{r}
#| warning: false
#| message: false

attrition_nn_fit_tune |> show_best(metric = "sens")
```

Viendo la gr√°fica en conjunto con los resultados de la funci√≥n show_best(), he decidido seleccionar como modelo ganador el 2¬∫ que proporciona la funci√≥n y es que por el tama√±o de la caja parece tener mayor estabilidad que el modelo con mejor media.

Adem√°s en este no existen valores at√≠picos extremos que indiquen ca√≠das cr√≠ticas de desempe√±o. Su comportamiento consistente a lo largo de las distintas particiones del cross validation sugiere una buena generalizaci√≥n sobre nuevos datos.

 **Nodos: 3 - Iter: 200 - Dropout: 0.5 - LR: 0.01** es nuestro üèÜ **modelo ganador** üèÜ.

### Modelo ganador s√≠ que s√≠

Generamos el modelo ganador del segundo entrenamiento

```{r}
#| message: false
#| warning: false

set.seed(200900)


best_nn_model <- mlp(hidden_units = 3,
                     epochs = 200,
                     dropout = 0.5,
                     learn_rate = 0.01) |>
                 set_engine("nnet") |>
                 set_mode("classification")

saveRDS(best_nn_model, file = "./outputs/best_nn.rds")
```

Creamos tambi√©n el flujo de trabajo con el mejor modelo:

```{r}
#| message: false
#| warning: false
#| 
attrition_best_wflow <- workflow() |> add_recipe(attrition_recipe) |> add_model(best_nn_model)
```

Ajustamos el conjunto de entrenamiento a nuestro mejor flujo de trabajo:

```{r}
#| message: false
#| warning: false
#| 
attrition_best_nn_fit <- attrition_best_wflow |> fit(data = attrition_train)
```

### Predicciones en test (2¬∫ Intento)

Se va a aplicar el modelo ganador del segundo entrenamiento al conjunto de test que se reserv√≥ al comenzar a tratar los datos para la red neuronal:

```{r}
#| message: false
#| warning: false

attrition_pred <- augment(attrition_best_nn_fit, attrition_test)

saveRDS(attrition_pred, file = "./outputs/nn_preds.rds")
```

#### Matriz de confusi√≥n (2¬∫ Intento)

```{r}
#| message: false
#| warning: false
#| code-fold: true
#|
# Matriz de Confusion
conf_mat <- confusionMatrix(attrition_pred$.pred_class, attrition_pred$attrition, positive = "1")
# Accuracy
accuracy <- conf_mat[["overall"]][["Accuracy"]]
# Sensitivity
sensitivity <- conf_mat[["byClass"]][["Sensitivity"]]
# Specificity
specificity <- conf_mat[["byClass"]][["Specificity"]]
# AUC
auc <- attrition_pred |>  roc_auc(truth = attrition, .pred_0)
auc_value <- auc |> pull(.estimate)

statistics <- data.frame (metrics  = c("accuracy","sensitivity","specificity","auc"),
                          values = c(accuracy,sensitivity,specificity,auc_value)
                          )
knitr::kable(statistics , col.names = gsub("[.]", " ", names(statistics)))
```

#### Curva ROC Y AUC

```{r}
#| message: false
#| warning: false
#| code-fold: true
#| 
# Curva ROC: etiqueta real vs probabilid de 1
roc_curve_nn <- attrition_pred |> roc_curve(truth = attrition, .pred_0)
# ----------------------
#   Gr√°fico Curva ROC
# ----------------------
ggplot(roc_curve_nn, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(lwd = 1, alpha = 0.85, color = "#e01b63") +
geom_abline(lty = "dashed") +
coord_equal() +
labs(x = "1 - Specificity",
     y = "Sensitivity",
     title = "CURVA ROC",
     subtitle = glue("AUC = {round(auc_value, 3)}"))+
theme_minimal()+
theme(axis.title.y = element_text(face="bold"),
      axis.title.x = element_text(face="bold"),
      plot.title = element_text(size =15,face="bold"),
      plot.subtitle = element_text(size  =10))
```


### ¬øC√≥mo vamos?

```{r}
#| message: false
#| warning: false
#| echo: false
#| 
saveRDS(attrition_pred, file = "./outputs/nn_predicted.rds")
saveRDS(statistics, file = "./outputs/nn_stats.rds")
saveRDS(roc_curve_nn, file = "./outputs/nn_roc_auc.rds")

nn_stats <- readRDS("./outputs/nn_stats.rds")
nn_stats$model <- "Red Neuronal"

nn_roc_curve <- readRDS("./outputs/nn_roc_auc.rds")
nn_roc_curve$model <- "Red Neuronal"

svm_pol_stats <- readRDS("./outputs/svm_pol_stats.rds")
svm_pol_stats$model <- "SVM Polinomial"

svm_pol_roc_curve <- readRDS("./outputs/svm_pol_roc_auc.rds")
svm_pol_roc_curve$model <- "SVM Polinomial"

svm_lin_stats <- readRDS("./outputs/svm_lin_stats.rds")
svm_lin_stats$model <- "SVM Lineal"

svm_lin_roc_curve <- readRDS("./outputs/svm_lin_roc_auc.rds")
svm_lin_roc_curve$model <- "SVM Lineal"

knn_stats <- readRDS("./outputs/knn_stats.rds")
knn_stats$model <- "KNN"

knn_roc_curve <- readRDS("./outputs/knn_roc_auc.rds")
knn_roc_curve$model <- "KNN"

tree_stats <- readRDS("./outputs/tree_stats.rds")
tree_stats$model <- "√Årbol"

tree_roc_curve <- readRDS("./outputs/tree_roc_auc.rds")
tree_roc_curve$model <- "√Årbol"

model_stats <- rbind(nn_stats, svm_pol_stats, svm_lin_stats, knn_stats, tree_stats)
model_roc_curve <- rbind(nn_roc_curve, svm_pol_roc_curve, svm_lin_roc_curve, knn_roc_curve, tree_roc_curve)
```

```{r}
#| message: false
#| warning: false
#| echo: false

datatable(model_stats |> arrange(metrics, values, model), rownames = FALSE, filter = "top",options = list(pageLength = 5)) |> formatStyle(names(statistics), lineHeight = "65%")

model_stats |> ggplot(aes(x = metrics , y= values, fill = model)) +
               geom_bar(alpha = 0.85, position = "dodge", stat = "identity") +
               scale_fill_manual(values = c("√Årbol" = "darkslategray1", "KNN" = "indianred1", "Red Neuronal" = "palegreen2", "SVM Lineal" = "pink", "SVM Polinomial" = "darkgoldenrod1", "Ensamblado" = "darkslategray")) +
               labs(title = "Comparativa Modelos",
                    subtitle = "Resultados de las m√©tricas para cada modelo empleado")+
                theme_minimal()+
                theme(axis.title.y = element_blank(),
                      axis.title.x = element_blank(),
                      axis.text.x = element_text(size = 12,face = "bold"),
                      plot.title = element_text(size =15,face="bold"),
                      plot.subtitle = element_text(size  =10))



# Gr√°fico Curva ROC
ggplot(model_roc_curve, aes(x = 1 - specificity, y = sensitivity, colour=model)) +
geom_line(lwd = 1, alpha = 0.85) +
geom_abline(lty = "dashed") +
coord_equal() +
scale_colour_manual(values = c("√Årbol" = "darkslategray1", "KNN" = "indianred1", "Red Neuronal" = "palegreen2", "SVM Lineal" = "pink", "SVM Polinomial" = "darkgoldenrod1", "Ensamblado" = "darkslategray")) +
labs(x = "1 - Specificity",
     y = "Sensitivity",
     title = "Comparativa Modelos",
     subtitle = "Curva ROC (test) de cada modelo empleado")+
theme_minimal()+
  theme(axis.title.y = element_text(face="bold"),
      axis.title.x = element_text(face="bold"),
      plot.title = element_text(size =15,face="bold"),
      plot.subtitle = element_text(size  =10))
```



## Ensamble - Bagging con Random Forest

Como m√©todo de ensamble vamos a utilizar el Bagging, m√°s concretamente un Random Forest que se trata de una modificaci√≥n del bagging que consiste en incorporar aleatoriedad en las variables utilizadas para segmentar cada nodo del √°rbol.

### Librer√≠as necesarias

```{r}
#| message: false
#| warning: false

rm(list = ls())

library(tidyverse)    # Depuraci√≥n datos
library(skimr)        # Resumen num√©rico
library(ggplot2)      # Gr√°ficos
library(tidymodels)   # Modelos
library(rpart)        # CART
library(rpart.plot)   # Graficar √°rbol
library(caret)        # Matriz de Confusion
library(glue)         # pegar texto + variables f√°cilmente
library(DT)           # Para mostrar tabla (formatStyle)
library(ROSE)         # Para Oversampling
library(yardstick)    # C√≥mo funcionan modelos
library(forcats)      # Para factores
library(randomForest) # rf
library(themis)       # Oversampling
library(gbm)          # Importancia GB
```

### Datos iniciales

```{r}
#| message: false
#| warning: false

attrition_data <- readRDS("./data/attrition_data.rds")
```

En el caso del Random Forest tambi√©n eliminaremos el ID

```{r}
#| message: false
#| warning: false

attrition_data <- attrition_data |> select(-employeeid)
```

La variable objetivo (**attrition**) est√° distribuida de la siguiente forma:

```{r}
#| message: false
#| warning: false
#| code-fold: true
#| 
attrition_data |> group_by(attrition) |> summarise(n = n(), Porc = round(n()*100.0/nrow(attrition_data),2)) |> 
ggplot(aes(x = attrition, y = n, fill = attrition)) +
geom_col(position = "dodge", alpha =0.8) +
geom_text(aes(label = paste(n," (",Porc,"%)", sep ="")),colour = "black", size = 4,vjust = -0.5, position = position_dodge(.9)) +
ylim(0,5300)+
scale_fill_manual(values = c("#023047","#C2185B")) +
labs(title = "Distribuci√≥n del target",
     subtitle = "Reparto de niveles de la variable attrition")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12),
      legend.position = "None"
      )
```


### Train y test

Dividimos nuestro conjunto de datos en **80% train** y **20% test**

```{r}
#| warning: false
#| message: false
# Semilla
set.seed(200900)
# Partici√≥n 20% de test
attrition_split <- initial_split(attrition_data, strata = attrition, prop = 0.80)
# Train
attrition_train <- training(attrition_split)
# Test
attrition_test <- testing(attrition_split)
```


### Downsampling

En este caso hemos elegido realizar downsampling debido a que mediante oversampling no se consigui√≥ solucionar el problema del overfitting que presentaba inicialmente el modelo.

Como resultado se ver√°n un poco sacrificadas otras m√©tricas pero vamos a conseguir buenos resultados por lo general.

```{r}
#| warning: false
#| message: false

attrition_train_balance <- ovun.sample(attrition ~ .,
                                   data = attrition_train,
                                   seed = 200900,
                                   method = "under")$data
```

La distribuci√≥n de nuestros datos despu√©s de realizar el **downsampling** queda de la siguiente forma:

```{r}
#| message: false
#| warning: false
#| code-fold: true
#| 
attrition_train_balance |> group_by(attrition) |> summarise(n = n(), Porc = round(n()*100.0/nrow(attrition_train_balance),2)) |> 
ggplot(aes(x = attrition, y = n, fill = attrition)) +
geom_col(position = "dodge", alpha =0.8) +
geom_text(aes(label = paste(n," (",Porc,"%)", sep ="")),colour = "black", size = 4,vjust = -0.5, position = position_dodge(.9)) +
ylim(0,5300)+
scale_fill_manual(values = c("#023047","#C2185B")) +
labs(title = "Distribuci√≥n del target",
     subtitle = "Reparto de niveles de la variable attrition")+
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
      axis.title.y = element_blank(),
      axis.title.x =element_blank(),
      axis.text.x = element_text(size = 12),
      legend.position = "None"
      )
```

### K-Fold cross validation

Para realizar el proceso de k-folding se va a utilizar la funci√≥n proporcionada en la asignatura de aprendizaje autom√°tico. 

```{r}
#| code-fold: false
#| message: false
#| warning: false
#| 
source("./funciones/utils.r")

attrition_data_cv <- fold_rep_for_cv(data = attrition_train_balance, folds = 3, reps = 3, target = "attrition", seed = 200900)
```

Una vez creadas las particiones ya se puede configurar un grid de hiperpar√°metros con el que se entrenar√° este Random Forest.

### Grid de hiperpar√°metros

En este modelo de Random Forest vamos a configurar los siguientes hiperpar√°metros:

- N¬∫ de √°rboles que es realmente el n√∫mero de iteraciones.

- N¬∫ de variables a muestrear

- Tama√±o de muestra para entrenar cada √°rbol. Si el n√∫mero de observaciones es peque√±o, mejor utilizar con reemplazamiento

- Tama√±o m√≠nimo de un nodo intermedio para seguir generando divisiones

En general se podr√≠an configurar muchos m√°s hiperpar√°metros que son propios del √°rbol de decisi√≥n, pero para no aumentar la complejidad y evitar que el c√≥mputo de estos modelos sea excesivo se va a considerar solo el nodeSize como par√°metro de los √Årboles de Decisi√≥n.

```{r}
#| code-fold: false
#| message: false
#| warning: false
#| 
nodesize_list <- c(5, 30, 40, 50, 90)

ntrees_list <- c(50, 100, 200, 400)

mtry_list <- c(2, 4 ,6)

sampsize_list <- c(100, 200)
```

El par√°metro de tama√±o de la muestra es grande en comparaci√≥n con nuestro conjunto de datos por lo que el valor de replace en Random Forest no deber√≠a de variar mucho el resultado.

El n√∫mero de √°rboles tomar√° valores de 200 o 500, cuantos m√°s haya ser√° m√°s robusto y a partir de cierto punto temprano no mejora mucho por lo que no tiene sentido ampliar mucho este n√∫mero.

En cuanto al n√∫mero de variables a muestrear, en nuestro caso, tenemos 19 variables en el dataset y dentro de los modelos Random Forest muchas veces definen este valor la ra√≠z del n√∫mero total de variables, es decir en nuestro caso aproximadamente 4. Vamos a asignar tambi√©n unos valores un poco m√°s bajos y altos para realizar la prueba.

Por √∫ltimo, el tama√±o de los nodos es reducido ya que el conjunto de datos tambi√©n lo es pero no queremos que sea muy reducido para evitar sobreajuste.

### Entrenamiento

```{r}
#| code-fold: true
#| message: false
#| warning: false
#| results: false
#| eval: false

cv_results <- data.frame(rep          = integer(),
                         fold         = integer(),
                         ntree        = integer(),
                         mtry         = integer(),
                         sampsize     = integer(),
                         nsize        = integer(),
                         accuracy     = double(),
                         kappa        = double(),
                         sensitivity  = double(),
                         specificity  = double(),
                         auc          = double())


for (data_fold in attrition_data_cv) 
{
    #---------------------------------
    # Conjuntos de Train y Val
    #---------------------------------
    rep_value <- data_fold[["repeat"]]
    fold_value <- data_fold[["fold"]]
    train <- data_fold[["train_data"]]
    val <- data_fold[["validation_data"]]
    
    #---------------------------------
    # Fine tunning con diferentes hiperpar√°metros
    #---------------------------------
    
    for (ntree in ntrees_list) 
    {
      for (mtry in mtry_list) 
      {
        for (sampsize in sampsize_list) 
        {
            for (nsize in nodesize_list) 
            {
            # ----------------- 
            #      Modelo
            # -----------------
            rf_model <- randomForest(attrition ~ .,
                              data = train,
                              ntree = ntree,
                              mtry  = mtry, 
                              sampsize = sampsize,
                              nodesize = nsize,
                              replace=TRUE,
                              importance = TRUE)
            
            
            # Predicciones en Val
            pred <- predict(rf_model, newdata = val, type = "class") 
            # Matriz de confusi√≥n
            conf_mat <- confusionMatrix(pred, val[["attrition"]], positive = "1")
            # Accuracy
            accuracy_value <- conf_mat[["overall"]][["Accuracy"]]
            # Kappa
            kappa_value <- conf_mat[["overall"]][["Kappa"]]
            # Sensitivity
            sensitivity_value <- conf_mat[["byClass"]][["Sensitivity"]]
            # Specificity
            specificity_value <- conf_mat[["byClass"]][["Specificity"]]
            # Curva ROC y AUC
            pred <- as.data.frame(predict(rf_model, val, type="prob"))
            pred$real_class <- as.factor(val[["attrition"]])
            pred <- pred |>  rename(prob_attrition = "1", prob_none = "0")
            auc <- pred |>  roc_auc(truth = real_class, prob_none)
            auc_value <- auc |>  pull(.estimate)
            # ----------------------------------------> Guardamos resultados
            cv_results[nrow(cv_results) + 1,] <- c( rep_value,
                                                    fold_value,
                                                    ntree,
                                                    mtry,
                                                    sampsize,
                                                    nsize,
                                                    round(accuracy_value,6),
                                                    round(kappa_value,6),
                                                    round(sensitivity_value,6),
                                                    round(specificity_value,6),
                                                    round(auc_value,6))
            # Para mostrar por pantalla lo que  se va ejecutando
            texto <- paste("Repeat: ",rep_value,
                           " - Fold: ",fold_value, 
                           " - Node size: ",nsize, 
                           " - Sample size: ",sampsize,
                           " - Mtry: ",mtry,
                           " - NTree: ",ntree, sep = "" )
            print(texto)
            print("-----------------------")
          }
        }
      }
    }
         
}
# Conversi√≥n a formatos correctos
cv_results$ntree <- as.double(cv_results$ntree)
cv_results$mtry <- as.double(cv_results$mtry)
cv_results$sampsize <- as.double(cv_results$sampsize)
cv_results$nsize <- as.double(cv_results$nsize)
cv_results$accuracy <- as.double(cv_results$accuracy)
cv_results$kappa <- as.double(cv_results$kappa)
cv_results$sensitivity <- as.double(cv_results$sensitivity)
cv_results$specificity <- as.double(cv_results$specificity)
cv_results$auc <- as.double(cv_results$auc)
# Variable con nombre modelos
cv_results <- cv_results |>  mutate(model = paste("nSize: ",nsize, " - sampSize:",sampsize," - mTry:" ,mtry," - nTree:" ,ntree, sep = ""))
# Guardamos
saveRDS(cv_results, file = "./outputs/rf_cv_results.rds")


```

Las m√©tricas de nuestros modelos de Random Forest entrenados son las siguientes:

```{r}
#| message: false
#| warning: false
#| code-fold: true

cv_results <- readRDS("./outputs/rf_cv_results.rds")

datatable(cv_results, rownames = FALSE, filter = "top",options = list(pageLength = 10)) |> formatStyle(names(cv_results), lineHeight = "65%")
```

```{r}
#| message: false
#| warning: false
#| code-fold: true

# Mejores 10 modelos en promedio de sensitivity
best_mean_cv_results <- cv_results |> 
                        group_by(model)|> summarise(sensitivity = mean(sensitivity))|> 
                        arrange(desc(sensitivity)) |>
                        slice(1:10)
# Plot
cv_results |> inner_join(best_mean_cv_results,by = "model")|>
ggplot( aes(x=model, y=sensitivity.x)) +
stat_boxplot(geom = "errorbar",width = 0.25) + 
geom_boxplot( fill = "#ff8fab") +
labs( title = "Cross Validation Results",
      subtitle = "Comparativa (en t√©rminos de sensitivity) de los modelos")+
scale_y_continuous(breaks = seq(from = 0.5, to=1, by=0.05))+
stat_summary(fun.y=mean, geom="point", shape=23, size=1.5, color="#023047", fill="#023047") +
theme_minimal()+
theme(plot.title= element_text(size=15, face = "bold" ),
      axis.title.x = element_blank(),
      axis.text.x  = element_text(size=7,face = "bold", angle = 90),
      axis.title.y = element_blank(),
      axis.text.y  = element_text(size=10,face = "bold"),
      legend.position = "None"
      )

```

Nuestro üèÜ **modelo ganador** üèÜ ser√° el que tiene **Tama√±o de nodo: 30 - Tama√±o de muestreo: 100 - N¬∫ de variables a muestrear: 6 - N¬∫ de √°rboles: 100**.

### Modelo ganador

```{r}
#| message: false
#| warning: false
#| 
set.seed(200900)
best_rf_model <- randomForest(attrition ~ .,
                              data = attrition_train_balance,
                              ntree = 100,
                              mtry  = 6, 
                              sampsize = 100,
                              nodesize = 30,
                              replace=TRUE,
                              importance = TRUE
                              )
# Guardar modelo
saveRDS(best_rf_model, file = "./outputs/best_rf_model.rds")
```

Graficamos la importancia de las variables:

```{r}
#| message: false
#| warning: false
#| 

importance_rf <- as.data.frame(best_rf_model[["importance"]])
importance_rf <- rownames_to_column(importance_rf, "Variables") |> arrange(desc(MeanDecreaseGini))
importance_rf$Variables <- as.factor(importance_rf$Variables)


importance_rf |> mutate(Variables = fct_reorder(Variables, MeanDecreaseGini)) |>
ggplot( aes(x=Variables, y=MeanDecreaseGini)) +
geom_bar(stat="identity", fill="#e01b63", width=.8)+
coord_flip() +
theme_bw()+
theme(axis.title.x = element_blank(),
      axis.text.x  = element_text(size=10,face = "bold"),
      axis.title.y = element_blank(),
      axis.text.y  = element_text(size=10,face = "bold"),
      legend.position = "None"
      ) 
```

Donde podemos ver que la variable overtime destaca sobre las dem√°s.

### Predicciones en test

```{r}
#| message: false
#| warning: false
#| 
# Matriz de Confusion
rf_pred <- predict(best_rf_model, newdata = attrition_test, type="response")
conf_mat <- confusionMatrix(rf_pred, attrition_test$attrition, positive = "1")
# Accuracy
accuracy <- conf_mat[["overall"]][["Accuracy"]]
# Sensitivity
sensitivity <- conf_mat[["byClass"]][["Sensitivity"]]
# Specificity
specificity <- conf_mat[["byClass"]][["Specificity"]]
# AUC
rf_pred <- as.data.frame(predict(best_rf_model, attrition_test, type="prob"))
rf_pred$real_class <- as.factor(attrition_test[["attrition"]])
auc <- rf_pred |> roc_auc(truth = real_class, "0")
auc_value <- auc |> pull(.estimate)
# Almacenamos valores en dataframe para visualizar mejor
statistics <- data.frame (metrics  = c("accuracy","sensitivity","specificity","auc"),
                          values = c(accuracy,sensitivity,specificity,auc_value)
                          )
knitr::kable(statistics , col.names = gsub("[.]", " ", names(statistics)))
```

Como ya se mencion√≥ anteriormente se ha conseguido mantener unas m√©tricas correctas en general y tener una buena sensibilidad respecto a la de nuestro entrenamiento por lo que podemos asegurar que hemos conseguido reducir el overfitting de nuestro modelo cuando probamos oversampling.

```{r}
#| message: false
#| warning: false
#| code-fold: true
#| 
# Curva ROC: etiqueta real vs probabilid de 1
roc_curve_rf <- rf_pred |> roc_curve(truth = real_class, "0")
# ----------------------
#   Gr√°fico Curva ROC
# ----------------------
ggplot(roc_curve_rf, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(lwd = 1, alpha = 0.85, color = "#e01b63") +
geom_abline(lty = "dashed") +
coord_equal() +
labs(x = "1 - Specificity",
     y = "Sensitivity",
     title = "CURVA ROC",
     subtitle = glue("AUC = {round(auc_value, 3)}"))+
theme_minimal()+
theme(axis.title.y = element_text(face="bold"),
      axis.title.x = element_text(face="bold"),
      plot.title = element_text(size =15,face="bold"),
      plot.subtitle = element_text(size  =10))
```
## Comparaci√≥n final 

```{r}
#| message: false
#| warning: false
#| echo: false
#| 
saveRDS(rf_pred, file = "./outputs/rf_predicted.rds")
saveRDS(statistics, file = "./outputs/rf_stats.rds")
saveRDS(roc_curve_rf, file = "./outputs/rf_roc_auc.rds")

rf_stats <- readRDS("./outputs/rf_stats.rds")
rf_stats$model <- "Ensamblado - RF"

rf_roc_curve <- readRDS("./outputs/rf_roc_auc.rds")
rf_roc_curve$model <- "Ensamblado - RF"

nn_stats <- readRDS("./outputs/nn_stats.rds")
nn_stats$model <- "Red Neuronal"

nn_roc_curve <- readRDS("./outputs/nn_roc_auc.rds")
nn_roc_curve$model <- "Red Neuronal"

svm_pol_stats <- readRDS("./outputs/svm_pol_stats.rds")
svm_pol_stats$model <- "SVM Polinomial"

svm_pol_roc_curve <- readRDS("./outputs/svm_pol_roc_auc.rds")
svm_pol_roc_curve$model <- "SVM Polinomial"

svm_lin_stats <- readRDS("./outputs/svm_lin_stats.rds")
svm_lin_stats$model <- "SVM Lineal"

svm_lin_roc_curve <- readRDS("./outputs/svm_lin_roc_auc.rds")
svm_lin_roc_curve$model <- "SVM Lineal"

knn_stats <- readRDS("./outputs/knn_stats.rds")
knn_stats$model <- "KNN"

knn_roc_curve <- readRDS("./outputs/knn_roc_auc.rds")
knn_roc_curve$model <- "KNN"

tree_stats <- readRDS("./outputs/tree_stats.rds")
tree_stats$model <- "√Årbol"

tree_roc_curve <- readRDS("./outputs/tree_roc_auc.rds")
tree_roc_curve$model <- "√Årbol"

model_stats <- rbind(rf_stats, nn_stats, svm_pol_stats, svm_lin_stats, knn_stats, tree_stats)
model_roc_curve <- rbind(rf_roc_curve, nn_roc_curve, svm_pol_roc_curve, svm_lin_roc_curve, knn_roc_curve, tree_roc_curve)
```

```{r}
#| message: false
#| warning: false
#| echo: false

datatable(model_stats |> arrange(metrics, values, model), rownames = FALSE, filter = "top",options = list(pageLength = 6)) |> formatStyle(names(statistics), lineHeight = "65%")

model_stats |> ggplot(aes(x = metrics , y= values, fill = model)) +
               geom_bar(alpha = 0.85, position = "dodge", stat = "identity") +
               scale_fill_manual(values = c("√Årbol" = "darkslategray1", "KNN" = "indianred1", "Red Neuronal" = "palegreen2", "SVM Lineal" = "pink", "SVM Polinomial" = "darkgoldenrod1", "Ensamblado - RF" = "darkslategray")) +
               labs(title = "Comparativa Modelos",
                    subtitle = "Resultados de las m√©tricas para cada modelo empleado")+
                theme_minimal()+
                theme(axis.title.y = element_blank(),
                      axis.title.x = element_blank(),
                      axis.text.x = element_text(size = 12,face = "bold"),
                      plot.title = element_text(size =15,face="bold"),
                      plot.subtitle = element_text(size  =10))



# Gr√°fico Curva ROC
ggplot(model_roc_curve, aes(x = 1 - specificity, y = sensitivity, colour=model)) +
geom_line(lwd = 1, alpha = 0.85) +
geom_abline(lty = "dashed") +
coord_equal() +
scale_colour_manual(values = c("√Årbol" = "darkslategray1", "KNN" = "indianred1", "Red Neuronal" = "palegreen2", "SVM Lineal" = "pink", "SVM Polinomial" = "darkgoldenrod1", "Ensamblado - RF" = "darkslategray")) +
labs(x = "1 - Specificity",
     y = "Sensitivity",
     title = "Comparativa Modelos",
     subtitle = "Curva ROC (test) de cada modelo empleado")+
theme_minimal()+
  theme(axis.title.y = element_text(face="bold"),
      axis.title.x = element_text(face="bold"),
      plot.title = element_text(size =15,face="bold"),
      plot.subtitle = element_text(size  =10))
```


Analizando estos gr√°ficos finales en los que podemos observar las comparaciones de las m√©tricas de los distintos modelos podemos extraer una serie de conclusiones finales:

En cuanto al **rendimiento de los modelos** existen 3 modelos que destacan sobre los dem√°s, estos son los dos de SVM y la Red Neuronal, mantienen unas m√©tricas generales muy buenas.

Por la propia definici√≥n de nuestro problema del abandono laboral, la m√©trica que m√°s nos interesa es la **sensibilidad** y es que con esta seremos capaces de predecir de forma correcta aquella gente que abandona el trabajo de forma voluntaria. Fallar en identificar a un empleado que abandonar√° (falso negativo) generalmente tiene un coste mayor que intervenir innecesariamente con un empleado que no planeaba abandonar (falso positivo). 

Los modelos que mejor sensibilidad tienen son los dos de **SVM** pero destaca sobre todo el que utiliza el **kernel polinomial**.

Viendo que la sensibilidad respecto al resto s√≠ que var√≠a bastante y, adem√°s, el resto de m√©tricas de SVM Polinomial son buenas, esta podr√≠a ser la mejor opci√≥n para nuestro problema. Por tanto, ese modelo ser√≠a mi elecci√≥n. üòã

En cuanto a las variables de nuestro conjunto de datos dentro de los modelos en los que se ha analizado la importancia de las variables, se ha visto como **overtime** es la variable que m√°s afectaba para que se produjese el abandono laboral, por lo que esto puede aportar mucha informaci√≥n para tratar de controlar este abandono voluntario del empleo.

