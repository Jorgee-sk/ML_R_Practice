plot.subtitle = element_text(size  =10))
# Plot ROC curve
plot(roc_curve2, col = "#37d8d5", main = "Curva ROC", print.auc = TRUE)
# Plot ROC curve
plot.roc(roc_curve2, col = "#37d8d5", main = "Curva ROC", print.auc = TRUE)
# Plot ROC curve
plot(roc_curve2, col = "#37d8d5", main = "Curva ROC", print.auc = TRUE)
#| code-fold: true
#| message: false
#| warning: false
#---------------------------------------------------------------------------------------------------------------------------
# Prediccions en formato prob
predicted <- as.data.frame(predict(best_tree, attrition_test, type="prob"))
# Unión de etiqueta real
predicted$real_class <- as.factor(attrition_test$attrition)
# Rename
predicted <- predicted |>  rename(prob_attrition = "1", prob_none = "0")
#----------------------------------------------------------------------------------------------------------
# Curva ROC: etiqueta real vs probabilid de 0. (Se invierte la clase)
roc_curve <- predicted |> roc_curve(truth = real_class, prob_none)
# Área debajo de la curva.
auc <- predicted |>  roc_auc(truth = real_class, prob_none)
auc <- auc |>  pull(.estimate)
# Curva ROC con otro paquete para comprobar que está mal calculada hasta el momento
# Calculate ROC curve
roc_curve2 <- roc(predicted$real_class, predicted$prob_attrition)
#---------------------------------------------------------------------------------------------------------------------------
# Gráfico Curva ROC- (con paquete habitual)
ggplot(roc_curve, aes(x = 1 - specificity, y = sensitivity)) +
#scale_x_reverse() +
# Línea de tamaño 2, color azul y transparencia 0.85
geom_line(lwd = 1, alpha = 0.85, color = "#e01b63") +
# Añadimos diagonal de línea tipo 4
geom_abline(lty = "dashed") +
# Hacemos el gráfico cuadrado
coord_equal() +
# Etiquetas
labs(x = "1 - Specificity",
y = "Sensitivity",
title = "CURVA ROC (ggplot) - Valor attrition inverso",
subtitle = glue("AUC = {round(auc, 3)}"))+
theme_minimal() +
# Tema
theme(axis.title.y = element_text(face="bold"),
axis.title.x = element_text(face="bold"),
plot.title = element_text(size =12,face="bold"),
plot.subtitle = element_text(size  =10))
# Plot ROC curve
plot(roc_curve2, col = "#37d8d5", main = "Curva ROC", print.auc = TRUE)
plot(roc_curve2,
col = "#37d8d5",
lwd = 1,
legacy.axes = TRUE,
main = "CURVA ROC (plot - roc_curve)",
sub = glue("AUC = {round(auc, 3)}"),
xlab = "1 - Specificity",
ylab = "Sensitivity",
print.auc = TRUE,
font.main = 2,
font.lab = 2,
cex.main = 1.2,
cex.sub = 0.9)
plot(roc_curve2,
col = "#37d8d5",
lwd = 1,
legacy.axes = TRUE,
main = "CURVA ROC (plot - roc_curve)",
xlab = "1 - Specificity",
ylab = "Sensitivity",
print.auc = TRUE,
font.main = 2,
font.lab = 2,
cex.main = 1.2,
cex.sub = 0.9)
plot(roc_curve2,
col = "#37d8d5",
lwd = 2,
legacy.axes = TRUE,
main = "CURVA ROC (plot - roc_curve)",
xlab = "1 - Specificity",
ylab = "Sensitivity",
print.auc = TRUE,
font.main = 2,
font.lab = 2,
cex.main = 1.2,
cex.sub = 0.9)
abline(a = 0, b = 1, lty = "dashed", col = "black")
plot(roc_curve2,
col = "#37d8d5",
lwd = 2,
legacy.axes = TRUE,
main = "CURVA ROC (plot - roc_curve)",
xlab = "1 - Specificity",
ylab = "Sensitivity",
print.auc = TRUE,
font.main = 2,
font.lab = 2,
cex.main = 1.2,
cex.sub = 0.9)
#| code-fold: true
#| message: false
#| warning: false
#---------------------------------------------------------------------------------------------------------------------------
# Prediccions en formato prob
predicted <- as.data.frame(predict(best_tree, attrition_test, type="prob"))
# Unión de etiqueta real
predicted$real_class <- as.factor(attrition_test$attrition)
# Rename
predicted <- predicted |>  rename(prob_attrition = "1", prob_none = "0")
#----------------------------------------------------------------------------------------------------------
# Curva ROC: etiqueta real vs probabilid de 0. (Se invierte la clase)
roc_curve <- predicted |> roc_curve(truth = real_class, prob_none)
# Área debajo de la curva.
auc <- predicted |>  roc_auc(truth = real_class, prob_none)
auc <- auc |>  pull(.estimate)
# Curva ROC con otro paquete para comprobar que está mal calculada hasta el momento
# Calculate ROC curve
roc_curve2 <- roc(predicted$real_class, predicted$prob_attrition)
#---------------------------------------------------------------------------------------------------------------------------
# Gráfico Curva ROC- (con paquete habitual)
ggplot(roc_curve, aes(x = 1 - specificity, y = sensitivity)) +
#scale_x_reverse() +
# Línea de tamaño 2, color azul y transparencia 0.85
geom_line(lwd = 1, alpha = 0.85, color = "#e01b63") +
# Añadimos diagonal de línea tipo 4
geom_abline(lty = "dashed") +
# Hacemos el gráfico cuadrado
coord_equal() +
# Etiquetas
labs(x = "1 - Specificity",
y = "Sensitivity",
title = "CURVA ROC (ggplot - roc_curve)",
subtitle = glue("AUC = {round(auc, 3)}"))+
theme_minimal() +
# Tema
theme(axis.title.y = element_text(face="bold"),
axis.title.x = element_text(face="bold"),
plot.title = element_text(size =12,face="bold"),
plot.subtitle = element_text(size  =10))
plot(roc_curve2,
col = "#37d8d5",
lwd = 2,
legacy.axes = TRUE,
main = "CURVA ROC (plot - roc_curve)",
xlab = "1 - Specificity",
ylab = "Sensitivity",
print.auc = TRUE,
font.main = 2,
font.lab = 2,
cex.main = 1.2,
cex.sub = 0.9)
#| code-fold: true
#| message: false
#| warning: false
#---------------------------------------------------------------------------------------------------------------------------
# Prediccions en formato prob
predicted <- as.data.frame(predict(best_tree, attrition_test, type="prob"))
# Unión de etiqueta real
predicted$real_class <- as.factor(attrition_test$attrition)
# Rename
predicted <- predicted |>  rename(prob_attrition = "1", prob_none = "0")
#----------------------------------------------------------------------------------------------------------
# Curva ROC: etiqueta real vs probabilid de 0. (Se invierte la clase)
roc_curve <- predicted |> roc_curve(truth = real_class, prob_none)
# Área debajo de la curva.
auc <- predicted |>  roc_auc(truth = real_class, prob_none)
auc <- auc |>  pull(.estimate)
# Curva ROC con otro paquete para comprobar que está mal calculada hasta el momento
# Calculate ROC curve
roc_curve2 <- roc(predicted$real_class, predicted$prob_attrition)
#---------------------------------------------------------------------------------------------------------------------------
# Gráfico Curva ROC- (con paquete habitual)
ggplot(roc_curve, aes(x = 1 - specificity, y = sensitivity)) +
#scale_x_reverse() +
# Línea de tamaño 2, color azul y transparencia 0.85
geom_line(lwd = 1, alpha = 0.85, color = "#e01b63") +
# Añadimos diagonal de línea tipo 4
geom_abline(lty = "dashed") +
# Hacemos el gráfico cuadrado
coord_equal() +
# Etiquetas
labs(x = "1 - Specificity",
y = "Sensitivity",
title = "CURVA ROC (ggplot - roc_curve)",
subtitle = glue("AUC = {round(auc, 3)}"))+
theme_minimal() +
# Tema
theme(axis.title.y = element_text(face="bold"),
axis.title.x = element_text(face="bold"),
plot.title = element_text(size =12,face="bold"),
plot.subtitle = element_text(size  =10))
plot(roc_curve2,
col = "#37d8d5",
lwd = 2,
legacy.axes = TRUE,
main = "CURVA ROC (plot - roc_curve)",
xlab = "1 - Specificity",
ylab = "Sensitivity",
print.auc = TRUE)
# Borramos variables del environment
rm(list = ls())
library(tidyverse)  # Depuración datos
library(skimr)      # Resumen numérico
library(ggplot2)    # Gráficos
library(tidymodels) # Modelos
library(rpart)      # CART
library(rpart.plot) # Graficar árbol
library(caret)      # Matriz de Confusion
library(glue)       # pegar texto + variables fácilmente
library(DT)         # Para mostrar tabla (formatStyle)
library(ROSE)       # Para Oversampling
library(outliers)   # Para funcion scores (receta)
library(lubridate)  # Fechas
library(timeDate)   # Festivos (receta)
library(hrbrthemes) # Tema ggplot
library(corrplot)   # Plot m.correl
library(kknn)       # ajuste knn
library(themis)     # Oversampling
#| message: false
#| warning: false
#|
# Borramos variables del environment
rm(list = ls())
library(tidyverse)  # Depuración datos
library(skimr)      # Resumen numérico
library(ggplot2)    # Gráficos
library(tidymodels) # Modelos
library(rpart)      # CART
library(rpart.plot) # Graficar árbol
library(caret)      # Matriz de Confusion
library(glue)       # pegar texto + variables fácilmente
library(DT)         # Para mostrar tabla (formatStyle)
library(ROSE)       # Para Oversampling
library(outliers)   # Para funcion scores (receta)
library(lubridate)  # Fechas
library(timeDate)   # Festivos (receta)
library(hrbrthemes) # Tema ggplot
library(corrplot)   # Plot m.correl
library(kknn)       # ajuste knn
library(themis)     # Oversampling
#| code-fold: false
#| message: false
#| warning: false
attrition_data <- readRDS("./data/attrition_data.rds")
#| code-fold: false
#| message: false
#| warning: false
attrition_data <- readRDS("./data/attrition_data.rds")
#| code-fold: false
#| message: false
#| warning: false
#|
set.seed(200900)
attrition_split <- initial_split(attrition_data, strata = attrition, prop = 0.80)
# Train
attrition_train <- training(attrition_split)
# Reparto en Train
attrition_train |> group_by(attrition) |> summarise(n = n()) |> mutate(prop = n /sum(n))
# Test
attrition_test <- testing(attrition_split)
# Reparto en test
attrition_test |> group_by(attrition) |> summarise(n = n()) |> mutate(prop = n /sum(n))
# Receta completa
attrition_recipe <-
# Fórmula y datos
recipe(data = attrition_train, attrition ~ .) |>
# Roles/borrado de la variable
update_role(employeeid, new_role = "ID") |> update_role_requirements(role = "ID", bake = FALSE) |>
# Categoria Other
step_other(all_nominal_predictors(), threshold = 0.005) |>
# Filtro de correlación
step_corr(all_numeric_predictors(), threshold = 0.95) |>
# Filtro 0 varianza
step_zv(all_predictors()) |>
# Min / Max
step_range(all_numeric_predictors(), min = 0, max = 1) |>
# nominales las pasemos a dummy 1/0
step_dummy(all_nominal_predictors(), -all_outcomes()) |>
# Oversampling
step_upsample(attrition, over_ratio = 1)
#| warning: false
#| message: false
attrition_train_baked <- bake(attrition_recipe |> prep(), new_data = NULL)
datatable(attrition_train_baked, rownames = FALSE, filter = "top",options = list(pageLength = 10)) |> formatStyle(names(vacuna_train_baked), lineHeight = "65%")
#| warning: false
#| message: false
attrition_train_baked <- bake(attrition_recipe |> prep(), new_data = NULL)
datatable(attrition_train_baked, rownames = FALSE, filter = "top",options = list(pageLength = 10)) |> formatStyle(names(attrition_train_baked), lineHeight = "65%")
#| warning: false
#| message: false
attrition_train_baked <- bake(attrition_recipe |> prep(), new_data = NULL)
datatable(attrition_train_baked, rownames = FALSE, filter = "top",options = list(pageLength = 10)) |> formatStyle(names(attrition_train_baked), lineHeight = "65%")
attrition_train_baked |> group_by(attrition) |> summarise(n = n(), Porc = round(n()*100.0/nrow(attrition_train_baked),2)) |>
ggplot(aes(x = attrition, y = n, fill = attrition)) +
geom_col(position = "dodge", alpha =0.8) +
ylim(c(0, 2600)) +
geom_text(aes(label = paste(n," (",Porc,"%)", sep ="")),colour = "black", size = 4,vjust = -0.5, position = position_dodge(.9)) +
scale_fill_manual(values = c("#023047","#C2185B")) +
theme_minimal()+theme_ipsum(base_family = "Arial")+
theme(plot.title = element_text(size = 20, face = "bold"),
axis.title.y = element_blank(),
axis.title.x =element_blank(),
axis.text.x = element_text(size = 12),
legend.position = "None"
)
attrition_train_baked |> group_by(attrition) |> summarise(n = n(), Porc = round(n()*100.0/nrow(attrition_train_baked),2)) |>
ggplot(aes(x = attrition, y = n, fill = attrition)) +
geom_col(position = "dodge", alpha =0.8) +
ylim(c(0, 2600)) +
geom_text(aes(label = paste(n," (",Porc,"%)", sep ="")),colour = "black", size = 4,vjust = -0.5, position = position_dodge(.9)) +
scale_fill_manual(values = c("#023047","#C2185B")) +
theme_minimal()+
theme(plot.title = element_text(size = 20, face = "bold"),
axis.title.y = element_blank(),
axis.title.x =element_blank(),
axis.text.x = element_text(size = 12),
legend.position = "None"
)
set.seed(200900)
folds <- vfold_cv(attrition_train, v = 5, strata = attrition, repeats = 3)
knn_model <- nearest_neighbor(mode = "classification",
neighbors = tune("k"),
weight_func = tune("weight"),
dist_power = tune("dist")) |>
set_engine("kknn")
attrition_wflow <- workflow() |> add_recipe(attrition_recipe) |> add_model(knn_model)
#| message: false
#| warning: false
grid_knn <- expand_grid(k = seq(100, 500, by = 100),
weight = c("inv","gaussian","epanechnikov","biweight"),
dist = c(1, 2))
#| message: false
#| warning: false
#| echo: false
datatable(grid_knn,
rownames = FALSE,
filter = "top",
options = list(pageLength = 10, dom = "tip")) |> formatStyle(names(grid_knn))
#| message: false
#| warning: false
#| echo: false
datatable(grid_knn,
rownames = FALSE,
filter = "top",
options = list(pageLength = 10, dom = "tip")) |> formatStyle(names(grid_knn))
#| message: false
#| warning: false
#| eval: false
# Tiempo de ejecución:
attrition_knn_fit_tune <- attrition_wflow |>
tune_grid(resamples = folds,
grid = grid_knn,
control = control_grid(verbose = TRUE),
metrics = metric_set(accuracy, sens, spec, roc_auc))
# Guardo resultados
saveRDS(attrition_knn_fit_tune, file = "./outputs/attrition_knn_fit_tune.rds")
#| message: false
#| warning: false
# Cargamos los datos obtenidos
attrition_knn_fit_tune <- readRDS("./outputs/attrition_knn_fit_tune.rds")
# Métricas tratadas en cv_results
cv_results <- attrition_knn_fit_tune |> collect_metrics(summarize = FALSE) |>
select(rep = id, fold = id2, k, weight, dist , metric = .metric, value = .estimate ) |>
pivot_wider(names_from = metric, values_from = value) |>
mutate(model = as.factor(paste(k," - ",weight," - ", dist, sep =""))) |>
arrange(desc(accuracy))
#| message: false
#| warning: false
#| echo: false
datatable(cv_results,
rownames = FALSE,
filter = "top",
options = list(pageLength = 10, dom = "tip")) |> formatStyle(names(cv_results))
#| message: false
#| warning: false
# Cargamos los datos obtenidos
attrition_knn_fit_tune <- readRDS("./outputs/attrition_knn_fit_tune.rds")
# Métricas tratadas en cv_results
attrition_cv_results <- attrition_knn_fit_tune |> collect_metrics(summarize = FALSE) |>
select(rep = id, fold = id2, k, weight, dist , metric = .metric, value = .estimate ) |>
pivot_wider(names_from = metric, values_from = value) |>
mutate(model = as.factor(paste(k," - ",weight," - ", dist, sep =""))) |>
arrange(desc(accuracy))
#| message: false
#| warning: false
#| echo: false
datatable(cv_results,
rownames = FALSE,
filter = "top",
options = list(pageLength = 10, dom = "tip")) |> formatStyle(names(cv_results))
#| message: false
#| warning: false
#| echo: false
datatable(cv_results,
rownames = FALSE,
filter = "top",
options = list(pageLength = 10, dom = "tip")) |> formatStyle(names(attrition_cv_results))
# Grafico comparativo
attrition_cv_results |> ggplot(aes(x=model, y=sens)) +
stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot( fill = "#ff8fab") +
labs( title = "Cross Validation Results",
subtitle = "Comparativa (en términos de sensitivity) de los modelos")+
scale_y_continuous(breaks = seq(from = 0.2, to=1, by=0.02))+
stat_summary(fun.y=mean, geom="point", shape=23, size=1.5, color="#023047", fill="#023047") +
theme_minimal()+
theme(plot.title= element_text(size=15, face = "bold" ),
axis.title.x = element_blank(),
axis.text.x  = element_text(size=10,face = "bold", angle = 90),
axis.title.y = element_blank(),
axis.text.y  = element_text(size=10,face = "bold"),
legend.position = "None"
)
attrition_cv_results_group <- attrition_cv_results |> group_by(model) |>
summarise(accuracy = mean(accuracy),
sensitivity = mean(sens),
specificity = mean(spec),
auc = mean(roc_auc)) |>
arrange(desc(accuracy)) |>
slice_head(n = 10) |>
select(model)
attrition_cv_results_top <- attrition_cv_results |>  inner_join(attrition_cv_results_group, by = "model")
attrition_cv_results_top |> ggplot(aes(x=model, y=sens)) +
stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot( fill = "#ff8fab") +
labs( title = "Cross Validation Results",
subtitle = "Comparativa (en términos de sensitivity) de los modelos")+
scale_y_continuous(breaks = seq(from = 0.2, to=1, by=0.02))+
stat_summary(fun.y=mean, geom="point", shape=23, size=1.5, color="#023047", fill="#023047") +
theme_minimal()+
theme(plot.title= element_text(size=15, face = "bold" ),
axis.title.x = element_blank(),
axis.text.x  = element_text(size=10,face = "bold", angle = 90),
axis.title.y = element_blank(),
axis.text.y  = element_text(size=10,face = "bold"),
legend.position = "None"
)
attrition_cv_results_top |> ggplot(aes(x=model, y=sens)) +
stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot( fill = "#e01b63") +
labs( title = "Cross Validation Results",
subtitle = "Comparativa (en términos de sensitivity) de los modelos")+
scale_y_continuous(breaks = seq(from = 0.2, to=1, by=0.02))+
stat_summary(fun.y=mean, geom="point", shape=23, size=1.5, color="blue", fill="blue") +
theme_minimal()+
theme(plot.title= element_text(size=15, face = "bold" ),
axis.title.x = element_blank(),
axis.text.x  = element_text(size=10,face = "bold", angle = 90),
axis.title.y = element_blank(),
axis.text.y  = element_text(size=10,face = "bold"),
legend.position = "None"
)
attrition_cv_results_top |> ggplot(aes(x=model, y=sens)) +
stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot( fill = "#e11b63") +
labs( title = "Cross Validation Results",
subtitle = "Comparativa (en términos de sensitivity) de los modelos")+
scale_y_continuous(breaks = seq(from = 0.2, to=1, by=0.02))+
stat_summary(fun.y=mean, geom="point", shape=23, size=1.5, color="blue", fill="blue") +
theme_minimal()+
theme(plot.title= element_text(size=15, face = "bold" ),
axis.title.x = element_blank(),
axis.text.x  = element_text(size=10,face = "bold", angle = 90),
axis.title.y = element_blank(),
axis.text.y  = element_text(size=10,face = "bold"),
legend.position = "None"
)
attrition_cv_results_top |> ggplot(aes(x=model, y=sens)) +
stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot( fill = "#e11b63") +
labs( title = "Cross Validation Results",
subtitle = "Comparativa (en términos de sensitivity) de los modelos")+
scale_y_continuous(breaks = seq(from = 0.2, to=1, by=0.02))+
stat_summary(fun.y=mean, geom="point", shape=23, size=1.5, color="#37d8d5", fill="blue") +
theme_minimal()+
theme(plot.title= element_text(size=15, face = "bold" ),
axis.title.x = element_blank(),
axis.text.x  = element_text(size=10,face = "bold", angle = 90),
axis.title.y = element_blank(),
axis.text.y  = element_text(size=10,face = "bold"),
legend.position = "None"
)
attrition_cv_results_top |> ggplot(aes(x=model, y=sens)) +
stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot( fill = "#e11b63") +
labs( title = "Cross Validation Results",
subtitle = "Comparativa (en términos de sensitivity) de los modelos")+
scale_y_continuous(breaks = seq(from = 0.2, to=1, by=0.02))+
stat_summary(fun.y=mean, geom="point", shape=23, size=1.5, color="#37d8d5", fill="#37d8d5") +
theme_minimal()+
theme(plot.title= element_text(size=15, face = "bold" ),
axis.title.x = element_blank(),
axis.text.x  = element_text(size=10,face = "bold", angle = 90),
axis.title.y = element_blank(),
axis.text.y  = element_text(size=10,face = "bold"),
legend.position = "None"
)
attrition_cv_results_top |> ggplot(aes(x=model, y=sens)) +
stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot( fill = "#e11b63") +
labs( title = "Cross Validation Results",
subtitle = "Comparativa (en términos de sensitivity) de los modelos")+
scale_y_continuous(breaks = seq(from = 0.2, to=1, by=0.02))+
stat_summary(fun.y=mean, geom="point", shape=23, size=1.5, color="black", fill="black") +
theme_minimal()+
theme(plot.title= element_text(size=15, face = "bold" ),
axis.title.x = element_blank(),
axis.text.x  = element_text(size=10,face = "bold", angle = 90),
axis.title.y = element_blank(),
axis.text.y  = element_text(size=10,face = "bold"),
legend.position = "None"
)
